head	1.109;
access;
symbols
	sid-snapshot-20180601:1.109
	sid-snapshot-20180501:1.109
	sid-snapshot-20180401:1.109
	sid-snapshot-20180301:1.109
	sid-snapshot-20180201:1.109
	sid-snapshot-20180101:1.109
	sid-snapshot-20171201:1.109
	sid-snapshot-20171101:1.109
	sid-snapshot-20171001:1.109
	sid-snapshot-20170901:1.109
	sid-snapshot-20170801:1.109
	sid-snapshot-20170701:1.109
	sid-snapshot-20170601:1.109
	sid-snapshot-20170501:1.109
	sid-snapshot-20170401:1.109
	sid-snapshot-20170301:1.109
	sid-snapshot-20170201:1.109
	sid-snapshot-20170101:1.109
	sid-snapshot-20161201:1.109
	sid-snapshot-20161101:1.109
	sid-snapshot-20160901:1.109
	sid-snapshot-20160801:1.109
	sid-snapshot-20160701:1.109
	sid-snapshot-20160601:1.109
	sid-snapshot-20160501:1.109
	sid-snapshot-20160401:1.109
	sid-snapshot-20160301:1.109
	sid-snapshot-20160201:1.109
	sid-snapshot-20160101:1.109
	sid-snapshot-20151201:1.109
	sid-snapshot-20151101:1.109
	sid-snapshot-20151001:1.109
	sid-snapshot-20150901:1.109
	sid-snapshot-20150801:1.109
	sid-snapshot-20150701:1.109
	sid-snapshot-20150601:1.109
	sid-snapshot-20150501:1.109
	sid-snapshot-20150401:1.109
	sid-snapshot-20150301:1.109
	sid-snapshot-20150201:1.109
	sid-snapshot-20150101:1.109
	sid-snapshot-20141201:1.109
	sid-snapshot-20141101:1.109
	sid-snapshot-20141001:1.109
	sid-snapshot-20140901:1.109
	sid-snapshot-20140801:1.109
	sid-snapshot-20140701:1.109
	sid-snapshot-20140601:1.109
	sid-snapshot-20140501:1.109
	sid-snapshot-20140401:1.109
	sid-snapshot-20140301:1.109
	sid-snapshot-20140201:1.109
	sid-snapshot-20140101:1.109
	sid-snapshot-20131201:1.109
	sid-snapshot-20131101:1.109
	sid-snapshot-20131001:1.109
	binutils-2_24-branch:1.109.0.2
	binutils-2_24-branchpoint:1.109
	binutils-2_21_1:1.100
	sid-snapshot-20130901:1.109
	gdb_7_6_1-2013-08-30-release:1.108
	sid-snapshot-20130801:1.108
	sid-snapshot-20130701:1.108
	sid-snapshot-20130601:1.108
	sid-snapshot-20130501:1.108
	gdb_7_6-2013-04-26-release:1.108
	sid-snapshot-20130401:1.108
	binutils-2_23_2:1.105
	gdb_7_6-branch:1.108.0.2
	gdb_7_6-2013-03-12-branchpoint:1.108
	sid-snapshot-20130301:1.108
	sid-snapshot-20130201:1.106
	sid-snapshot-20130101:1.105
	sid-snapshot-20121201:1.105
	gdb_7_5_1-2012-11-29-release:1.105
	binutils-2_23_1:1.105
	sid-snapshot-20121101:1.105
	binutils-2_23:1.105
	sid-snapshot-20121001:1.105
	sid-snapshot-20120901:1.105
	gdb_7_5-2012-08-17-release:1.105
	sid-snapshot-20120801:1.105
	binutils-2_23-branch:1.105.0.4
	binutils-2_23-branchpoint:1.105
	gdb_7_5-branch:1.105.0.2
	gdb_7_5-2012-07-18-branchpoint:1.105
	sid-snapshot-20120701:1.105
	sid-snapshot-20120601:1.105
	sid-snapshot-20120501:1.104
	binutils-2_22_branch:1.101.0.6
	gdb_7_4_1-2012-04-26-release:1.102
	sid-snapshot-20120401:1.103
	sid-snapshot-20120301:1.103
	sid-snapshot-20120201:1.102
	gdb_7_4-2012-01-24-release:1.102
	sid-snapshot-20120101:1.102
	gdb_7_4-branch:1.102.0.2
	gdb_7_4-2011-12-13-branchpoint:1.102
	sid-snapshot-20111201:1.102
	binutils-2_22:1.101
	sid-snapshot-20111101:1.102
	sid-snapshot-20111001:1.101
	binutils-2_22-branch:1.101.0.4
	binutils-2_22-branchpoint:1.101
	gdb_7_3_1-2011-09-04-release:1.101
	sid-snapshot-20110901:1.101
	sid-snapshot-20110801:1.101
	gdb_7_3-2011-07-26-release:1.101
	sid-snapshot-20110701:1.101
	sid-snapshot-20110601:1.101
	sid-snapshot-20110501:1.101
	gdb_7_3-branch:1.101.0.2
	gdb_7_3-2011-04-01-branchpoint:1.101
	sid-snapshot-20110401:1.101
	sid-snapshot-20110301:1.101
	sid-snapshot-20110201:1.100
	sid-snapshot-20110101:1.100
	binutils-2_21:1.100
	sid-snapshot-20101201:1.100
	binutils-2_21-branch:1.100.0.2
	binutils-2_21-branchpoint:1.100
	sid-snapshot-20101101:1.100
	sid-snapshot-20101001:1.98
	binutils-2_20_1:1.89.2.3
	gdb_7_2-2010-09-02-release:1.96
	sid-snapshot-20100901:1.97
	sid-snapshot-20100801:1.96
	gdb_7_2-branch:1.96.0.2
	gdb_7_2-2010-07-07-branchpoint:1.96
	sid-snapshot-20100701:1.96
	sid-snapshot-20100601:1.95
	sid-snapshot-20100501:1.95
	sid-snapshot-20100401:1.94
	gdb_7_1-2010-03-18-release:1.94
	sid-snapshot-20100301:1.94
	gdb_7_1-branch:1.94.0.2
	gdb_7_1-2010-02-18-branchpoint:1.94
	sid-snapshot-20100201:1.93
	sid-snapshot-20100101:1.93
	gdb_7_0_1-2009-12-22-release:1.89
	sid-snapshot-20091201:1.92
	sid-snapshot-20091101:1.90
	binutils-2_20:1.89.2.1
	gdb_7_0-2009-10-06-release:1.89
	sid-snapshot-20091001:1.90
	gdb_7_0-branch:1.89.0.4
	gdb_7_0-2009-09-16-branchpoint:1.89
	arc-sim-20090309:1.29
	binutils-arc-20081103-branch:1.53.0.6
	binutils-arc-20081103-branchpoint:1.53
	binutils-2_20-branch:1.89.0.2
	binutils-2_20-branchpoint:1.89
	sid-snapshot-20090901:1.88
	sid-snapshot-20090801:1.87
	msnyder-checkpoint-072509-branch:1.87.0.2
	msnyder-checkpoint-072509-branchpoint:1.87
	sid-snapshot-20090701:1.83
	dje-cgen-play1-branch:1.83.0.2
	dje-cgen-play1-branchpoint:1.83
	sid-snapshot-20090601:1.81
	sid-snapshot-20090501:1.69
	sid-snapshot-20090401:1.69
	arc-20081103-branch:1.53.0.4
	arc-20081103-branchpoint:1.53
	arc-insight_6_8-branch:1.29.0.6
	arc-insight_6_8-branchpoint:1.29
	insight_6_8-branch:1.29.0.4
	insight_6_8-branchpoint:1.29
	sid-snapshot-20090301:1.64
	binutils-2_19_1:1.51.2.1
	sid-snapshot-20090201:1.62
	sid-snapshot-20090101:1.57
	reverse-20081226-branch:1.57.0.2
	reverse-20081226-branchpoint:1.57
	sid-snapshot-20081201:1.53
	multiprocess-20081120-branch:1.53.0.2
	multiprocess-20081120-branchpoint:1.53
	sid-snapshot-20081101:1.53
	binutils-2_19:1.51.2.1
	sid-snapshot-20081001:1.52
	reverse-20080930-branch:1.52.0.2
	reverse-20080930-branchpoint:1.52
	binutils-2_19-branch:1.51.0.2
	binutils-2_19-branchpoint:1.51
	sid-snapshot-20080901:1.51
	sid-snapshot-20080801:1.49
	reverse-20080717-branch:1.48.0.2
	reverse-20080717-branchpoint:1.48
	sid-snapshot-20080701:1.48
	msnyder-reverse-20080609-branch:1.45.0.2
	msnyder-reverse-20080609-branchpoint:1.45
	drow-reverse-20070409-branch:1.10.0.2
	drow-reverse-20070409-branchpoint:1.10
	sid-snapshot-20080601:1.42
	sid-snapshot-20080501:1.39
	sid-snapshot-20080403:1.36
	sid-snapshot-20080401:1.35
	gdb_6_8-2008-03-27-release:1.29
	sid-snapshot-20080301:1.30
	gdb_6_8-branch:1.29.0.2
	gdb_6_8-2008-02-26-branchpoint:1.29
	sid-snapshot-20080201:1.27
	sid-snapshot-20080101:1.26
	sid-snapshot-20071201:1.24
	sid-snapshot-20071101:1.24
	gdb_6_7_1-2007-10-29-release:1.21
	gdb_6_7-2007-10-10-release:1.21
	sid-snapshot-20071001:1.24
	gdb_6_7-branch:1.21.0.2
	gdb_6_7-2007-09-07-branchpoint:1.21
	binutils-2_18:1.20
	binutils-2_18-branch:1.20.0.2
	binutils-2_18-branchpoint:1.20
	insight_6_6-20070208-release:1.1
	gdb_6_6-2006-12-18-release:1.1
	gdb_6_6-branch:1.1.0.2
	gdb_6_6-2006-11-15-branchpoint:1.1
	binutils_latest_snapshot:1.109;
locks; strict;
comment	@ * @;


1.109
date	2013.08.23.07.54.17;	author nickc;	state Exp;
branches;
next	1.108;

1.108
date	2013.02.21.02.29.09;	author amodra;	state Exp;
branches;
next	1.107;

1.107
date	2013.02.10.04.36.32;	author amodra;	state Exp;
branches;
next	1.106;

1.106
date	2013.01.10.20.03.53;	author hjl;	state Exp;
branches;
next	1.105;

1.105
date	2012.05.07.03.27.51;	author macro;	state Exp;
branches;
next	1.104;

1.104
date	2012.04.24.05.12.35;	author amodra;	state Exp;
branches;
next	1.103;

1.103
date	2012.02.26.23.12.16;	author amodra;	state Exp;
branches;
next	1.102;

1.102
date	2011.10.19.07.17.18;	author amodra;	state Exp;
branches;
next	1.101;

1.101
date	2011.02.28.18.30.16;	author ktietz;	state Exp;
branches
	1.101.4.1;
next	1.100;

1.100
date	2010.10.25.15.54.14;	author drow;	state Exp;
branches;
next	1.99;

1.99
date	2010.10.04.14.13.09;	author bernds;	state Exp;
branches;
next	1.98;

1.98
date	2010.09.16.10.36.00;	author amodra;	state Exp;
branches;
next	1.97;

1.97
date	2010.08.25.14.53.44;	author hjl;	state Exp;
branches;
next	1.96;

1.96
date	2010.06.27.04.07.52;	author amodra;	state Exp;
branches;
next	1.95;

1.95
date	2010.04.24.01.05.24;	author amodra;	state Exp;
branches;
next	1.94;

1.94
date	2010.02.04.09.16.40;	author nickc;	state Exp;
branches;
next	1.93;

1.93
date	2009.12.11.13.42.03;	author nickc;	state Exp;
branches;
next	1.92;

1.92
date	2009.11.17.13.37.01;	author uweigand;	state Exp;
branches;
next	1.91;

1.91
date	2009.11.03.13.58.49;	author uweigand;	state Exp;
branches;
next	1.90;

1.90
date	2009.10.01.13.09.56;	author uweigand;	state Exp;
branches;
next	1.89;

1.89
date	2009.09.04.06.54.12;	author amodra;	state Exp;
branches
	1.89.2.1;
next	1.88;

1.88
date	2009.08.05.20.40.33;	author tsmigiel;	state Exp;
branches;
next	1.87;

1.87
date	2009.07.24.19.51.26;	author tsmigiel;	state Exp;
branches;
next	1.86;

1.86
date	2009.07.10.14.00.38;	author amodra;	state Exp;
branches;
next	1.85;

1.85
date	2009.07.09.10.58.06;	author amodra;	state Exp;
branches;
next	1.84;

1.84
date	2009.07.07.03.26.47;	author amodra;	state Exp;
branches;
next	1.83;

1.83
date	2009.06.16.13.44.00;	author uweigand;	state Exp;
branches;
next	1.82;

1.82
date	2009.06.06.06.36.52;	author amodra;	state Exp;
branches;
next	1.81;

1.81
date	2009.05.28.10.47.44;	author uweigand;	state Exp;
branches;
next	1.80;

1.80
date	2009.05.28.10.42.47;	author uweigand;	state Exp;
branches;
next	1.79;

1.79
date	2009.05.21.14.15.48;	author amodra;	state Exp;
branches;
next	1.78;

1.78
date	2009.05.14.17.56.56;	author uweigand;	state Exp;
branches;
next	1.77;

1.77
date	2009.05.14.16.56.08;	author uweigand;	state Exp;
branches;
next	1.76;

1.76
date	2009.05.14.16.04.01;	author uweigand;	state Exp;
branches;
next	1.75;

1.75
date	2009.05.14.15.26.35;	author uweigand;	state Exp;
branches;
next	1.74;

1.74
date	2009.05.14.14.42.36;	author uweigand;	state Exp;
branches;
next	1.73;

1.73
date	2009.05.14.14.40.57;	author uweigand;	state Exp;
branches;
next	1.72;

1.72
date	2009.05.14.14.39.04;	author uweigand;	state Exp;
branches;
next	1.71;

1.71
date	2009.05.14.04.30.01;	author amodra;	state Exp;
branches;
next	1.70;

1.70
date	2009.05.11.09.40.52;	author amodra;	state Exp;
branches;
next	1.69;

1.69
date	2009.03.19.07.04.11;	author amodra;	state Exp;
branches;
next	1.68;

1.68
date	2009.03.17.12.46.18;	author amodra;	state Exp;
branches;
next	1.67;

1.67
date	2009.03.15.15.15.29;	author uweigand;	state Exp;
branches;
next	1.66;

1.66
date	2009.03.15.03.28.51;	author amodra;	state Exp;
branches;
next	1.65;

1.65
date	2009.03.11.00.18.02;	author uweigand;	state Exp;
branches;
next	1.64;

1.64
date	2009.02.09.14.24.41;	author amodra;	state Exp;
branches;
next	1.63;

1.63
date	2009.02.04.02.42.57;	author amodra;	state Exp;
branches;
next	1.62;

1.62
date	2009.01.21.02.27.12;	author amodra;	state Exp;
branches;
next	1.61;

1.61
date	2009.01.12.14.13.03;	author amodra;	state Exp;
branches;
next	1.60;

1.60
date	2009.01.12.13.56.03;	author amodra;	state Exp;
branches;
next	1.59;

1.59
date	2009.01.12.04.09.43;	author amodra;	state Exp;
branches;
next	1.58;

1.58
date	2009.01.12.00.23.56;	author amodra;	state Exp;
branches;
next	1.57;

1.57
date	2008.12.10.13.36.41;	author amodra;	state Exp;
branches;
next	1.56;

1.56
date	2008.12.10.06.32.52;	author amodra;	state Exp;
branches;
next	1.55;

1.55
date	2008.12.10.03.49.02;	author amodra;	state Exp;
branches;
next	1.54;

1.54
date	2008.12.10.00.37.11;	author amodra;	state Exp;
branches;
next	1.53;

1.53
date	2008.10.20.10.57.33;	author amodra;	state Exp;
branches;
next	1.52;

1.52
date	2008.09.29.14.12.02;	author amodra;	state Exp;
branches;
next	1.51;

1.51
date	2008.08.04.13.01.42;	author amodra;	state Exp;
branches
	1.51.2.1;
next	1.50;

1.50
date	2008.08.02.06.44.43;	author amodra;	state Exp;
branches;
next	1.49;

1.49
date	2008.07.21.07.36.25;	author amodra;	state Exp;
branches;
next	1.48;

1.48
date	2008.06.19.16.16.58;	author amodra;	state Exp;
branches;
next	1.47;

1.47
date	2008.06.19.16.14.15;	author amodra;	state Exp;
branches;
next	1.46;

1.46
date	2008.06.16.16.16.31;	author amodra;	state Exp;
branches;
next	1.45;

1.45
date	2008.06.07.12.02.47;	author amodra;	state Exp;
branches;
next	1.44;

1.44
date	2008.06.06.06.02.00;	author amodra;	state Exp;
branches;
next	1.43;

1.43
date	2008.06.04.07.07.19;	author amodra;	state Exp;
branches;
next	1.42;

1.42
date	2008.05.28.08.15.27;	author amodra;	state Exp;
branches;
next	1.41;

1.41
date	2008.05.12.12.22.53;	author amodra;	state Exp;
branches;
next	1.40;

1.40
date	2008.05.07.14.46.44;	author amodra;	state Exp;
branches;
next	1.39;

1.39
date	2008.04.08.05.48.28;	author amodra;	state Exp;
branches;
next	1.38;

1.38
date	2008.04.08.03.26.54;	author amodra;	state Exp;
branches;
next	1.37;

1.37
date	2008.04.07.13.07.23;	author amodra;	state Exp;
branches;
next	1.36;

1.36
date	2008.04.01.23.52.00;	author amodra;	state Exp;
branches;
next	1.35;

1.35
date	2008.03.20.05.35.10;	author amodra;	state Exp;
branches;
next	1.34;

1.34
date	2008.03.14.04.42.16;	author amodra;	state Exp;
branches;
next	1.33;

1.33
date	2008.03.11.23.23.23;	author amodra;	state Exp;
branches;
next	1.32;

1.32
date	2008.03.11.09.30.50;	author amodra;	state Exp;
branches;
next	1.31;

1.31
date	2008.03.03.10.03.40;	author amodra;	state Exp;
branches;
next	1.30;

1.30
date	2008.02.28.09.30.27;	author amodra;	state Exp;
branches;
next	1.29;

1.29
date	2008.02.07.01.26.56;	author amodra;	state Exp;
branches;
next	1.28;

1.28
date	2008.02.04.01.13.38;	author amodra;	state Exp;
branches;
next	1.27;

1.27
date	2008.01.28.05.59.24;	author amodra;	state Exp;
branches;
next	1.26;

1.26
date	2007.12.05.03.29.20;	author amodra;	state Exp;
branches;
next	1.25;

1.25
date	2007.12.04.03.29.43;	author amodra;	state Exp;
branches;
next	1.24;

1.24
date	2007.09.25.08.27.39;	author amodra;	state Exp;
branches;
next	1.23;

1.23
date	2007.09.25.07.58.21;	author amodra;	state Exp;
branches;
next	1.22;

1.22
date	2007.09.24.00.30.03;	author amodra;	state Exp;
branches;
next	1.21;

1.21
date	2007.09.04.04.09.22;	author amodra;	state Exp;
branches;
next	1.20;

1.20
date	2007.07.03.14.26.41;	author nickc;	state Exp;
branches;
next	1.19;

1.19
date	2007.06.29.01.39.54;	author amodra;	state Exp;
branches;
next	1.18;

1.18
date	2007.06.27.07.12.54;	author amodra;	state Exp;
branches;
next	1.17;

1.17
date	2007.05.12.06.45.33;	author amodra;	state Exp;
branches;
next	1.16;

1.16
date	2007.05.11.03.10.11;	author amodra;	state Exp;
branches;
next	1.15;

1.15
date	2007.05.08.02.29.27;	author amodra;	state Exp;
branches;
next	1.14;

1.14
date	2007.05.07.14.37.27;	author amodra;	state Exp;
branches;
next	1.13;

1.13
date	2007.04.30.14.06.39;	author amodra;	state Exp;
branches;
next	1.12;

1.12
date	2007.04.26.14.46.57;	author amodra;	state Exp;
branches;
next	1.11;

1.11
date	2007.04.12.07.47.13;	author amodra;	state Exp;
branches;
next	1.10;

1.10
date	2007.04.05.07.01.52;	author amodra;	state Exp;
branches;
next	1.9;

1.9
date	2007.03.26.12.50.09;	author amodra;	state Exp;
branches;
next	1.8;

1.8
date	2007.03.26.12.23.02;	author amodra;	state Exp;
branches;
next	1.7;

1.7
date	2007.03.23.00.42.00;	author amodra;	state Exp;
branches;
next	1.6;

1.6
date	2007.03.17.02.56.37;	author amodra;	state Exp;
branches;
next	1.5;

1.5
date	2007.03.07.08.54.34;	author amodra;	state Exp;
branches;
next	1.4;

1.4
date	2007.02.27.08.29.52;	author amodra;	state Exp;
branches;
next	1.3;

1.3
date	2007.02.21.02.48.22;	author amodra;	state Exp;
branches;
next	1.2;

1.2
date	2006.12.15.04.13.34;	author amodra;	state Exp;
branches;
next	1.1;

1.1
date	2006.10.25.06.49.20;	author amodra;	state Exp;
branches;
next	;

1.101.4.1
date	2012.05.11.12.24.28;	author nickc;	state Exp;
branches;
next	;

1.89.2.1
date	2009.10.01.13.16.23;	author uweigand;	state Exp;
branches;
next	1.89.2.2;

1.89.2.2
date	2009.11.03.13.59.39;	author uweigand;	state Exp;
branches;
next	1.89.2.3;

1.89.2.3
date	2009.11.17.13.47.05;	author uweigand;	state Exp;
branches;
next	;

1.51.2.1
date	2008.09.30.01.16.21;	author amodra;	state Exp;
branches;
next	;


desc
@@


1.109
log
@	PR binutils/15834
	Fix typos:
---
 bfd/bfdio.c                                  |  2 +-
 bfd/elf32-spu.c                              |  2 +-
 bfd/elfnn-aarch64.c                          |  2 +-
 binutils/od-xcoff.c                          |  2 +-
 config/tcl.m4                                |  2 +-
 gas/config/tc-ia64.c                         |  2 +-
 gas/config/tc-sparc.c                        |  2 +-
 gas/config/tc-z80.c                          | 12 ++++++------
 gas/doc/c-i386.texi                          |  6 +++---
 gas/doc/c-m32r.texi                          |  2 +-
 gas/testsuite/gas/d10v/instruction_packing.d |  2 +-
 gas/testsuite/gas/z80/atend.d                |  2 +-
 gold/object.h                                |  2 +-
 include/gdb/remote-sim.h                     |  2 +-
 include/opcode/ChangeLog                     |  2 +-
 include/opcode/i960.h                        |  2 +-
 ld/testsuite/ld-mips-elf/mips16-pic-1.inc    |  2 +-
 opcodes/aarch64-asm.c                        |  2 +-
 opcodes/aarch64-dis.c                        |  2 +-
 opcodes/msp430-dis.c                         |  2 +-
@
text
@/* SPU specific support for 32-bit ELF

   Copyright 2006-2013 Free Software Foundation, Inc.

   This file is part of BFD, the Binary File Descriptor library.

   This program is free software; you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation; either version 3 of the License, or
   (at your option) any later version.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License along
   with this program; if not, write to the Free Software Foundation, Inc.,
   51 Franklin Street - Fifth Floor, Boston, MA 02110-1301, USA.  */

#include "sysdep.h"
#include "libiberty.h"
#include "bfd.h"
#include "bfdlink.h"
#include "libbfd.h"
#include "elf-bfd.h"
#include "elf/spu.h"
#include "elf32-spu.h"

/* We use RELA style relocs.  Don't define USE_REL.  */

static bfd_reloc_status_type spu_elf_rel9 (bfd *, arelent *, asymbol *,
					   void *, asection *,
					   bfd *, char **);

/* Values of type 'enum elf_spu_reloc_type' are used to index this
   array, so it must be declared in the order of that type.  */

static reloc_howto_type elf_howto_table[] = {
  HOWTO (R_SPU_NONE,       0, 0,  0, FALSE,  0, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_NONE",
	 FALSE, 0, 0x00000000, FALSE),
  HOWTO (R_SPU_ADDR10,     4, 2, 10, FALSE, 14, complain_overflow_bitfield,
	 bfd_elf_generic_reloc, "SPU_ADDR10",
	 FALSE, 0, 0x00ffc000, FALSE),
  HOWTO (R_SPU_ADDR16,     2, 2, 16, FALSE,  7, complain_overflow_bitfield,
	 bfd_elf_generic_reloc, "SPU_ADDR16",
	 FALSE, 0, 0x007fff80, FALSE),
  HOWTO (R_SPU_ADDR16_HI, 16, 2, 16, FALSE,  7, complain_overflow_bitfield,
	 bfd_elf_generic_reloc, "SPU_ADDR16_HI",
	 FALSE, 0, 0x007fff80, FALSE),
  HOWTO (R_SPU_ADDR16_LO,  0, 2, 16, FALSE,  7, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_ADDR16_LO",
	 FALSE, 0, 0x007fff80, FALSE),
  HOWTO (R_SPU_ADDR18,     0, 2, 18, FALSE,  7, complain_overflow_bitfield,
	 bfd_elf_generic_reloc, "SPU_ADDR18",
	 FALSE, 0, 0x01ffff80, FALSE),
  HOWTO (R_SPU_ADDR32,     0, 2, 32, FALSE,  0, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_ADDR32",
	 FALSE, 0, 0xffffffff, FALSE),
  HOWTO (R_SPU_REL16,      2, 2, 16,  TRUE,  7, complain_overflow_bitfield,
	 bfd_elf_generic_reloc, "SPU_REL16",
	 FALSE, 0, 0x007fff80, TRUE),
  HOWTO (R_SPU_ADDR7,      0, 2,  7, FALSE, 14, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_ADDR7",
	 FALSE, 0, 0x001fc000, FALSE),
  HOWTO (R_SPU_REL9,       2, 2,  9,  TRUE,  0, complain_overflow_signed,
	 spu_elf_rel9,          "SPU_REL9",
	 FALSE, 0, 0x0180007f, TRUE),
  HOWTO (R_SPU_REL9I,      2, 2,  9,  TRUE,  0, complain_overflow_signed,
	 spu_elf_rel9,          "SPU_REL9I",
	 FALSE, 0, 0x0000c07f, TRUE),
  HOWTO (R_SPU_ADDR10I,    0, 2, 10, FALSE, 14, complain_overflow_signed,
	 bfd_elf_generic_reloc, "SPU_ADDR10I",
	 FALSE, 0, 0x00ffc000, FALSE),
  HOWTO (R_SPU_ADDR16I,    0, 2, 16, FALSE,  7, complain_overflow_signed,
	 bfd_elf_generic_reloc, "SPU_ADDR16I",
	 FALSE, 0, 0x007fff80, FALSE),
  HOWTO (R_SPU_REL32,      0, 2, 32, TRUE,  0, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_REL32",
	 FALSE, 0, 0xffffffff, TRUE),
  HOWTO (R_SPU_ADDR16X,    0, 2, 16, FALSE,  7, complain_overflow_bitfield,
	 bfd_elf_generic_reloc, "SPU_ADDR16X",
	 FALSE, 0, 0x007fff80, FALSE),
  HOWTO (R_SPU_PPU32,      0, 2, 32, FALSE,  0, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_PPU32",
	 FALSE, 0, 0xffffffff, FALSE),
  HOWTO (R_SPU_PPU64,      0, 4, 64, FALSE,  0, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_PPU64",
	 FALSE, 0, -1, FALSE),
  HOWTO (R_SPU_ADD_PIC,      0, 0, 0, FALSE,  0, complain_overflow_dont,
	 bfd_elf_generic_reloc, "SPU_ADD_PIC",
	 FALSE, 0, 0x00000000, FALSE),
};

static struct bfd_elf_special_section const spu_elf_special_sections[] = {
  { "._ea", 4, 0, SHT_PROGBITS, SHF_WRITE },
  { ".toe", 4, 0, SHT_NOBITS, SHF_ALLOC },
  { NULL, 0, 0, 0, 0 }
};

static enum elf_spu_reloc_type
spu_elf_bfd_to_reloc_type (bfd_reloc_code_real_type code)
{
  switch (code)
    {
    default:
      return R_SPU_NONE;
    case BFD_RELOC_SPU_IMM10W:
      return R_SPU_ADDR10;
    case BFD_RELOC_SPU_IMM16W:
      return R_SPU_ADDR16;
    case BFD_RELOC_SPU_LO16:
      return R_SPU_ADDR16_LO;
    case BFD_RELOC_SPU_HI16:
      return R_SPU_ADDR16_HI;
    case BFD_RELOC_SPU_IMM18:
      return R_SPU_ADDR18;
    case BFD_RELOC_SPU_PCREL16:
      return R_SPU_REL16;
    case BFD_RELOC_SPU_IMM7:
      return R_SPU_ADDR7;
    case BFD_RELOC_SPU_IMM8:
      return R_SPU_NONE;
    case BFD_RELOC_SPU_PCREL9a:
      return R_SPU_REL9;
    case BFD_RELOC_SPU_PCREL9b:
      return R_SPU_REL9I;
    case BFD_RELOC_SPU_IMM10:
      return R_SPU_ADDR10I;
    case BFD_RELOC_SPU_IMM16:
      return R_SPU_ADDR16I;
    case BFD_RELOC_32:
      return R_SPU_ADDR32;
    case BFD_RELOC_32_PCREL:
      return R_SPU_REL32;
    case BFD_RELOC_SPU_PPU32:
      return R_SPU_PPU32;
    case BFD_RELOC_SPU_PPU64:
      return R_SPU_PPU64;
    case BFD_RELOC_SPU_ADD_PIC:
      return R_SPU_ADD_PIC;
    }
}

static void
spu_elf_info_to_howto (bfd *abfd ATTRIBUTE_UNUSED,
		       arelent *cache_ptr,
		       Elf_Internal_Rela *dst)
{
  enum elf_spu_reloc_type r_type;

  r_type = (enum elf_spu_reloc_type) ELF32_R_TYPE (dst->r_info);
  BFD_ASSERT (r_type < R_SPU_max);
  cache_ptr->howto = &elf_howto_table[(int) r_type];
}

static reloc_howto_type *
spu_elf_reloc_type_lookup (bfd *abfd ATTRIBUTE_UNUSED,
			   bfd_reloc_code_real_type code)
{
  enum elf_spu_reloc_type r_type = spu_elf_bfd_to_reloc_type (code);

  if (r_type == R_SPU_NONE)
    return NULL;

  return elf_howto_table + r_type;
}

static reloc_howto_type *
spu_elf_reloc_name_lookup (bfd *abfd ATTRIBUTE_UNUSED,
			   const char *r_name)
{
  unsigned int i;

  for (i = 0; i < sizeof (elf_howto_table) / sizeof (elf_howto_table[0]); i++)
    if (elf_howto_table[i].name != NULL
	&& strcasecmp (elf_howto_table[i].name, r_name) == 0)
      return &elf_howto_table[i];

  return NULL;
}

/* Apply R_SPU_REL9 and R_SPU_REL9I relocs.  */

static bfd_reloc_status_type
spu_elf_rel9 (bfd *abfd, arelent *reloc_entry, asymbol *symbol,
	      void *data, asection *input_section,
	      bfd *output_bfd, char **error_message)
{
  bfd_size_type octets;
  bfd_vma val;
  long insn;

  /* If this is a relocatable link (output_bfd test tells us), just
     call the generic function.  Any adjustment will be done at final
     link time.  */
  if (output_bfd != NULL)
    return bfd_elf_generic_reloc (abfd, reloc_entry, symbol, data,
				  input_section, output_bfd, error_message);

  if (reloc_entry->address > bfd_get_section_limit (abfd, input_section))
    return bfd_reloc_outofrange;
  octets = reloc_entry->address * bfd_octets_per_byte (abfd);

  /* Get symbol value.  */
  val = 0;
  if (!bfd_is_com_section (symbol->section))
    val = symbol->value;
  if (symbol->section->output_section)
    val += symbol->section->output_section->vma;

  val += reloc_entry->addend;

  /* Make it pc-relative.  */
  val -= input_section->output_section->vma + input_section->output_offset;

  val >>= 2;
  if (val + 256 >= 512)
    return bfd_reloc_overflow;

  insn = bfd_get_32 (abfd, (bfd_byte *) data + octets);

  /* Move two high bits of value to REL9I and REL9 position.
     The mask will take care of selecting the right field.  */
  val = (val & 0x7f) | ((val & 0x180) << 7) | ((val & 0x180) << 16);
  insn &= ~reloc_entry->howto->dst_mask;
  insn |= val & reloc_entry->howto->dst_mask;
  bfd_put_32 (abfd, insn, (bfd_byte *) data + octets);
  return bfd_reloc_ok;
}

static bfd_boolean
spu_elf_new_section_hook (bfd *abfd, asection *sec)
{
  if (!sec->used_by_bfd)
    {
      struct _spu_elf_section_data *sdata;

      sdata = bfd_zalloc (abfd, sizeof (*sdata));
      if (sdata == NULL)
	return FALSE;
      sec->used_by_bfd = sdata;
    }

  return _bfd_elf_new_section_hook (abfd, sec);
}

/* Set up overlay info for executables.  */

static bfd_boolean
spu_elf_object_p (bfd *abfd)
{
  if ((abfd->flags & (EXEC_P | DYNAMIC)) != 0)
    {
      unsigned int i, num_ovl, num_buf;
      Elf_Internal_Phdr *phdr = elf_tdata (abfd)->phdr;
      Elf_Internal_Ehdr *ehdr = elf_elfheader (abfd);
      Elf_Internal_Phdr *last_phdr = NULL;

      for (num_buf = 0, num_ovl = 0, i = 0; i < ehdr->e_phnum; i++, phdr++)
	if (phdr->p_type == PT_LOAD && (phdr->p_flags & PF_OVERLAY) != 0)
	  {
	    unsigned int j;

	    ++num_ovl;
	    if (last_phdr == NULL
		|| ((last_phdr->p_vaddr ^ phdr->p_vaddr) & 0x3ffff) != 0)
	      ++num_buf;
	    last_phdr = phdr;
	    for (j = 1; j < elf_numsections (abfd); j++)
	      {
		Elf_Internal_Shdr *shdr = elf_elfsections (abfd)[j];

		if (ELF_SECTION_SIZE (shdr, phdr) != 0
		    && ELF_SECTION_IN_SEGMENT (shdr, phdr))
		  {
		    asection *sec = shdr->bfd_section;
		    spu_elf_section_data (sec)->u.o.ovl_index = num_ovl;
		    spu_elf_section_data (sec)->u.o.ovl_buf = num_buf;
		  }
	      }
	  }
    }
  return TRUE;
}

/* Specially mark defined symbols named _EAR_* with BSF_KEEP so that
   strip --strip-unneeded will not remove them.  */

static void
spu_elf_backend_symbol_processing (bfd *abfd ATTRIBUTE_UNUSED, asymbol *sym)
{
  if (sym->name != NULL
      && sym->section != bfd_abs_section_ptr
      && strncmp (sym->name, "_EAR_", 5) == 0)
    sym->flags |= BSF_KEEP;
}

/* SPU ELF linker hash table.  */

struct spu_link_hash_table
{
  struct elf_link_hash_table elf;

  struct spu_elf_params *params;

  /* Shortcuts to overlay sections.  */
  asection *ovtab;
  asection *init;
  asection *toe;
  asection **ovl_sec;

  /* Count of stubs in each overlay section.  */
  unsigned int *stub_count;

  /* The stub section for each overlay section.  */
  asection **stub_sec;

  struct elf_link_hash_entry *ovly_entry[2];

  /* Number of overlay buffers.  */
  unsigned int num_buf;

  /* Total number of overlays.  */
  unsigned int num_overlays;

  /* For soft icache.  */
  unsigned int line_size_log2;
  unsigned int num_lines_log2;
  unsigned int fromelem_size_log2;

  /* How much memory we have.  */
  unsigned int local_store;

  /* Count of overlay stubs needed in non-overlay area.  */
  unsigned int non_ovly_stub;

  /* Pointer to the fixup section */
  asection *sfixup;

  /* Set on error.  */
  unsigned int stub_err : 1;
};

/* Hijack the generic got fields for overlay stub accounting.  */

struct got_entry
{
  struct got_entry *next;
  unsigned int ovl;
  union {
    bfd_vma addend;
    bfd_vma br_addr;
  };
  bfd_vma stub_addr;
};

#define spu_hash_table(p) \
  (elf_hash_table_id ((struct elf_link_hash_table *) ((p)->hash)) \
  == SPU_ELF_DATA ? ((struct spu_link_hash_table *) ((p)->hash)) : NULL)

struct call_info
{
  struct function_info *fun;
  struct call_info *next;
  unsigned int count;
  unsigned int max_depth;
  unsigned int is_tail : 1;
  unsigned int is_pasted : 1;
  unsigned int broken_cycle : 1;
  unsigned int priority : 13;
};

struct function_info
{
  /* List of functions called.  Also branches to hot/cold part of
     function.  */
  struct call_info *call_list;
  /* For hot/cold part of function, point to owner.  */
  struct function_info *start;
  /* Symbol at start of function.  */
  union {
    Elf_Internal_Sym *sym;
    struct elf_link_hash_entry *h;
  } u;
  /* Function section.  */
  asection *sec;
  asection *rodata;
  /* Where last called from, and number of sections called from.  */
  asection *last_caller;
  unsigned int call_count;
  /* Address range of (this part of) function.  */
  bfd_vma lo, hi;
  /* Offset where we found a store of lr, or -1 if none found.  */
  bfd_vma lr_store;
  /* Offset where we found the stack adjustment insn.  */
  bfd_vma sp_adjust;
  /* Stack usage.  */
  int stack;
  /* Distance from root of call tree.  Tail and hot/cold branches
     count as one deeper.  We aren't counting stack frames here.  */
  unsigned int depth;
  /* Set if global symbol.  */
  unsigned int global : 1;
  /* Set if known to be start of function (as distinct from a hunk
     in hot/cold section.  */
  unsigned int is_func : 1;
  /* Set if not a root node.  */
  unsigned int non_root : 1;
  /* Flags used during call tree traversal.  It's cheaper to replicate
     the visit flags than have one which needs clearing after a traversal.  */
  unsigned int visit1 : 1;
  unsigned int visit2 : 1;
  unsigned int marking : 1;
  unsigned int visit3 : 1;
  unsigned int visit4 : 1;
  unsigned int visit5 : 1;
  unsigned int visit6 : 1;
  unsigned int visit7 : 1;
};

struct spu_elf_stack_info
{
  int num_fun;
  int max_fun;
  /* Variable size array describing functions, one per contiguous
     address range belonging to a function.  */
  struct function_info fun[1];
};

static struct function_info *find_function (asection *, bfd_vma,
					    struct bfd_link_info *);

/* Create a spu ELF linker hash table.  */

static struct bfd_link_hash_table *
spu_elf_link_hash_table_create (bfd *abfd)
{
  struct spu_link_hash_table *htab;

  htab = bfd_zmalloc (sizeof (*htab));
  if (htab == NULL)
    return NULL;

  if (!_bfd_elf_link_hash_table_init (&htab->elf, abfd,
				      _bfd_elf_link_hash_newfunc,
				      sizeof (struct elf_link_hash_entry),
				      SPU_ELF_DATA))
    {
      free (htab);
      return NULL;
    }

  htab->elf.init_got_refcount.refcount = 0;
  htab->elf.init_got_refcount.glist = NULL;
  htab->elf.init_got_offset.offset = 0;
  htab->elf.init_got_offset.glist = NULL;
  return &htab->elf.root;
}

void
spu_elf_setup (struct bfd_link_info *info, struct spu_elf_params *params)
{
  bfd_vma max_branch_log2;

  struct spu_link_hash_table *htab = spu_hash_table (info);
  htab->params = params;
  htab->line_size_log2 = bfd_log2 (htab->params->line_size);
  htab->num_lines_log2 = bfd_log2 (htab->params->num_lines);

  /* For the software i-cache, we provide a "from" list whose size
     is a power-of-two number of quadwords, big enough to hold one
     byte per outgoing branch.  Compute this number here.  */
  max_branch_log2 = bfd_log2 (htab->params->max_branch);
  htab->fromelem_size_log2 = max_branch_log2 > 4 ? max_branch_log2 - 4 : 0;
}

/* Find the symbol for the given R_SYMNDX in IBFD and set *HP and *SYMP
   to (hash, NULL) for global symbols, and (NULL, sym) for locals.  Set
   *SYMSECP to the symbol's section.  *LOCSYMSP caches local syms.  */

static bfd_boolean
get_sym_h (struct elf_link_hash_entry **hp,
	   Elf_Internal_Sym **symp,
	   asection **symsecp,
	   Elf_Internal_Sym **locsymsp,
	   unsigned long r_symndx,
	   bfd *ibfd)
{
  Elf_Internal_Shdr *symtab_hdr = &elf_tdata (ibfd)->symtab_hdr;

  if (r_symndx >= symtab_hdr->sh_info)
    {
      struct elf_link_hash_entry **sym_hashes = elf_sym_hashes (ibfd);
      struct elf_link_hash_entry *h;

      h = sym_hashes[r_symndx - symtab_hdr->sh_info];
      while (h->root.type == bfd_link_hash_indirect
	     || h->root.type == bfd_link_hash_warning)
	h = (struct elf_link_hash_entry *) h->root.u.i.link;

      if (hp != NULL)
	*hp = h;

      if (symp != NULL)
	*symp = NULL;

      if (symsecp != NULL)
	{
	  asection *symsec = NULL;
	  if (h->root.type == bfd_link_hash_defined
	      || h->root.type == bfd_link_hash_defweak)
	    symsec = h->root.u.def.section;
	  *symsecp = symsec;
	}
    }
  else
    {
      Elf_Internal_Sym *sym;
      Elf_Internal_Sym *locsyms = *locsymsp;

      if (locsyms == NULL)
	{
	  locsyms = (Elf_Internal_Sym *) symtab_hdr->contents;
	  if (locsyms == NULL)
	    locsyms = bfd_elf_get_elf_syms (ibfd, symtab_hdr,
					    symtab_hdr->sh_info,
					    0, NULL, NULL, NULL);
	  if (locsyms == NULL)
	    return FALSE;
	  *locsymsp = locsyms;
	}
      sym = locsyms + r_symndx;

      if (hp != NULL)
	*hp = NULL;

      if (symp != NULL)
	*symp = sym;

      if (symsecp != NULL)
	*symsecp = bfd_section_from_elf_index (ibfd, sym->st_shndx);
    }

  return TRUE;
}

/* Create the note section if not already present.  This is done early so
   that the linker maps the sections to the right place in the output.  */

bfd_boolean
spu_elf_create_sections (struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  bfd *ibfd;

  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    if (bfd_get_section_by_name (ibfd, SPU_PTNOTE_SPUNAME) != NULL)
      break;

  if (ibfd == NULL)
    {
      /* Make SPU_PTNOTE_SPUNAME section.  */
      asection *s;
      size_t name_len;
      size_t size;
      bfd_byte *data;
      flagword flags;

      ibfd = info->input_bfds;
      flags = SEC_LOAD | SEC_READONLY | SEC_HAS_CONTENTS | SEC_IN_MEMORY;
      s = bfd_make_section_anyway_with_flags (ibfd, SPU_PTNOTE_SPUNAME, flags);
      if (s == NULL
	  || !bfd_set_section_alignment (ibfd, s, 4))
	return FALSE;

      name_len = strlen (bfd_get_filename (info->output_bfd)) + 1;
      size = 12 + ((sizeof (SPU_PLUGIN_NAME) + 3) & -4);
      size += (name_len + 3) & -4;

      if (!bfd_set_section_size (ibfd, s, size))
	return FALSE;

      data = bfd_zalloc (ibfd, size);
      if (data == NULL)
	return FALSE;

      bfd_put_32 (ibfd, sizeof (SPU_PLUGIN_NAME), data + 0);
      bfd_put_32 (ibfd, name_len, data + 4);
      bfd_put_32 (ibfd, 1, data + 8);
      memcpy (data + 12, SPU_PLUGIN_NAME, sizeof (SPU_PLUGIN_NAME));
      memcpy (data + 12 + ((sizeof (SPU_PLUGIN_NAME) + 3) & -4),
	      bfd_get_filename (info->output_bfd), name_len);
      s->contents = data;
    }

  if (htab->params->emit_fixups)
    {
      asection *s;
      flagword flags;

      if (htab->elf.dynobj == NULL)
	htab->elf.dynobj = ibfd;
      ibfd = htab->elf.dynobj;
      flags = (SEC_LOAD | SEC_ALLOC | SEC_READONLY | SEC_HAS_CONTENTS
	       | SEC_IN_MEMORY | SEC_LINKER_CREATED);
      s = bfd_make_section_anyway_with_flags (ibfd, ".fixup", flags);
      if (s == NULL || !bfd_set_section_alignment (ibfd, s, 2))
	return FALSE;
      htab->sfixup = s;
    }

  return TRUE;
}

/* qsort predicate to sort sections by vma.  */

static int
sort_sections (const void *a, const void *b)
{
  const asection *const *s1 = a;
  const asection *const *s2 = b;
  bfd_signed_vma delta = (*s1)->vma - (*s2)->vma;

  if (delta != 0)
    return delta < 0 ? -1 : 1;

  return (*s1)->index - (*s2)->index;
}

/* Identify overlays in the output bfd, and number them.
   Returns 0 on error, 1 if no overlays, 2 if overlays.  */

int
spu_elf_find_overlays (struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  asection **alloc_sec;
  unsigned int i, n, ovl_index, num_buf;
  asection *s;
  bfd_vma ovl_end;
  static const char *const entry_names[2][2] = {
    { "__ovly_load", "__icache_br_handler" },
    { "__ovly_return", "__icache_call_handler" }
  };

  if (info->output_bfd->section_count < 2)
    return 1;

  alloc_sec
    = bfd_malloc (info->output_bfd->section_count * sizeof (*alloc_sec));
  if (alloc_sec == NULL)
    return 0;

  /* Pick out all the alloced sections.  */
  for (n = 0, s = info->output_bfd->sections; s != NULL; s = s->next)
    if ((s->flags & SEC_ALLOC) != 0
	&& (s->flags & (SEC_LOAD | SEC_THREAD_LOCAL)) != SEC_THREAD_LOCAL
	&& s->size != 0)
      alloc_sec[n++] = s;

  if (n == 0)
    {
      free (alloc_sec);
      return 1;
    }

  /* Sort them by vma.  */
  qsort (alloc_sec, n, sizeof (*alloc_sec), sort_sections);

  ovl_end = alloc_sec[0]->vma + alloc_sec[0]->size;
  if (htab->params->ovly_flavour == ovly_soft_icache)
    {
      unsigned int prev_buf = 0, set_id = 0;

      /* Look for an overlapping vma to find the first overlay section.  */
      bfd_vma vma_start = 0;

      for (i = 1; i < n; i++)
	{
	  s = alloc_sec[i];
	  if (s->vma < ovl_end)
	    {
	      asection *s0 = alloc_sec[i - 1];
	      vma_start = s0->vma;
	      ovl_end = (s0->vma
			 + ((bfd_vma) 1
			    << (htab->num_lines_log2 + htab->line_size_log2)));
	      --i;
	      break;
	    }
	  else
	    ovl_end = s->vma + s->size;
	}

      /* Now find any sections within the cache area.  */
      for (ovl_index = 0, num_buf = 0; i < n; i++)
	{
	  s = alloc_sec[i];
	  if (s->vma >= ovl_end)
	    break;

	  /* A section in an overlay area called .ovl.init is not
	     an overlay, in the sense that it might be loaded in
	     by the overlay manager, but rather the initial
	     section contents for the overlay buffer.  */
	  if (strncmp (s->name, ".ovl.init", 9) != 0)
	    {
	      num_buf = ((s->vma - vma_start) >> htab->line_size_log2) + 1;
	      set_id = (num_buf == prev_buf)? set_id + 1 : 0;
	      prev_buf = num_buf;

	      if ((s->vma - vma_start) & (htab->params->line_size - 1))
		{
		  info->callbacks->einfo (_("%X%P: overlay section %A "
					    "does not start on a cache line.\n"),
					  s);
		  bfd_set_error (bfd_error_bad_value);
		  return 0;
		}
	      else if (s->size > htab->params->line_size)
		{
		  info->callbacks->einfo (_("%X%P: overlay section %A "
					    "is larger than a cache line.\n"),
					  s);
		  bfd_set_error (bfd_error_bad_value);
		  return 0;
		}

	      alloc_sec[ovl_index++] = s;
	      spu_elf_section_data (s)->u.o.ovl_index
		= (set_id << htab->num_lines_log2) + num_buf;
	      spu_elf_section_data (s)->u.o.ovl_buf = num_buf;
	    }
	}

      /* Ensure there are no more overlay sections.  */
      for ( ; i < n; i++)
	{
	  s = alloc_sec[i];
	  if (s->vma < ovl_end)
	    {
	      info->callbacks->einfo (_("%X%P: overlay section %A "
					"is not in cache area.\n"),
				      alloc_sec[i-1]);
	      bfd_set_error (bfd_error_bad_value);
	      return 0;
	    }
	  else
	    ovl_end = s->vma + s->size;
	}
    }
  else
    {
      /* Look for overlapping vmas.  Any with overlap must be overlays.
	 Count them.  Also count the number of overlay regions.  */
      for (ovl_index = 0, num_buf = 0, i = 1; i < n; i++)
	{
	  s = alloc_sec[i];
	  if (s->vma < ovl_end)
	    {
	      asection *s0 = alloc_sec[i - 1];

	      if (spu_elf_section_data (s0)->u.o.ovl_index == 0)
		{
		  ++num_buf;
		  if (strncmp (s0->name, ".ovl.init", 9) != 0)
		    {
		      alloc_sec[ovl_index] = s0;
		      spu_elf_section_data (s0)->u.o.ovl_index = ++ovl_index;
		      spu_elf_section_data (s0)->u.o.ovl_buf = num_buf;
		    }
		  else
		    ovl_end = s->vma + s->size;
		}
	      if (strncmp (s->name, ".ovl.init", 9) != 0)
		{
		  alloc_sec[ovl_index] = s;
		  spu_elf_section_data (s)->u.o.ovl_index = ++ovl_index;
		  spu_elf_section_data (s)->u.o.ovl_buf = num_buf;
		  if (s0->vma != s->vma)
		    {
		      info->callbacks->einfo (_("%X%P: overlay sections %A "
						"and %A do not start at the "
						"same address.\n"),
					      s0, s);
		      bfd_set_error (bfd_error_bad_value);
		      return 0;
		    }
		  if (ovl_end < s->vma + s->size)
		    ovl_end = s->vma + s->size;
		}
	    }
	  else
	    ovl_end = s->vma + s->size;
	}
    }

  htab->num_overlays = ovl_index;
  htab->num_buf = num_buf;
  htab->ovl_sec = alloc_sec;

  if (ovl_index == 0)
    return 1;

  for (i = 0; i < 2; i++)
    {
      const char *name;
      struct elf_link_hash_entry *h;

      name = entry_names[i][htab->params->ovly_flavour];
      h = elf_link_hash_lookup (&htab->elf, name, TRUE, FALSE, FALSE);
      if (h == NULL)
	return 0;

      if (h->root.type == bfd_link_hash_new)
	{
	  h->root.type = bfd_link_hash_undefined;
	  h->ref_regular = 1;
	  h->ref_regular_nonweak = 1;
	  h->non_elf = 0;
	}
      htab->ovly_entry[i] = h;
    }

  return 2;
}

/* Non-zero to use bra in overlay stubs rather than br.  */
#define BRA_STUBS 0

#define BRA	0x30000000
#define BRASL	0x31000000
#define BR	0x32000000
#define BRSL	0x33000000
#define NOP	0x40200000
#define LNOP	0x00200000
#define ILA	0x42000000

/* Return true for all relative and absolute branch instructions.
   bra   00110000 0..
   brasl 00110001 0..
   br    00110010 0..
   brsl  00110011 0..
   brz   00100000 0..
   brnz  00100001 0..
   brhz  00100010 0..
   brhnz 00100011 0..  */

static bfd_boolean
is_branch (const unsigned char *insn)
{
  return (insn[0] & 0xec) == 0x20 && (insn[1] & 0x80) == 0;
}

/* Return true for all indirect branch instructions.
   bi     00110101 000
   bisl   00110101 001
   iret   00110101 010
   bisled 00110101 011
   biz    00100101 000
   binz   00100101 001
   bihz   00100101 010
   bihnz  00100101 011  */

static bfd_boolean
is_indirect_branch (const unsigned char *insn)
{
  return (insn[0] & 0xef) == 0x25 && (insn[1] & 0x80) == 0;
}

/* Return true for branch hint instructions.
   hbra  0001000..
   hbrr  0001001..  */

static bfd_boolean
is_hint (const unsigned char *insn)
{
  return (insn[0] & 0xfc) == 0x10;
}

/* True if INPUT_SECTION might need overlay stubs.  */

static bfd_boolean
maybe_needs_stubs (asection *input_section)
{
  /* No stubs for debug sections and suchlike.  */
  if ((input_section->flags & SEC_ALLOC) == 0)
    return FALSE;

  /* No stubs for link-once sections that will be discarded.  */
  if (input_section->output_section == bfd_abs_section_ptr)
    return FALSE;

  /* Don't create stubs for .eh_frame references.  */
  if (strcmp (input_section->name, ".eh_frame") == 0)
    return FALSE;

  return TRUE;
}

enum _stub_type
{
  no_stub,
  call_ovl_stub,
  br000_ovl_stub,
  br001_ovl_stub,
  br010_ovl_stub,
  br011_ovl_stub,
  br100_ovl_stub,
  br101_ovl_stub,
  br110_ovl_stub,
  br111_ovl_stub,
  nonovl_stub,
  stub_error
};

/* Return non-zero if this reloc symbol should go via an overlay stub.
   Return 2 if the stub must be in non-overlay area.  */

static enum _stub_type
needs_ovl_stub (struct elf_link_hash_entry *h,
		Elf_Internal_Sym *sym,
		asection *sym_sec,
		asection *input_section,
		Elf_Internal_Rela *irela,
		bfd_byte *contents,
		struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  enum elf_spu_reloc_type r_type;
  unsigned int sym_type;
  bfd_boolean branch, hint, call;
  enum _stub_type ret = no_stub;
  bfd_byte insn[4];

  if (sym_sec == NULL
      || sym_sec->output_section == bfd_abs_section_ptr
      || spu_elf_section_data (sym_sec->output_section) == NULL)
    return ret;

  if (h != NULL)
    {
      /* Ensure no stubs for user supplied overlay manager syms.  */
      if (h == htab->ovly_entry[0] || h == htab->ovly_entry[1])
	return ret;

      /* setjmp always goes via an overlay stub, because then the return
	 and hence the longjmp goes via __ovly_return.  That magically
	 makes setjmp/longjmp between overlays work.  */
      if (strncmp (h->root.root.string, "setjmp", 6) == 0
	  && (h->root.root.string[6] == '\0' || h->root.root.string[6] == '@@'))
	ret = call_ovl_stub;
    }

  if (h != NULL)
    sym_type = h->type;
  else
    sym_type = ELF_ST_TYPE (sym->st_info);

  r_type = ELF32_R_TYPE (irela->r_info);
  branch = FALSE;
  hint = FALSE;
  call = FALSE;
  if (r_type == R_SPU_REL16 || r_type == R_SPU_ADDR16)
    {
      if (contents == NULL)
	{
	  contents = insn;
	  if (!bfd_get_section_contents (input_section->owner,
					 input_section,
					 contents,
					 irela->r_offset, 4))
	    return stub_error;
	}
      else
	contents += irela->r_offset;

      branch = is_branch (contents);
      hint = is_hint (contents);
      if (branch || hint)
	{
	  call = (contents[0] & 0xfd) == 0x31;
	  if (call
	      && sym_type != STT_FUNC
	      && contents != insn)
	    {
	      /* It's common for people to write assembly and forget
		 to give function symbols the right type.  Handle
		 calls to such symbols, but warn so that (hopefully)
		 people will fix their code.  We need the symbol
		 type to be correct to distinguish function pointer
		 initialisation from other pointer initialisations.  */
	      const char *sym_name;

	      if (h != NULL)
		sym_name = h->root.root.string;
	      else
		{
		  Elf_Internal_Shdr *symtab_hdr;
		  symtab_hdr = &elf_tdata (input_section->owner)->symtab_hdr;
		  sym_name = bfd_elf_sym_name (input_section->owner,
					       symtab_hdr,
					       sym,
					       sym_sec);
		}
	      (*_bfd_error_handler) (_("warning: call to non-function"
				       " symbol %s defined in %B"),
				     sym_sec->owner, sym_name);

	    }
	}
    }

  if ((!branch && htab->params->ovly_flavour == ovly_soft_icache)
      || (sym_type != STT_FUNC
	  && !(branch || hint)
	  && (sym_sec->flags & SEC_CODE) == 0))
    return no_stub;

  /* Usually, symbols in non-overlay sections don't need stubs.  */
  if (spu_elf_section_data (sym_sec->output_section)->u.o.ovl_index == 0
      && !htab->params->non_overlay_stubs)
    return ret;

  /* A reference from some other section to a symbol in an overlay
     section needs a stub.  */
  if (spu_elf_section_data (sym_sec->output_section)->u.o.ovl_index
       != spu_elf_section_data (input_section->output_section)->u.o.ovl_index)
    {
      unsigned int lrlive = 0;
      if (branch)
	lrlive = (contents[1] & 0x70) >> 4;

      if (!lrlive && (call || sym_type == STT_FUNC))
	ret = call_ovl_stub;
      else
	ret = br000_ovl_stub + lrlive;
    }

  /* If this insn isn't a branch then we are possibly taking the
     address of a function and passing it out somehow.  Soft-icache code
     always generates inline code to do indirect branches.  */
  if (!(branch || hint)
      && sym_type == STT_FUNC
      && htab->params->ovly_flavour != ovly_soft_icache)
    ret = nonovl_stub;

  return ret;
}

static bfd_boolean
count_stub (struct spu_link_hash_table *htab,
	    bfd *ibfd,
	    asection *isec,
	    enum _stub_type stub_type,
	    struct elf_link_hash_entry *h,
	    const Elf_Internal_Rela *irela)
{
  unsigned int ovl = 0;
  struct got_entry *g, **head;
  bfd_vma addend;

  /* If this instruction is a branch or call, we need a stub
     for it.  One stub per function per overlay.
     If it isn't a branch, then we are taking the address of
     this function so need a stub in the non-overlay area
     for it.  One stub per function.  */
  if (stub_type != nonovl_stub)
    ovl = spu_elf_section_data (isec->output_section)->u.o.ovl_index;

  if (h != NULL)
    head = &h->got.glist;
  else
    {
      if (elf_local_got_ents (ibfd) == NULL)
	{
	  bfd_size_type amt = (elf_tdata (ibfd)->symtab_hdr.sh_info
			       * sizeof (*elf_local_got_ents (ibfd)));
	  elf_local_got_ents (ibfd) = bfd_zmalloc (amt);
	  if (elf_local_got_ents (ibfd) == NULL)
	    return FALSE;
	}
      head = elf_local_got_ents (ibfd) + ELF32_R_SYM (irela->r_info);
    }

  if (htab->params->ovly_flavour == ovly_soft_icache)
    {
      htab->stub_count[ovl] += 1;
      return TRUE;
    }

  addend = 0;
  if (irela != NULL)
    addend = irela->r_addend;

  if (ovl == 0)
    {
      struct got_entry *gnext;

      for (g = *head; g != NULL; g = g->next)
	if (g->addend == addend && g->ovl == 0)
	  break;

      if (g == NULL)
	{
	  /* Need a new non-overlay area stub.  Zap other stubs.  */
	  for (g = *head; g != NULL; g = gnext)
	    {
	      gnext = g->next;
	      if (g->addend == addend)
		{
		  htab->stub_count[g->ovl] -= 1;
		  free (g);
		}
	    }
	}
    }
  else
    {
      for (g = *head; g != NULL; g = g->next)
	if (g->addend == addend && (g->ovl == ovl || g->ovl == 0))
	  break;
    }

  if (g == NULL)
    {
      g = bfd_malloc (sizeof *g);
      if (g == NULL)
	return FALSE;
      g->ovl = ovl;
      g->addend = addend;
      g->stub_addr = (bfd_vma) -1;
      g->next = *head;
      *head = g;

      htab->stub_count[ovl] += 1;
    }

  return TRUE;
}

/* Support two sizes of overlay stubs, a slower more compact stub of two
   instructions, and a faster stub of four instructions.
   Soft-icache stubs are four or eight words.  */

static unsigned int
ovl_stub_size (struct spu_elf_params *params)
{
  return 16 << params->ovly_flavour >> params->compact_stub;
}

static unsigned int
ovl_stub_size_log2 (struct spu_elf_params *params)
{
  return 4 + params->ovly_flavour - params->compact_stub;
}

/* Two instruction overlay stubs look like:

   brsl $75,__ovly_load
   .word target_ovl_and_address

   ovl_and_address is a word with the overlay number in the top 14 bits
   and local store address in the bottom 18 bits.

   Four instruction overlay stubs look like:

   ila $78,ovl_number
   lnop
   ila $79,target_address
   br __ovly_load

   Software icache stubs are:

   .word target_index
   .word target_ia;
   .word lrlive_branchlocalstoreaddr;
   brasl $75,__icache_br_handler
   .quad xor_pattern
*/

static bfd_boolean
build_stub (struct bfd_link_info *info,
	    bfd *ibfd,
	    asection *isec,
	    enum _stub_type stub_type,
	    struct elf_link_hash_entry *h,
	    const Elf_Internal_Rela *irela,
	    bfd_vma dest,
	    asection *dest_sec)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  unsigned int ovl, dest_ovl, set_id;
  struct got_entry *g, **head;
  asection *sec;
  bfd_vma addend, from, to, br_dest, patt;
  unsigned int lrlive;

  ovl = 0;
  if (stub_type != nonovl_stub)
    ovl = spu_elf_section_data (isec->output_section)->u.o.ovl_index;

  if (h != NULL)
    head = &h->got.glist;
  else
    head = elf_local_got_ents (ibfd) + ELF32_R_SYM (irela->r_info);

  addend = 0;
  if (irela != NULL)
    addend = irela->r_addend;

  if (htab->params->ovly_flavour == ovly_soft_icache)
    {
      g = bfd_malloc (sizeof *g);
      if (g == NULL)
	return FALSE;
      g->ovl = ovl;
      g->br_addr = 0;
      if (irela != NULL)
	g->br_addr = (irela->r_offset
		      + isec->output_offset
		      + isec->output_section->vma);
      g->next = *head;
      *head = g;
    }
  else
    {
      for (g = *head; g != NULL; g = g->next)
	if (g->addend == addend && (g->ovl == ovl || g->ovl == 0))
	  break;
      if (g == NULL)
	abort ();

      if (g->ovl == 0 && ovl != 0)
	return TRUE;

      if (g->stub_addr != (bfd_vma) -1)
	return TRUE;
    }

  sec = htab->stub_sec[ovl];
  dest += dest_sec->output_offset + dest_sec->output_section->vma;
  from = sec->size + sec->output_offset + sec->output_section->vma;
  g->stub_addr = from;
  to = (htab->ovly_entry[0]->root.u.def.value
	+ htab->ovly_entry[0]->root.u.def.section->output_offset
	+ htab->ovly_entry[0]->root.u.def.section->output_section->vma);

  if (((dest | to | from) & 3) != 0)
    {
      htab->stub_err = 1;
      return FALSE;
    }
  dest_ovl = spu_elf_section_data (dest_sec->output_section)->u.o.ovl_index;

  if (htab->params->ovly_flavour == ovly_normal
      && !htab->params->compact_stub)
    {
      bfd_put_32 (sec->owner, ILA + ((dest_ovl << 7) & 0x01ffff80) + 78,
		  sec->contents + sec->size);
      bfd_put_32 (sec->owner, LNOP,
		  sec->contents + sec->size + 4);
      bfd_put_32 (sec->owner, ILA + ((dest << 7) & 0x01ffff80) + 79,
		  sec->contents + sec->size + 8);
      if (!BRA_STUBS)
	bfd_put_32 (sec->owner, BR + (((to - (from + 12)) << 5) & 0x007fff80),
		    sec->contents + sec->size + 12);
      else
	bfd_put_32 (sec->owner, BRA + ((to << 5) & 0x007fff80),
		    sec->contents + sec->size + 12);
    }
  else if (htab->params->ovly_flavour == ovly_normal
	   && htab->params->compact_stub)
    {
      if (!BRA_STUBS)
	bfd_put_32 (sec->owner, BRSL + (((to - from) << 5) & 0x007fff80) + 75,
		    sec->contents + sec->size);
      else
	bfd_put_32 (sec->owner, BRASL + ((to << 5) & 0x007fff80) + 75,
		    sec->contents + sec->size);
      bfd_put_32 (sec->owner, (dest & 0x3ffff) | (dest_ovl << 18),
		  sec->contents + sec->size + 4);
    }
  else if (htab->params->ovly_flavour == ovly_soft_icache
	   && htab->params->compact_stub)
    {
      lrlive = 0;
      if (stub_type == nonovl_stub)
	;
      else if (stub_type == call_ovl_stub)
	/* A brsl makes lr live and *(*sp+16) is live.
	   Tail calls have the same liveness.  */
	lrlive = 5;
      else if (!htab->params->lrlive_analysis)
	/* Assume stack frame and lr save.  */
	lrlive = 1;
      else if (irela != NULL)
	{
	  /* Analyse branch instructions.  */
	  struct function_info *caller;
	  bfd_vma off;

	  caller = find_function (isec, irela->r_offset, info);
	  if (caller->start == NULL)
	    off = irela->r_offset;
	  else
	    {
	      struct function_info *found = NULL;

	      /* Find the earliest piece of this function that
		 has frame adjusting instructions.  We might
		 see dynamic frame adjustment (eg. for alloca)
		 in some later piece, but functions using
		 alloca always set up a frame earlier.  Frame
		 setup instructions are always in one piece.  */
	      if (caller->lr_store != (bfd_vma) -1
		  || caller->sp_adjust != (bfd_vma) -1)
		found = caller;
	      while (caller->start != NULL)
		{
		  caller = caller->start;
		  if (caller->lr_store != (bfd_vma) -1
		      || caller->sp_adjust != (bfd_vma) -1)
		    found = caller;
		}
	      if (found != NULL)
		caller = found;
	      off = (bfd_vma) -1;
	    }

	  if (off > caller->sp_adjust)
	    {
	      if (off > caller->lr_store)
		/* Only *(*sp+16) is live.  */
		lrlive = 1;
	      else
		/* If no lr save, then we must be in a
		   leaf function with a frame.
		   lr is still live.  */
		lrlive = 4;
	    }
	  else if (off > caller->lr_store)
	    {
	      /* Between lr save and stack adjust.  */
	      lrlive = 3;
	      /* This should never happen since prologues won't
		 be split here.  */
	      BFD_ASSERT (0);
	    }
	  else
	    /* On entry to function.  */
	    lrlive = 5;

	  if (stub_type != br000_ovl_stub
	      && lrlive != stub_type - br000_ovl_stub)
	    info->callbacks->einfo (_("%A:0x%v lrlive .brinfo (%u) differs "
				      "from analysis (%u)\n"),
				    isec, irela->r_offset, lrlive,
				    stub_type - br000_ovl_stub);
	}

      /* If given lrlive info via .brinfo, use it.  */
      if (stub_type > br000_ovl_stub)
	lrlive = stub_type - br000_ovl_stub;

      if (ovl == 0)
	to = (htab->ovly_entry[1]->root.u.def.value
	      + htab->ovly_entry[1]->root.u.def.section->output_offset
	      + htab->ovly_entry[1]->root.u.def.section->output_section->vma);

      /* The branch that uses this stub goes to stub_addr + 4.  We'll
	 set up an xor pattern that can be used by the icache manager
	 to modify this branch to go directly to its destination.  */
      g->stub_addr += 4;
      br_dest = g->stub_addr;
      if (irela == NULL)
	{
	  /* Except in the case of _SPUEAR_ stubs, the branch in
	     question is the one in the stub itself.  */
	  BFD_ASSERT (stub_type == nonovl_stub);
	  g->br_addr = g->stub_addr;
	  br_dest = to;
	}

      set_id = ((dest_ovl - 1) >> htab->num_lines_log2) + 1;
      bfd_put_32 (sec->owner, (set_id << 18) | (dest & 0x3ffff),
		  sec->contents + sec->size);
      bfd_put_32 (sec->owner, BRASL + ((to << 5) & 0x007fff80) + 75,
		  sec->contents + sec->size + 4);
      bfd_put_32 (sec->owner, (lrlive << 29) | (g->br_addr & 0x3ffff),
		  sec->contents + sec->size + 8);
      patt = dest ^ br_dest;
      if (irela != NULL && ELF32_R_TYPE (irela->r_info) == R_SPU_REL16)
	patt = (dest - g->br_addr) ^ (br_dest - g->br_addr);
      bfd_put_32 (sec->owner, (patt << 5) & 0x007fff80,
		  sec->contents + sec->size + 12);

      if (ovl == 0)
	/* Extra space for linked list entries.  */
	sec->size += 16;
    }
  else
    abort ();

  sec->size += ovl_stub_size (htab->params);

  if (htab->params->emit_stub_syms)
    {
      size_t len;
      char *name;
      int add;

      len = 8 + sizeof (".ovl_call.") - 1;
      if (h != NULL)
	len += strlen (h->root.root.string);
      else
	len += 8 + 1 + 8;
      add = 0;
      if (irela != NULL)
	add = (int) irela->r_addend & 0xffffffff;
      if (add != 0)
	len += 1 + 8;
      name = bfd_malloc (len + 1);
      if (name == NULL)
	return FALSE;

      sprintf (name, "%08x.ovl_call.", g->ovl);
      if (h != NULL)
	strcpy (name + 8 + sizeof (".ovl_call.") - 1, h->root.root.string);
      else
	sprintf (name + 8 + sizeof (".ovl_call.") - 1, "%x:%x",
		 dest_sec->id & 0xffffffff,
		 (int) ELF32_R_SYM (irela->r_info) & 0xffffffff);
      if (add != 0)
	sprintf (name + len - 9, "+%x", add);

      h = elf_link_hash_lookup (&htab->elf, name, TRUE, TRUE, FALSE);
      free (name);
      if (h == NULL)
	return FALSE;
      if (h->root.type == bfd_link_hash_new)
	{
	  h->root.type = bfd_link_hash_defined;
	  h->root.u.def.section = sec;
	  h->size = ovl_stub_size (htab->params);
	  h->root.u.def.value = sec->size - h->size;
	  h->type = STT_FUNC;
	  h->ref_regular = 1;
	  h->def_regular = 1;
	  h->ref_regular_nonweak = 1;
	  h->forced_local = 1;
	  h->non_elf = 0;
	}
    }

  return TRUE;
}

/* Called via elf_link_hash_traverse to allocate stubs for any _SPUEAR_
   symbols.  */

static bfd_boolean
allocate_spuear_stubs (struct elf_link_hash_entry *h, void *inf)
{
  /* Symbols starting with _SPUEAR_ need a stub because they may be
     invoked by the PPU.  */
  struct bfd_link_info *info = inf;
  struct spu_link_hash_table *htab = spu_hash_table (info);
  asection *sym_sec;

  if ((h->root.type == bfd_link_hash_defined
       || h->root.type == bfd_link_hash_defweak)
      && h->def_regular
      && strncmp (h->root.root.string, "_SPUEAR_", 8) == 0
      && (sym_sec = h->root.u.def.section) != NULL
      && sym_sec->output_section != bfd_abs_section_ptr
      && spu_elf_section_data (sym_sec->output_section) != NULL
      && (spu_elf_section_data (sym_sec->output_section)->u.o.ovl_index != 0
	  || htab->params->non_overlay_stubs))
    {
      return count_stub (htab, NULL, NULL, nonovl_stub, h, NULL);
    }

  return TRUE;
}

static bfd_boolean
build_spuear_stubs (struct elf_link_hash_entry *h, void *inf)
{
  /* Symbols starting with _SPUEAR_ need a stub because they may be
     invoked by the PPU.  */
  struct bfd_link_info *info = inf;
  struct spu_link_hash_table *htab = spu_hash_table (info);
  asection *sym_sec;

  if ((h->root.type == bfd_link_hash_defined
       || h->root.type == bfd_link_hash_defweak)
      && h->def_regular
      && strncmp (h->root.root.string, "_SPUEAR_", 8) == 0
      && (sym_sec = h->root.u.def.section) != NULL
      && sym_sec->output_section != bfd_abs_section_ptr
      && spu_elf_section_data (sym_sec->output_section) != NULL
      && (spu_elf_section_data (sym_sec->output_section)->u.o.ovl_index != 0
	  || htab->params->non_overlay_stubs))
    {
      return build_stub (info, NULL, NULL, nonovl_stub, h, NULL,
			 h->root.u.def.value, sym_sec);
    }

  return TRUE;
}

/* Size or build stubs.  */

static bfd_boolean
process_stubs (struct bfd_link_info *info, bfd_boolean build)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  bfd *ibfd;

  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      Elf_Internal_Shdr *symtab_hdr;
      asection *isec;
      Elf_Internal_Sym *local_syms = NULL;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      /* We'll need the symbol table in a second.  */
      symtab_hdr = &elf_tdata (ibfd)->symtab_hdr;
      if (symtab_hdr->sh_info == 0)
	continue;

      /* Walk over each section attached to the input bfd.  */
      for (isec = ibfd->sections; isec != NULL; isec = isec->next)
	{
	  Elf_Internal_Rela *internal_relocs, *irelaend, *irela;

	  /* If there aren't any relocs, then there's nothing more to do.  */
	  if ((isec->flags & SEC_RELOC) == 0
	      || isec->reloc_count == 0)
	    continue;

	  if (!maybe_needs_stubs (isec))
	    continue;

	  /* Get the relocs.  */
	  internal_relocs = _bfd_elf_link_read_relocs (ibfd, isec, NULL, NULL,
						       info->keep_memory);
	  if (internal_relocs == NULL)
	    goto error_ret_free_local;

	  /* Now examine each relocation.  */
	  irela = internal_relocs;
	  irelaend = irela + isec->reloc_count;
	  for (; irela < irelaend; irela++)
	    {
	      enum elf_spu_reloc_type r_type;
	      unsigned int r_indx;
	      asection *sym_sec;
	      Elf_Internal_Sym *sym;
	      struct elf_link_hash_entry *h;
	      enum _stub_type stub_type;

	      r_type = ELF32_R_TYPE (irela->r_info);
	      r_indx = ELF32_R_SYM (irela->r_info);

	      if (r_type >= R_SPU_max)
		{
		  bfd_set_error (bfd_error_bad_value);
		error_ret_free_internal:
		  if (elf_section_data (isec)->relocs != internal_relocs)
		    free (internal_relocs);
		error_ret_free_local:
		  if (local_syms != NULL
		      && (symtab_hdr->contents
			  != (unsigned char *) local_syms))
		    free (local_syms);
		  return FALSE;
		}

	      /* Determine the reloc target section.  */
	      if (!get_sym_h (&h, &sym, &sym_sec, &local_syms, r_indx, ibfd))
		goto error_ret_free_internal;

	      stub_type = needs_ovl_stub (h, sym, sym_sec, isec, irela,
					  NULL, info);
	      if (stub_type == no_stub)
		continue;
	      else if (stub_type == stub_error)
		goto error_ret_free_internal;

	      if (htab->stub_count == NULL)
		{
		  bfd_size_type amt;
		  amt = (htab->num_overlays + 1) * sizeof (*htab->stub_count);
		  htab->stub_count = bfd_zmalloc (amt);
		  if (htab->stub_count == NULL)
		    goto error_ret_free_internal;
		}

	      if (!build)
		{
		  if (!count_stub (htab, ibfd, isec, stub_type, h, irela))
		    goto error_ret_free_internal;
		}
	      else
		{
		  bfd_vma dest;

		  if (h != NULL)
		    dest = h->root.u.def.value;
		  else
		    dest = sym->st_value;
		  dest += irela->r_addend;
		  if (!build_stub (info, ibfd, isec, stub_type, h, irela,
				   dest, sym_sec))
		    goto error_ret_free_internal;
		}
	    }

	  /* We're done with the internal relocs, free them.  */
	  if (elf_section_data (isec)->relocs != internal_relocs)
	    free (internal_relocs);
	}

      if (local_syms != NULL
	  && symtab_hdr->contents != (unsigned char *) local_syms)
	{
	  if (!info->keep_memory)
	    free (local_syms);
	  else
	    symtab_hdr->contents = (unsigned char *) local_syms;
	}
    }

  return TRUE;
}

/* Allocate space for overlay call and return stubs.
   Return 0 on error, 1 if no overlays, 2 otherwise.  */

int
spu_elf_size_stubs (struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab;
  bfd *ibfd;
  bfd_size_type amt;
  flagword flags;
  unsigned int i;
  asection *stub;

  if (!process_stubs (info, FALSE))
    return 0;

  htab = spu_hash_table (info);
  elf_link_hash_traverse (&htab->elf, allocate_spuear_stubs, info);
  if (htab->stub_err)
    return 0;

  ibfd = info->input_bfds;
  if (htab->stub_count != NULL)
    {
      amt = (htab->num_overlays + 1) * sizeof (*htab->stub_sec);
      htab->stub_sec = bfd_zmalloc (amt);
      if (htab->stub_sec == NULL)
	return 0;

      flags = (SEC_ALLOC | SEC_LOAD | SEC_CODE | SEC_READONLY
	       | SEC_HAS_CONTENTS | SEC_IN_MEMORY);
      stub = bfd_make_section_anyway_with_flags (ibfd, ".stub", flags);
      htab->stub_sec[0] = stub;
      if (stub == NULL
	  || !bfd_set_section_alignment (ibfd, stub,
					 ovl_stub_size_log2 (htab->params)))
	return 0;
      stub->size = htab->stub_count[0] * ovl_stub_size (htab->params);
      if (htab->params->ovly_flavour == ovly_soft_icache)
	/* Extra space for linked list entries.  */
	stub->size += htab->stub_count[0] * 16;

      for (i = 0; i < htab->num_overlays; ++i)
	{
	  asection *osec = htab->ovl_sec[i];
	  unsigned int ovl = spu_elf_section_data (osec)->u.o.ovl_index;
	  stub = bfd_make_section_anyway_with_flags (ibfd, ".stub", flags);
	  htab->stub_sec[ovl] = stub;
	  if (stub == NULL
	      || !bfd_set_section_alignment (ibfd, stub,
					     ovl_stub_size_log2 (htab->params)))
	    return 0;
	  stub->size = htab->stub_count[ovl] * ovl_stub_size (htab->params);
	}
    }

  if (htab->params->ovly_flavour == ovly_soft_icache)
    {
      /* Space for icache manager tables.
	 a) Tag array, one quadword per cache line.
	 b) Rewrite "to" list, one quadword per cache line.
	 c) Rewrite "from" list, one byte per outgoing branch (rounded up to
	    a power-of-two number of full quadwords) per cache line.  */

      flags = SEC_ALLOC;
      htab->ovtab = bfd_make_section_anyway_with_flags (ibfd, ".ovtab", flags);
      if (htab->ovtab == NULL
	  || !bfd_set_section_alignment (ibfd, htab->ovtab, 4))
	return 0;

      htab->ovtab->size = (16 + 16 + (16 << htab->fromelem_size_log2))
			  << htab->num_lines_log2;

      flags = SEC_ALLOC | SEC_LOAD | SEC_HAS_CONTENTS | SEC_IN_MEMORY;
      htab->init = bfd_make_section_anyway_with_flags (ibfd, ".ovini", flags);
      if (htab->init == NULL
	  || !bfd_set_section_alignment (ibfd, htab->init, 4))
	return 0;

      htab->init->size = 16;
    }
  else if (htab->stub_count == NULL)
    return 1;
  else
    {
      /* htab->ovtab consists of two arrays.
	 .	struct {
	 .	  u32 vma;
	 .	  u32 size;
	 .	  u32 file_off;
	 .	  u32 buf;
	 .	} _ovly_table[];
	 .
	 .	struct {
	 .	  u32 mapped;
	 .	} _ovly_buf_table[];
	 .  */

      flags = SEC_ALLOC | SEC_LOAD | SEC_HAS_CONTENTS | SEC_IN_MEMORY;
      htab->ovtab = bfd_make_section_anyway_with_flags (ibfd, ".ovtab", flags);
      if (htab->ovtab == NULL
	  || !bfd_set_section_alignment (ibfd, htab->ovtab, 4))
	return 0;

      htab->ovtab->size = htab->num_overlays * 16 + 16 + htab->num_buf * 4;
    }

  htab->toe = bfd_make_section_anyway_with_flags (ibfd, ".toe", SEC_ALLOC);
  if (htab->toe == NULL
      || !bfd_set_section_alignment (ibfd, htab->toe, 4))
    return 0;
  htab->toe->size = 16;

  return 2;
}

/* Called from ld to place overlay manager data sections.  This is done
   after the overlay manager itself is loaded, mainly so that the
   linker's htab->init section is placed after any other .ovl.init
   sections.  */

void
spu_elf_place_overlay_data (struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  unsigned int i;

  if (htab->stub_sec != NULL)
    {
      (*htab->params->place_spu_section) (htab->stub_sec[0], NULL, ".text");

      for (i = 0; i < htab->num_overlays; ++i)
	{
	  asection *osec = htab->ovl_sec[i];
	  unsigned int ovl = spu_elf_section_data (osec)->u.o.ovl_index;
	  (*htab->params->place_spu_section) (htab->stub_sec[ovl], osec, NULL);
	}
    }

  if (htab->params->ovly_flavour == ovly_soft_icache)
    (*htab->params->place_spu_section) (htab->init, NULL, ".ovl.init");

  if (htab->ovtab != NULL)
    {
      const char *ovout = ".data";
      if (htab->params->ovly_flavour == ovly_soft_icache)
	ovout = ".bss";
      (*htab->params->place_spu_section) (htab->ovtab, NULL, ovout);
    }

  if (htab->toe != NULL)
    (*htab->params->place_spu_section) (htab->toe, NULL, ".toe");
}

/* Functions to handle embedded spu_ovl.o object.  */

static void *
ovl_mgr_open (struct bfd *nbfd ATTRIBUTE_UNUSED, void *stream)
{
  return stream;
}

static file_ptr
ovl_mgr_pread (struct bfd *abfd ATTRIBUTE_UNUSED,
	       void *stream,
	       void *buf,
	       file_ptr nbytes,
	       file_ptr offset)
{
  struct _ovl_stream *os;
  size_t count;
  size_t max;

  os = (struct _ovl_stream *) stream;
  max = (const char *) os->end - (const char *) os->start;

  if ((ufile_ptr) offset >= max)
    return 0;

  count = nbytes;
  if (count > max - offset)
    count = max - offset;

  memcpy (buf, (const char *) os->start + offset, count);
  return count;
}

bfd_boolean
spu_elf_open_builtin_lib (bfd **ovl_bfd, const struct _ovl_stream *stream)
{
  *ovl_bfd = bfd_openr_iovec ("builtin ovl_mgr",
			      "elf32-spu",
			      ovl_mgr_open,
			      (void *) stream,
			      ovl_mgr_pread,
			      NULL,
			      NULL);
  return *ovl_bfd != NULL;
}

static unsigned int
overlay_index (asection *sec)
{
  if (sec == NULL
      || sec->output_section == bfd_abs_section_ptr)
    return 0;
  return spu_elf_section_data (sec->output_section)->u.o.ovl_index;
}

/* Define an STT_OBJECT symbol.  */

static struct elf_link_hash_entry *
define_ovtab_symbol (struct spu_link_hash_table *htab, const char *name)
{
  struct elf_link_hash_entry *h;

  h = elf_link_hash_lookup (&htab->elf, name, TRUE, FALSE, FALSE);
  if (h == NULL)
    return NULL;

  if (h->root.type != bfd_link_hash_defined
      || !h->def_regular)
    {
      h->root.type = bfd_link_hash_defined;
      h->root.u.def.section = htab->ovtab;
      h->type = STT_OBJECT;
      h->ref_regular = 1;
      h->def_regular = 1;
      h->ref_regular_nonweak = 1;
      h->non_elf = 0;
    }
  else if (h->root.u.def.section->owner != NULL)
    {
      (*_bfd_error_handler) (_("%B is not allowed to define %s"),
			     h->root.u.def.section->owner,
			     h->root.root.string);
      bfd_set_error (bfd_error_bad_value);
      return NULL;
    }
  else
    {
      (*_bfd_error_handler) (_("you are not allowed to define %s in a script"),
			     h->root.root.string);
      bfd_set_error (bfd_error_bad_value);
      return NULL;
    }

  return h;
}

/* Fill in all stubs and the overlay tables.  */

static bfd_boolean
spu_elf_build_stubs (struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  struct elf_link_hash_entry *h;
  bfd_byte *p;
  asection *s;
  bfd *obfd;
  unsigned int i;

  if (htab->num_overlays != 0)
    {
      for (i = 0; i < 2; i++)
	{
	  h = htab->ovly_entry[i];
	  if (h != NULL
	      && (h->root.type == bfd_link_hash_defined
		  || h->root.type == bfd_link_hash_defweak)
	      && h->def_regular)
	    {
	      s = h->root.u.def.section->output_section;
	      if (spu_elf_section_data (s)->u.o.ovl_index)
		{
		  (*_bfd_error_handler) (_("%s in overlay section"),
					 h->root.root.string);
		  bfd_set_error (bfd_error_bad_value);
		  return FALSE;
		}
	    }
	}
    }

  if (htab->stub_sec != NULL)
    {
      for (i = 0; i <= htab->num_overlays; i++)
	if (htab->stub_sec[i]->size != 0)
	  {
	    htab->stub_sec[i]->contents = bfd_zalloc (htab->stub_sec[i]->owner,
						      htab->stub_sec[i]->size);
	    if (htab->stub_sec[i]->contents == NULL)
	      return FALSE;
	    htab->stub_sec[i]->rawsize = htab->stub_sec[i]->size;
	    htab->stub_sec[i]->size = 0;
	  }

      /* Fill in all the stubs.  */
      process_stubs (info, TRUE);
      if (!htab->stub_err)
	elf_link_hash_traverse (&htab->elf, build_spuear_stubs, info);

      if (htab->stub_err)
	{
	  (*_bfd_error_handler) (_("overlay stub relocation overflow"));
	  bfd_set_error (bfd_error_bad_value);
	  return FALSE;
	}

      for (i = 0; i <= htab->num_overlays; i++)
	{
	  if (htab->stub_sec[i]->size != htab->stub_sec[i]->rawsize)
	    {
	      (*_bfd_error_handler)  (_("stubs don't match calculated size"));
	      bfd_set_error (bfd_error_bad_value);
	      return FALSE;
	    }
	  htab->stub_sec[i]->rawsize = 0;
	}
    }

  if (htab->ovtab == NULL || htab->ovtab->size == 0)
    return TRUE;

  htab->ovtab->contents = bfd_zalloc (htab->ovtab->owner, htab->ovtab->size);
  if (htab->ovtab->contents == NULL)
    return FALSE;

  p = htab->ovtab->contents;
  if (htab->params->ovly_flavour == ovly_soft_icache)
    {
      bfd_vma off;

      h = define_ovtab_symbol (htab, "__icache_tag_array");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = 0;
      h->size = 16 << htab->num_lines_log2;
      off = h->size;

      h = define_ovtab_symbol (htab, "__icache_tag_array_size");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = 16 << htab->num_lines_log2;
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_rewrite_to");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = off;
      h->size = 16 << htab->num_lines_log2;
      off += h->size;

      h = define_ovtab_symbol (htab, "__icache_rewrite_to_size");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = 16 << htab->num_lines_log2;
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_rewrite_from");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = off;
      h->size = 16 << (htab->fromelem_size_log2 + htab->num_lines_log2);
      off += h->size;

      h = define_ovtab_symbol (htab, "__icache_rewrite_from_size");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = 16 << (htab->fromelem_size_log2
				   + htab->num_lines_log2);
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_log2_fromelemsize");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = htab->fromelem_size_log2;
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_base");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = htab->ovl_sec[0]->vma;
      h->root.u.def.section = bfd_abs_section_ptr;
      h->size = htab->num_buf << htab->line_size_log2;

      h = define_ovtab_symbol (htab, "__icache_linesize");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = 1 << htab->line_size_log2;
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_log2_linesize");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = htab->line_size_log2;
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_neg_log2_linesize");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = -htab->line_size_log2;
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_cachesize");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = 1 << (htab->num_lines_log2 + htab->line_size_log2);
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_log2_cachesize");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = htab->num_lines_log2 + htab->line_size_log2;
      h->root.u.def.section = bfd_abs_section_ptr;

      h = define_ovtab_symbol (htab, "__icache_neg_log2_cachesize");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = -(htab->num_lines_log2 + htab->line_size_log2);
      h->root.u.def.section = bfd_abs_section_ptr;

      if (htab->init != NULL && htab->init->size != 0)
	{
	  htab->init->contents = bfd_zalloc (htab->init->owner,
					     htab->init->size);
	  if (htab->init->contents == NULL)
	    return FALSE;

	  h = define_ovtab_symbol (htab, "__icache_fileoff");
	  if (h == NULL)
	    return FALSE;
	  h->root.u.def.value = 0;
	  h->root.u.def.section = htab->init;
	  h->size = 8;
	}
    }
  else
    {
      /* Write out _ovly_table.  */
      /* set low bit of .size to mark non-overlay area as present.  */
      p[7] = 1;
      obfd = htab->ovtab->output_section->owner;
      for (s = obfd->sections; s != NULL; s = s->next)
	{
	  unsigned int ovl_index = spu_elf_section_data (s)->u.o.ovl_index;

	  if (ovl_index != 0)
	    {
	      unsigned long off = ovl_index * 16;
	      unsigned int ovl_buf = spu_elf_section_data (s)->u.o.ovl_buf;

	      bfd_put_32 (htab->ovtab->owner, s->vma, p + off);
	      bfd_put_32 (htab->ovtab->owner, (s->size + 15) & -16,
			  p + off + 4);
	      /* file_off written later in spu_elf_modify_program_headers.  */
	      bfd_put_32 (htab->ovtab->owner, ovl_buf, p + off + 12);
	    }
	}

      h = define_ovtab_symbol (htab, "_ovly_table");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = 16;
      h->size = htab->num_overlays * 16;

      h = define_ovtab_symbol (htab, "_ovly_table_end");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = htab->num_overlays * 16 + 16;
      h->size = 0;

      h = define_ovtab_symbol (htab, "_ovly_buf_table");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = htab->num_overlays * 16 + 16;
      h->size = htab->num_buf * 4;

      h = define_ovtab_symbol (htab, "_ovly_buf_table_end");
      if (h == NULL)
	return FALSE;
      h->root.u.def.value = htab->num_overlays * 16 + 16 + htab->num_buf * 4;
      h->size = 0;
    }

  h = define_ovtab_symbol (htab, "_EAR_");
  if (h == NULL)
    return FALSE;
  h->root.u.def.section = htab->toe;
  h->root.u.def.value = 0;
  h->size = 16;

  return TRUE;
}

/* Check that all loadable section VMAs lie in the range
   LO .. HI inclusive, and stash some parameters for --auto-overlay.  */

asection *
spu_elf_check_vma (struct bfd_link_info *info)
{
  struct elf_segment_map *m;
  unsigned int i;
  struct spu_link_hash_table *htab = spu_hash_table (info);
  bfd *abfd = info->output_bfd;
  bfd_vma hi = htab->params->local_store_hi;
  bfd_vma lo = htab->params->local_store_lo;

  htab->local_store = hi + 1 - lo;

  for (m = elf_seg_map (abfd); m != NULL; m = m->next)
    if (m->p_type == PT_LOAD)
      for (i = 0; i < m->count; i++)
	if (m->sections[i]->size != 0
	    && (m->sections[i]->vma < lo
		|| m->sections[i]->vma > hi
		|| m->sections[i]->vma + m->sections[i]->size - 1 > hi))
	  return m->sections[i];

  return NULL;
}

/* OFFSET in SEC (presumably) is the beginning of a function prologue.
   Search for stack adjusting insns, and return the sp delta.
   If a store of lr is found save the instruction offset to *LR_STORE.
   If a stack adjusting instruction is found, save that offset to
   *SP_ADJUST.  */

static int
find_function_stack_adjust (asection *sec,
			    bfd_vma offset,
			    bfd_vma *lr_store,
			    bfd_vma *sp_adjust)
{
  int reg[128];

  memset (reg, 0, sizeof (reg));
  for ( ; offset + 4 <= sec->size; offset += 4)
    {
      unsigned char buf[4];
      int rt, ra;
      int imm;

      /* Assume no relocs on stack adjusing insns.  */
      if (!bfd_get_section_contents (sec->owner, sec, buf, offset, 4))
	break;

      rt = buf[3] & 0x7f;
      ra = ((buf[2] & 0x3f) << 1) | (buf[3] >> 7);

      if (buf[0] == 0x24 /* stqd */)
	{
	  if (rt == 0 /* lr */ && ra == 1 /* sp */)
	    *lr_store = offset;
	  continue;
	}

      /* Partly decoded immediate field.  */
      imm = (buf[1] << 9) | (buf[2] << 1) | (buf[3] >> 7);

      if (buf[0] == 0x1c /* ai */)
	{
	  imm >>= 7;
	  imm = (imm ^ 0x200) - 0x200;
	  reg[rt] = reg[ra] + imm;

	  if (rt == 1 /* sp */)
	    {
	      if (reg[rt] > 0)
		break;
	      *sp_adjust = offset;
	      return reg[rt];
	    }
	}
      else if (buf[0] == 0x18 && (buf[1] & 0xe0) == 0 /* a */)
	{
	  int rb = ((buf[1] & 0x1f) << 2) | ((buf[2] & 0xc0) >> 6);

	  reg[rt] = reg[ra] + reg[rb];
	  if (rt == 1)
	    {
	      if (reg[rt] > 0)
		break;
	      *sp_adjust = offset;
	      return reg[rt];
	    }
	}
      else if (buf[0] == 0x08 && (buf[1] & 0xe0) == 0 /* sf */)
	{
	  int rb = ((buf[1] & 0x1f) << 2) | ((buf[2] & 0xc0) >> 6);

	  reg[rt] = reg[rb] - reg[ra];
	  if (rt == 1)
	    {
	      if (reg[rt] > 0)
		break;
	      *sp_adjust = offset;
	      return reg[rt];
	    }
	}
      else if ((buf[0] & 0xfc) == 0x40 /* il, ilh, ilhu, ila */)
	{
	  if (buf[0] >= 0x42 /* ila */)
	    imm |= (buf[0] & 1) << 17;
	  else
	    {
	      imm &= 0xffff;

	      if (buf[0] == 0x40 /* il */)
		{
		  if ((buf[1] & 0x80) == 0)
		    continue;
		  imm = (imm ^ 0x8000) - 0x8000;
		}
	      else if ((buf[1] & 0x80) == 0 /* ilhu */)
		imm <<= 16;
	    }
	  reg[rt] = imm;
	  continue;
	}
      else if (buf[0] == 0x60 && (buf[1] & 0x80) != 0 /* iohl */)
	{
	  reg[rt] |= imm & 0xffff;
	  continue;
	}
      else if (buf[0] == 0x04 /* ori */)
	{
	  imm >>= 7;
	  imm = (imm ^ 0x200) - 0x200;
	  reg[rt] = reg[ra] | imm;
	  continue;
	}
      else if (buf[0] == 0x32 && (buf[1] & 0x80) != 0 /* fsmbi */)
	{
	  reg[rt] = (  ((imm & 0x8000) ? 0xff000000 : 0)
		     | ((imm & 0x4000) ? 0x00ff0000 : 0)
		     | ((imm & 0x2000) ? 0x0000ff00 : 0)
		     | ((imm & 0x1000) ? 0x000000ff : 0));
	  continue;
	}
      else if (buf[0] == 0x16 /* andbi */)
	{
	  imm >>= 7;
	  imm &= 0xff;
	  imm |= imm << 8;
	  imm |= imm << 16;
	  reg[rt] = reg[ra] & imm;
	  continue;
	}
      else if (buf[0] == 0x33 && imm == 1 /* brsl .+4 */)
	{
	  /* Used in pic reg load.  Say rt is trashed.  Won't be used
	     in stack adjust, but we need to continue past this branch.  */
	  reg[rt] = 0;
	  continue;
	}
      else if (is_branch (buf) || is_indirect_branch (buf))
	/* If we hit a branch then we must be out of the prologue.  */
	break;
    }

  return 0;
}

/* qsort predicate to sort symbols by section and value.  */

static Elf_Internal_Sym *sort_syms_syms;
static asection **sort_syms_psecs;

static int
sort_syms (const void *a, const void *b)
{
  Elf_Internal_Sym *const *s1 = a;
  Elf_Internal_Sym *const *s2 = b;
  asection *sec1,*sec2;
  bfd_signed_vma delta;

  sec1 = sort_syms_psecs[*s1 - sort_syms_syms];
  sec2 = sort_syms_psecs[*s2 - sort_syms_syms];

  if (sec1 != sec2)
    return sec1->index - sec2->index;

  delta = (*s1)->st_value - (*s2)->st_value;
  if (delta != 0)
    return delta < 0 ? -1 : 1;

  delta = (*s2)->st_size - (*s1)->st_size;
  if (delta != 0)
    return delta < 0 ? -1 : 1;

  return *s1 < *s2 ? -1 : 1;
}

/* Allocate a struct spu_elf_stack_info with MAX_FUN struct function_info
   entries for section SEC.  */

static struct spu_elf_stack_info *
alloc_stack_info (asection *sec, int max_fun)
{
  struct _spu_elf_section_data *sec_data = spu_elf_section_data (sec);
  bfd_size_type amt;

  amt = sizeof (struct spu_elf_stack_info);
  amt += (max_fun - 1) * sizeof (struct function_info);
  sec_data->u.i.stack_info = bfd_zmalloc (amt);
  if (sec_data->u.i.stack_info != NULL)
    sec_data->u.i.stack_info->max_fun = max_fun;
  return sec_data->u.i.stack_info;
}

/* Add a new struct function_info describing a (part of a) function
   starting at SYM_H.  Keep the array sorted by address.  */

static struct function_info *
maybe_insert_function (asection *sec,
		       void *sym_h,
		       bfd_boolean global,
		       bfd_boolean is_func)
{
  struct _spu_elf_section_data *sec_data = spu_elf_section_data (sec);
  struct spu_elf_stack_info *sinfo = sec_data->u.i.stack_info;
  int i;
  bfd_vma off, size;

  if (sinfo == NULL)
    {
      sinfo = alloc_stack_info (sec, 20);
      if (sinfo == NULL)
	return NULL;
    }

  if (!global)
    {
      Elf_Internal_Sym *sym = sym_h;
      off = sym->st_value;
      size = sym->st_size;
    }
  else
    {
      struct elf_link_hash_entry *h = sym_h;
      off = h->root.u.def.value;
      size = h->size;
    }

  for (i = sinfo->num_fun; --i >= 0; )
    if (sinfo->fun[i].lo <= off)
      break;

  if (i >= 0)
    {
      /* Don't add another entry for an alias, but do update some
	 info.  */
      if (sinfo->fun[i].lo == off)
	{
	  /* Prefer globals over local syms.  */
	  if (global && !sinfo->fun[i].global)
	    {
	      sinfo->fun[i].global = TRUE;
	      sinfo->fun[i].u.h = sym_h;
	    }
	  if (is_func)
	    sinfo->fun[i].is_func = TRUE;
	  return &sinfo->fun[i];
	}
      /* Ignore a zero-size symbol inside an existing function.  */
      else if (sinfo->fun[i].hi > off && size == 0)
	return &sinfo->fun[i];
    }

  if (sinfo->num_fun >= sinfo->max_fun)
    {
      bfd_size_type amt = sizeof (struct spu_elf_stack_info);
      bfd_size_type old = amt;

      old += (sinfo->max_fun - 1) * sizeof (struct function_info);
      sinfo->max_fun += 20 + (sinfo->max_fun >> 1);
      amt += (sinfo->max_fun - 1) * sizeof (struct function_info);
      sinfo = bfd_realloc (sinfo, amt);
      if (sinfo == NULL)
	return NULL;
      memset ((char *) sinfo + old, 0, amt - old);
      sec_data->u.i.stack_info = sinfo;
    }

  if (++i < sinfo->num_fun)
    memmove (&sinfo->fun[i + 1], &sinfo->fun[i],
	     (sinfo->num_fun - i) * sizeof (sinfo->fun[i]));
  sinfo->fun[i].is_func = is_func;
  sinfo->fun[i].global = global;
  sinfo->fun[i].sec = sec;
  if (global)
    sinfo->fun[i].u.h = sym_h;
  else
    sinfo->fun[i].u.sym = sym_h;
  sinfo->fun[i].lo = off;
  sinfo->fun[i].hi = off + size;
  sinfo->fun[i].lr_store = -1;
  sinfo->fun[i].sp_adjust = -1;
  sinfo->fun[i].stack = -find_function_stack_adjust (sec, off,
						     &sinfo->fun[i].lr_store,
						     &sinfo->fun[i].sp_adjust);
  sinfo->num_fun += 1;
  return &sinfo->fun[i];
}

/* Return the name of FUN.  */

static const char *
func_name (struct function_info *fun)
{
  asection *sec;
  bfd *ibfd;
  Elf_Internal_Shdr *symtab_hdr;

  while (fun->start != NULL)
    fun = fun->start;

  if (fun->global)
    return fun->u.h->root.root.string;

  sec = fun->sec;
  if (fun->u.sym->st_name == 0)
    {
      size_t len = strlen (sec->name);
      char *name = bfd_malloc (len + 10);
      if (name == NULL)
	return "(null)";
      sprintf (name, "%s+%lx", sec->name,
	       (unsigned long) fun->u.sym->st_value & 0xffffffff);
      return name;
    }
  ibfd = sec->owner;
  symtab_hdr = &elf_tdata (ibfd)->symtab_hdr;
  return bfd_elf_sym_name (ibfd, symtab_hdr, fun->u.sym, sec);
}

/* Read the instruction at OFF in SEC.  Return true iff the instruction
   is a nop, lnop, or stop 0 (all zero insn).  */

static bfd_boolean
is_nop (asection *sec, bfd_vma off)
{
  unsigned char insn[4];

  if (off + 4 > sec->size
      || !bfd_get_section_contents (sec->owner, sec, insn, off, 4))
    return FALSE;
  if ((insn[0] & 0xbf) == 0 && (insn[1] & 0xe0) == 0x20)
    return TRUE;
  if (insn[0] == 0 && insn[1] == 0 && insn[2] == 0 && insn[3] == 0)
    return TRUE;
  return FALSE;
}

/* Extend the range of FUN to cover nop padding up to LIMIT.
   Return TRUE iff some instruction other than a NOP was found.  */

static bfd_boolean
insns_at_end (struct function_info *fun, bfd_vma limit)
{
  bfd_vma off = (fun->hi + 3) & -4;

  while (off < limit && is_nop (fun->sec, off))
    off += 4;
  if (off < limit)
    {
      fun->hi = off;
      return TRUE;
    }
  fun->hi = limit;
  return FALSE;
}

/* Check and fix overlapping function ranges.  Return TRUE iff there
   are gaps in the current info we have about functions in SEC.  */

static bfd_boolean
check_function_ranges (asection *sec, struct bfd_link_info *info)
{
  struct _spu_elf_section_data *sec_data = spu_elf_section_data (sec);
  struct spu_elf_stack_info *sinfo = sec_data->u.i.stack_info;
  int i;
  bfd_boolean gaps = FALSE;

  if (sinfo == NULL)
    return FALSE;

  for (i = 1; i < sinfo->num_fun; i++)
    if (sinfo->fun[i - 1].hi > sinfo->fun[i].lo)
      {
	/* Fix overlapping symbols.  */
	const char *f1 = func_name (&sinfo->fun[i - 1]);
	const char *f2 = func_name (&sinfo->fun[i]);

	info->callbacks->einfo (_("warning: %s overlaps %s\n"), f1, f2);
	sinfo->fun[i - 1].hi = sinfo->fun[i].lo;
      }
    else if (insns_at_end (&sinfo->fun[i - 1], sinfo->fun[i].lo))
      gaps = TRUE;

  if (sinfo->num_fun == 0)
    gaps = TRUE;
  else
    {
      if (sinfo->fun[0].lo != 0)
	gaps = TRUE;
      if (sinfo->fun[sinfo->num_fun - 1].hi > sec->size)
	{
	  const char *f1 = func_name (&sinfo->fun[sinfo->num_fun - 1]);

	  info->callbacks->einfo (_("warning: %s exceeds section size\n"), f1);
	  sinfo->fun[sinfo->num_fun - 1].hi = sec->size;
	}
      else if (insns_at_end (&sinfo->fun[sinfo->num_fun - 1], sec->size))
	gaps = TRUE;
    }
  return gaps;
}

/* Search current function info for a function that contains address
   OFFSET in section SEC.  */

static struct function_info *
find_function (asection *sec, bfd_vma offset, struct bfd_link_info *info)
{
  struct _spu_elf_section_data *sec_data = spu_elf_section_data (sec);
  struct spu_elf_stack_info *sinfo = sec_data->u.i.stack_info;
  int lo, hi, mid;

  lo = 0;
  hi = sinfo->num_fun;
  while (lo < hi)
    {
      mid = (lo + hi) / 2;
      if (offset < sinfo->fun[mid].lo)
	hi = mid;
      else if (offset >= sinfo->fun[mid].hi)
	lo = mid + 1;
      else
	return &sinfo->fun[mid];
    }
  info->callbacks->einfo (_("%A:0x%v not found in function table\n"),
			  sec, offset);
  bfd_set_error (bfd_error_bad_value);
  return NULL;
}

/* Add CALLEE to CALLER call list if not already present.  Return TRUE
   if CALLEE was new.  If this function return FALSE, CALLEE should
   be freed.  */

static bfd_boolean
insert_callee (struct function_info *caller, struct call_info *callee)
{
  struct call_info **pp, *p;

  for (pp = &caller->call_list; (p = *pp) != NULL; pp = &p->next)
    if (p->fun == callee->fun)
      {
	/* Tail calls use less stack than normal calls.  Retain entry
	   for normal call over one for tail call.  */
	p->is_tail &= callee->is_tail;
	if (!p->is_tail)
	  {
	    p->fun->start = NULL;
	    p->fun->is_func = TRUE;
	  }
	p->count += callee->count;
	/* Reorder list so most recent call is first.  */
	*pp = p->next;
	p->next = caller->call_list;
	caller->call_list = p;
	return FALSE;
      }
  callee->next = caller->call_list;
  caller->call_list = callee;
  return TRUE;
}

/* Copy CALL and insert the copy into CALLER.  */

static bfd_boolean
copy_callee (struct function_info *caller, const struct call_info *call)
{
  struct call_info *callee;
  callee = bfd_malloc (sizeof (*callee));
  if (callee == NULL)
    return FALSE;
  *callee = *call;
  if (!insert_callee (caller, callee))
    free (callee);
  return TRUE;
}

/* We're only interested in code sections.  Testing SEC_IN_MEMORY excludes
   overlay stub sections.  */

static bfd_boolean
interesting_section (asection *s)
{
  return (s->output_section != bfd_abs_section_ptr
	  && ((s->flags & (SEC_ALLOC | SEC_LOAD | SEC_CODE | SEC_IN_MEMORY))
	      == (SEC_ALLOC | SEC_LOAD | SEC_CODE))
	  && s->size != 0);
}

/* Rummage through the relocs for SEC, looking for function calls.
   If CALL_TREE is true, fill in call graph.  If CALL_TREE is false,
   mark destination symbols on calls as being functions.  Also
   look at branches, which may be tail calls or go to hot/cold
   section part of same function.  */

static bfd_boolean
mark_functions_via_relocs (asection *sec,
			   struct bfd_link_info *info,
			   int call_tree)
{
  Elf_Internal_Rela *internal_relocs, *irelaend, *irela;
  Elf_Internal_Shdr *symtab_hdr;
  void *psyms;
  unsigned int priority = 0;
  static bfd_boolean warned;

  if (!interesting_section (sec)
      || sec->reloc_count == 0)
    return TRUE;

  internal_relocs = _bfd_elf_link_read_relocs (sec->owner, sec, NULL, NULL,
					       info->keep_memory);
  if (internal_relocs == NULL)
    return FALSE;

  symtab_hdr = &elf_tdata (sec->owner)->symtab_hdr;
  psyms = &symtab_hdr->contents;
  irela = internal_relocs;
  irelaend = irela + sec->reloc_count;
  for (; irela < irelaend; irela++)
    {
      enum elf_spu_reloc_type r_type;
      unsigned int r_indx;
      asection *sym_sec;
      Elf_Internal_Sym *sym;
      struct elf_link_hash_entry *h;
      bfd_vma val;
      bfd_boolean nonbranch, is_call;
      struct function_info *caller;
      struct call_info *callee;

      r_type = ELF32_R_TYPE (irela->r_info);
      nonbranch = r_type != R_SPU_REL16 && r_type != R_SPU_ADDR16;

      r_indx = ELF32_R_SYM (irela->r_info);
      if (!get_sym_h (&h, &sym, &sym_sec, psyms, r_indx, sec->owner))
	return FALSE;

      if (sym_sec == NULL
	  || sym_sec->output_section == bfd_abs_section_ptr)
	continue;

      is_call = FALSE;
      if (!nonbranch)
	{
	  unsigned char insn[4];

	  if (!bfd_get_section_contents (sec->owner, sec, insn,
					 irela->r_offset, 4))
	    return FALSE;
	  if (is_branch (insn))
	    {
	      is_call = (insn[0] & 0xfd) == 0x31;
	      priority = insn[1] & 0x0f;
	      priority <<= 8;
	      priority |= insn[2];
	      priority <<= 8;
	      priority |= insn[3];
	      priority >>= 7;
	      if ((sym_sec->flags & (SEC_ALLOC | SEC_LOAD | SEC_CODE))
		  != (SEC_ALLOC | SEC_LOAD | SEC_CODE))
		{
		  if (!warned)
		    info->callbacks->einfo
		      (_("%B(%A+0x%v): call to non-code section"
			 " %B(%A), analysis incomplete\n"),
		       sec->owner, sec, irela->r_offset,
		       sym_sec->owner, sym_sec);
		  warned = TRUE;
		  continue;
		}
	    }
	  else
	    {
	      nonbranch = TRUE;
	      if (is_hint (insn))
		continue;
	    }
	}

      if (nonbranch)
	{
	  /* For --auto-overlay, count possible stubs we need for
	     function pointer references.  */
	  unsigned int sym_type;
	  if (h)
	    sym_type = h->type;
	  else
	    sym_type = ELF_ST_TYPE (sym->st_info);
	  if (sym_type == STT_FUNC)
	    {
	      if (call_tree && spu_hash_table (info)->params->auto_overlay)
		spu_hash_table (info)->non_ovly_stub += 1;
	      /* If the symbol type is STT_FUNC then this must be a
		 function pointer initialisation.  */
	      continue;
	    }
	  /* Ignore data references.  */
	  if ((sym_sec->flags & (SEC_ALLOC | SEC_LOAD | SEC_CODE))
	      != (SEC_ALLOC | SEC_LOAD | SEC_CODE))
	    continue;
	  /* Otherwise we probably have a jump table reloc for
	     a switch statement or some other reference to a
	     code label.  */
	}

      if (h)
	val = h->root.u.def.value;
      else
	val = sym->st_value;
      val += irela->r_addend;

      if (!call_tree)
	{
	  struct function_info *fun;

	  if (irela->r_addend != 0)
	    {
	      Elf_Internal_Sym *fake = bfd_zmalloc (sizeof (*fake));
	      if (fake == NULL)
		return FALSE;
	      fake->st_value = val;
	      fake->st_shndx
		= _bfd_elf_section_from_bfd_section (sym_sec->owner, sym_sec);
	      sym = fake;
	    }
	  if (sym)
	    fun = maybe_insert_function (sym_sec, sym, FALSE, is_call);
	  else
	    fun = maybe_insert_function (sym_sec, h, TRUE, is_call);
	  if (fun == NULL)
	    return FALSE;
	  if (irela->r_addend != 0
	      && fun->u.sym != sym)
	    free (sym);
	  continue;
	}

      caller = find_function (sec, irela->r_offset, info);
      if (caller == NULL)
	return FALSE;
      callee = bfd_malloc (sizeof *callee);
      if (callee == NULL)
	return FALSE;

      callee->fun = find_function (sym_sec, val, info);
      if (callee->fun == NULL)
	return FALSE;
      callee->is_tail = !is_call;
      callee->is_pasted = FALSE;
      callee->broken_cycle = FALSE;
      callee->priority = priority;
      callee->count = nonbranch? 0 : 1;
      if (callee->fun->last_caller != sec)
	{
	  callee->fun->last_caller = sec;
	  callee->fun->call_count += 1;
	}
      if (!insert_callee (caller, callee))
	free (callee);
      else if (!is_call
	       && !callee->fun->is_func
	       && callee->fun->stack == 0)
	{
	  /* This is either a tail call or a branch from one part of
	     the function to another, ie. hot/cold section.  If the
	     destination has been called by some other function then
	     it is a separate function.  We also assume that functions
	     are not split across input files.  */
	  if (sec->owner != sym_sec->owner)
	    {
	      callee->fun->start = NULL;
	      callee->fun->is_func = TRUE;
	    }
	  else if (callee->fun->start == NULL)
	    {
	      struct function_info *caller_start = caller;
	      while (caller_start->start)
		caller_start = caller_start->start;

	      if (caller_start != callee->fun)
		callee->fun->start = caller_start;
	    }
	  else
	    {
	      struct function_info *callee_start;
	      struct function_info *caller_start;
	      callee_start = callee->fun;
	      while (callee_start->start)
		callee_start = callee_start->start;
	      caller_start = caller;
	      while (caller_start->start)
		caller_start = caller_start->start;
	      if (caller_start != callee_start)
		{
		  callee->fun->start = NULL;
		  callee->fun->is_func = TRUE;
		}
	    }
	}
    }

  return TRUE;
}

/* Handle something like .init or .fini, which has a piece of a function.
   These sections are pasted together to form a single function.  */

static bfd_boolean
pasted_function (asection *sec)
{
  struct bfd_link_order *l;
  struct _spu_elf_section_data *sec_data;
  struct spu_elf_stack_info *sinfo;
  Elf_Internal_Sym *fake;
  struct function_info *fun, *fun_start;

  fake = bfd_zmalloc (sizeof (*fake));
  if (fake == NULL)
    return FALSE;
  fake->st_value = 0;
  fake->st_size = sec->size;
  fake->st_shndx
    = _bfd_elf_section_from_bfd_section (sec->owner, sec);
  fun = maybe_insert_function (sec, fake, FALSE, FALSE);
  if (!fun)
    return FALSE;

  /* Find a function immediately preceding this section.  */
  fun_start = NULL;
  for (l = sec->output_section->map_head.link_order; l != NULL; l = l->next)
    {
      if (l->u.indirect.section == sec)
	{
	  if (fun_start != NULL)
	    {
	      struct call_info *callee = bfd_malloc (sizeof *callee);
	      if (callee == NULL)
		return FALSE;

	      fun->start = fun_start;
	      callee->fun = fun;
	      callee->is_tail = TRUE;
	      callee->is_pasted = TRUE;
	      callee->broken_cycle = FALSE;
	      callee->priority = 0;
	      callee->count = 1;
	      if (!insert_callee (fun_start, callee))
		free (callee);
	      return TRUE;
	    }
	  break;
	}
      if (l->type == bfd_indirect_link_order
	  && (sec_data = spu_elf_section_data (l->u.indirect.section)) != NULL
	  && (sinfo = sec_data->u.i.stack_info) != NULL
	  && sinfo->num_fun != 0)
	fun_start = &sinfo->fun[sinfo->num_fun - 1];
    }

  /* Don't return an error if we did not find a function preceding this
     section.  The section may have incorrect flags.  */
  return TRUE;
}

/* Map address ranges in code sections to functions.  */

static bfd_boolean
discover_functions (struct bfd_link_info *info)
{
  bfd *ibfd;
  int bfd_idx;
  Elf_Internal_Sym ***psym_arr;
  asection ***sec_arr;
  bfd_boolean gaps = FALSE;

  bfd_idx = 0;
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    bfd_idx++;

  psym_arr = bfd_zmalloc (bfd_idx * sizeof (*psym_arr));
  if (psym_arr == NULL)
    return FALSE;
  sec_arr = bfd_zmalloc (bfd_idx * sizeof (*sec_arr));
  if (sec_arr == NULL)
    return FALSE;

  for (ibfd = info->input_bfds, bfd_idx = 0;
       ibfd != NULL;
       ibfd = ibfd->link_next, bfd_idx++)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      Elf_Internal_Shdr *symtab_hdr;
      asection *sec;
      size_t symcount;
      Elf_Internal_Sym *syms, *sy, **psyms, **psy;
      asection **psecs, **p;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      /* Read all the symbols.  */
      symtab_hdr = &elf_tdata (ibfd)->symtab_hdr;
      symcount = symtab_hdr->sh_size / symtab_hdr->sh_entsize;
      if (symcount == 0)
	{
	  if (!gaps)
	    for (sec = ibfd->sections; sec != NULL && !gaps; sec = sec->next)
	      if (interesting_section (sec))
		{
		  gaps = TRUE;
		  break;
		}
	  continue;
	}

      if (symtab_hdr->contents != NULL)
	{
	  /* Don't use cached symbols since the generic ELF linker
	     code only reads local symbols, and we need globals too.  */
	  free (symtab_hdr->contents);
	  symtab_hdr->contents = NULL;
	}
      syms = bfd_elf_get_elf_syms (ibfd, symtab_hdr, symcount, 0,
				   NULL, NULL, NULL);
      symtab_hdr->contents = (void *) syms;
      if (syms == NULL)
	return FALSE;

      /* Select defined function symbols that are going to be output.  */
      psyms = bfd_malloc ((symcount + 1) * sizeof (*psyms));
      if (psyms == NULL)
	return FALSE;
      psym_arr[bfd_idx] = psyms;
      psecs = bfd_malloc (symcount * sizeof (*psecs));
      if (psecs == NULL)
	return FALSE;
      sec_arr[bfd_idx] = psecs;
      for (psy = psyms, p = psecs, sy = syms; sy < syms + symcount; ++p, ++sy)
	if (ELF_ST_TYPE (sy->st_info) == STT_NOTYPE
	    || ELF_ST_TYPE (sy->st_info) == STT_FUNC)
	  {
	    asection *s;

	    *p = s = bfd_section_from_elf_index (ibfd, sy->st_shndx);
	    if (s != NULL && interesting_section (s))
	      *psy++ = sy;
	  }
      symcount = psy - psyms;
      *psy = NULL;

      /* Sort them by section and offset within section.  */
      sort_syms_syms = syms;
      sort_syms_psecs = psecs;
      qsort (psyms, symcount, sizeof (*psyms), sort_syms);

      /* Now inspect the function symbols.  */
      for (psy = psyms; psy < psyms + symcount; )
	{
	  asection *s = psecs[*psy - syms];
	  Elf_Internal_Sym **psy2;

	  for (psy2 = psy; ++psy2 < psyms + symcount; )
	    if (psecs[*psy2 - syms] != s)
	      break;

	  if (!alloc_stack_info (s, psy2 - psy))
	    return FALSE;
	  psy = psy2;
	}

      /* First install info about properly typed and sized functions.
	 In an ideal world this will cover all code sections, except
	 when partitioning functions into hot and cold sections,
	 and the horrible pasted together .init and .fini functions.  */
      for (psy = psyms; psy < psyms + symcount; ++psy)
	{
	  sy = *psy;
	  if (ELF_ST_TYPE (sy->st_info) == STT_FUNC)
	    {
	      asection *s = psecs[sy - syms];
	      if (!maybe_insert_function (s, sy, FALSE, TRUE))
		return FALSE;
	    }
	}

      for (sec = ibfd->sections; sec != NULL && !gaps; sec = sec->next)
	if (interesting_section (sec))
	  gaps |= check_function_ranges (sec, info);
    }

  if (gaps)
    {
      /* See if we can discover more function symbols by looking at
	 relocations.  */
      for (ibfd = info->input_bfds, bfd_idx = 0;
	   ibfd != NULL;
	   ibfd = ibfd->link_next, bfd_idx++)
	{
	  asection *sec;

	  if (psym_arr[bfd_idx] == NULL)
	    continue;

	  for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	    if (!mark_functions_via_relocs (sec, info, FALSE))
	      return FALSE;
	}

      for (ibfd = info->input_bfds, bfd_idx = 0;
	   ibfd != NULL;
	   ibfd = ibfd->link_next, bfd_idx++)
	{
	  Elf_Internal_Shdr *symtab_hdr;
	  asection *sec;
	  Elf_Internal_Sym *syms, *sy, **psyms, **psy;
	  asection **psecs;

	  if ((psyms = psym_arr[bfd_idx]) == NULL)
	    continue;

	  psecs = sec_arr[bfd_idx];

	  symtab_hdr = &elf_tdata (ibfd)->symtab_hdr;
	  syms = (Elf_Internal_Sym *) symtab_hdr->contents;

	  gaps = FALSE;
	  for (sec = ibfd->sections; sec != NULL && !gaps; sec = sec->next)
	    if (interesting_section (sec))
	      gaps |= check_function_ranges (sec, info);
	  if (!gaps)
	    continue;

	  /* Finally, install all globals.  */
	  for (psy = psyms; (sy = *psy) != NULL; ++psy)
	    {
	      asection *s;

	      s = psecs[sy - syms];

	      /* Global syms might be improperly typed functions.  */
	      if (ELF_ST_TYPE (sy->st_info) != STT_FUNC
		  && ELF_ST_BIND (sy->st_info) == STB_GLOBAL)
		{
		  if (!maybe_insert_function (s, sy, FALSE, FALSE))
		    return FALSE;
		}
	    }
	}

      for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
	{
	  extern const bfd_target bfd_elf32_spu_vec;
	  asection *sec;

	  if (ibfd->xvec != &bfd_elf32_spu_vec)
	    continue;

	  /* Some of the symbols we've installed as marking the
	     beginning of functions may have a size of zero.  Extend
	     the range of such functions to the beginning of the
	     next symbol of interest.  */
	  for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	    if (interesting_section (sec))
	      {
		struct _spu_elf_section_data *sec_data;
		struct spu_elf_stack_info *sinfo;

		sec_data = spu_elf_section_data (sec);
		sinfo = sec_data->u.i.stack_info;
		if (sinfo != NULL && sinfo->num_fun != 0)
		  {
		    int fun_idx;
		    bfd_vma hi = sec->size;

		    for (fun_idx = sinfo->num_fun; --fun_idx >= 0; )
		      {
			sinfo->fun[fun_idx].hi = hi;
			hi = sinfo->fun[fun_idx].lo;
		      }

		    sinfo->fun[0].lo = 0;
		  }
		/* No symbols in this section.  Must be .init or .fini
		   or something similar.  */
		else if (!pasted_function (sec))
		  return FALSE;
	      }
	}
    }

  for (ibfd = info->input_bfds, bfd_idx = 0;
       ibfd != NULL;
       ibfd = ibfd->link_next, bfd_idx++)
    {
      if (psym_arr[bfd_idx] == NULL)
	continue;

      free (psym_arr[bfd_idx]);
      free (sec_arr[bfd_idx]);
    }

  free (psym_arr);
  free (sec_arr);

  return TRUE;
}

/* Iterate over all function_info we have collected, calling DOIT on
   each node if ROOT_ONLY is false.  Only call DOIT on root nodes
   if ROOT_ONLY.  */

static bfd_boolean
for_each_node (bfd_boolean (*doit) (struct function_info *,
				    struct bfd_link_info *,
				    void *),
	       struct bfd_link_info *info,
	       void *param,
	       int root_only)
{
  bfd *ibfd;

  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      asection *sec;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	{
	  struct _spu_elf_section_data *sec_data;
	  struct spu_elf_stack_info *sinfo;

	  if ((sec_data = spu_elf_section_data (sec)) != NULL
	      && (sinfo = sec_data->u.i.stack_info) != NULL)
	    {
	      int i;
	      for (i = 0; i < sinfo->num_fun; ++i)
		if (!root_only || !sinfo->fun[i].non_root)
		  if (!doit (&sinfo->fun[i], info, param))
		    return FALSE;
	    }
	}
    }
  return TRUE;
}

/* Transfer call info attached to struct function_info entries for
   all of a given function's sections to the first entry.  */

static bfd_boolean
transfer_calls (struct function_info *fun,
		struct bfd_link_info *info ATTRIBUTE_UNUSED,
		void *param ATTRIBUTE_UNUSED)
{
  struct function_info *start = fun->start;

  if (start != NULL)
    {
      struct call_info *call, *call_next;

      while (start->start != NULL)
	start = start->start;
      for (call = fun->call_list; call != NULL; call = call_next)
	{
	  call_next = call->next;
	  if (!insert_callee (start, call))
	    free (call);
	}
      fun->call_list = NULL;
    }
  return TRUE;
}

/* Mark nodes in the call graph that are called by some other node.  */

static bfd_boolean
mark_non_root (struct function_info *fun,
	       struct bfd_link_info *info ATTRIBUTE_UNUSED,
	       void *param ATTRIBUTE_UNUSED)
{
  struct call_info *call;

  if (fun->visit1)
    return TRUE;
  fun->visit1 = TRUE;
  for (call = fun->call_list; call; call = call->next)
    {
      call->fun->non_root = TRUE;
      mark_non_root (call->fun, 0, 0);
    }
  return TRUE;
}

/* Remove cycles from the call graph.  Set depth of nodes.  */

static bfd_boolean
remove_cycles (struct function_info *fun,
	       struct bfd_link_info *info,
	       void *param)
{
  struct call_info **callp, *call;
  unsigned int depth = *(unsigned int *) param;
  unsigned int max_depth = depth;

  fun->depth = depth;
  fun->visit2 = TRUE;
  fun->marking = TRUE;

  callp = &fun->call_list;
  while ((call = *callp) != NULL)
    {
      call->max_depth = depth + !call->is_pasted;
      if (!call->fun->visit2)
	{
	  if (!remove_cycles (call->fun, info, &call->max_depth))
	    return FALSE;
	  if (max_depth < call->max_depth)
	    max_depth = call->max_depth;
	}
      else if (call->fun->marking)
	{
	  struct spu_link_hash_table *htab = spu_hash_table (info);

	  if (!htab->params->auto_overlay
	      && htab->params->stack_analysis)
	    {
	      const char *f1 = func_name (fun);
	      const char *f2 = func_name (call->fun);

	      info->callbacks->info (_("Stack analysis will ignore the call "
				       "from %s to %s\n"),
				     f1, f2);
	    }

	  call->broken_cycle = TRUE;
	}
      callp = &call->next;
    }
  fun->marking = FALSE;
  *(unsigned int *) param = max_depth;
  return TRUE;
}

/* Check that we actually visited all nodes in remove_cycles.  If we
   didn't, then there is some cycle in the call graph not attached to
   any root node.  Arbitrarily choose a node in the cycle as a new
   root and break the cycle.  */

static bfd_boolean
mark_detached_root (struct function_info *fun,
		    struct bfd_link_info *info,
		    void *param)
{
  if (fun->visit2)
    return TRUE;
  fun->non_root = FALSE;
  *(unsigned int *) param = 0;
  return remove_cycles (fun, info, param);
}

/* Populate call_list for each function.  */

static bfd_boolean
build_call_tree (struct bfd_link_info *info)
{
  bfd *ibfd;
  unsigned int depth;

  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      asection *sec;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	if (!mark_functions_via_relocs (sec, info, TRUE))
	  return FALSE;
    }

  /* Transfer call info from hot/cold section part of function
     to main entry.  */
  if (!spu_hash_table (info)->params->auto_overlay
      && !for_each_node (transfer_calls, info, 0, FALSE))
    return FALSE;

  /* Find the call graph root(s).  */
  if (!for_each_node (mark_non_root, info, 0, FALSE))
    return FALSE;

  /* Remove cycles from the call graph.  We start from the root node(s)
     so that we break cycles in a reasonable place.  */
  depth = 0;
  if (!for_each_node (remove_cycles, info, &depth, TRUE))
    return FALSE;

  return for_each_node (mark_detached_root, info, &depth, FALSE);
}

/* qsort predicate to sort calls by priority, max_depth then count.  */

static int
sort_calls (const void *a, const void *b)
{
  struct call_info *const *c1 = a;
  struct call_info *const *c2 = b;
  int delta;

  delta = (*c2)->priority - (*c1)->priority;
  if (delta != 0)
    return delta;

  delta = (*c2)->max_depth - (*c1)->max_depth;
  if (delta != 0)
    return delta;

  delta = (*c2)->count - (*c1)->count;
  if (delta != 0)
    return delta;

  return (char *) c1 - (char *) c2;
}

struct _mos_param {
  unsigned int max_overlay_size;
};

/* Set linker_mark and gc_mark on any sections that we will put in
   overlays.  These flags are used by the generic ELF linker, but we
   won't be continuing on to bfd_elf_final_link so it is OK to use
   them.  linker_mark is clear before we get here.  Set segment_mark
   on sections that are part of a pasted function (excluding the last
   section).

   Set up function rodata section if --overlay-rodata.  We don't
   currently include merged string constant rodata sections since

   Sort the call graph so that the deepest nodes will be visited
   first.  */

static bfd_boolean
mark_overlay_section (struct function_info *fun,
		      struct bfd_link_info *info,
		      void *param)
{
  struct call_info *call;
  unsigned int count;
  struct _mos_param *mos_param = param;
  struct spu_link_hash_table *htab = spu_hash_table (info);

  if (fun->visit4)
    return TRUE;

  fun->visit4 = TRUE;
  if (!fun->sec->linker_mark
      && (htab->params->ovly_flavour != ovly_soft_icache
	  || htab->params->non_ia_text
	  || strncmp (fun->sec->name, ".text.ia.", 9) == 0
	  || strcmp (fun->sec->name, ".init") == 0
	  || strcmp (fun->sec->name, ".fini") == 0))
    {
      unsigned int size;

      fun->sec->linker_mark = 1;
      fun->sec->gc_mark = 1;
      fun->sec->segment_mark = 0;
      /* Ensure SEC_CODE is set on this text section (it ought to
	 be!), and SEC_CODE is clear on rodata sections.  We use
	 this flag to differentiate the two overlay section types.  */
      fun->sec->flags |= SEC_CODE;

      size = fun->sec->size;
      if (htab->params->auto_overlay & OVERLAY_RODATA)
	{
	  char *name = NULL;

	  /* Find the rodata section corresponding to this function's
	     text section.  */
	  if (strcmp (fun->sec->name, ".text") == 0)
	    {
	      name = bfd_malloc (sizeof (".rodata"));
	      if (name == NULL)
		return FALSE;
	      memcpy (name, ".rodata", sizeof (".rodata"));
	    }
	  else if (strncmp (fun->sec->name, ".text.", 6) == 0)
	    {
	      size_t len = strlen (fun->sec->name);
	      name = bfd_malloc (len + 3);
	      if (name == NULL)
		return FALSE;
	      memcpy (name, ".rodata", sizeof (".rodata"));
	      memcpy (name + 7, fun->sec->name + 5, len - 4);
	    }
	  else if (strncmp (fun->sec->name, ".gnu.linkonce.t.", 16) == 0)
	    {
	      size_t len = strlen (fun->sec->name) + 1;
	      name = bfd_malloc (len);
	      if (name == NULL)
		return FALSE;
	      memcpy (name, fun->sec->name, len);
	      name[14] = 'r';
	    }

	  if (name != NULL)
	    {
	      asection *rodata = NULL;
	      asection *group_sec = elf_section_data (fun->sec)->next_in_group;
	      if (group_sec == NULL)
		rodata = bfd_get_section_by_name (fun->sec->owner, name);
	      else
		while (group_sec != NULL && group_sec != fun->sec)
		  {
		    if (strcmp (group_sec->name, name) == 0)
		      {
			rodata = group_sec;
			break;
		      }
		    group_sec = elf_section_data (group_sec)->next_in_group;
		  }
	      fun->rodata = rodata;
	      if (fun->rodata)
		{
		  size += fun->rodata->size;
		  if (htab->params->line_size != 0
		      && size > htab->params->line_size)
		    {
		      size -= fun->rodata->size;
		      fun->rodata = NULL;
		    }
		  else
		    {
		      fun->rodata->linker_mark = 1;
		      fun->rodata->gc_mark = 1;
		      fun->rodata->flags &= ~SEC_CODE;
		    }
		}
	      free (name);
	    }
	}
      if (mos_param->max_overlay_size < size)
	mos_param->max_overlay_size = size;
    }

  for (count = 0, call = fun->call_list; call != NULL; call = call->next)
    count += 1;

  if (count > 1)
    {
      struct call_info **calls = bfd_malloc (count * sizeof (*calls));
      if (calls == NULL)
	return FALSE;

      for (count = 0, call = fun->call_list; call != NULL; call = call->next)
	calls[count++] = call;

      qsort (calls, count, sizeof (*calls), sort_calls);

      fun->call_list = NULL;
      while (count != 0)
	{
	  --count;
	  calls[count]->next = fun->call_list;
	  fun->call_list = calls[count];
	}
      free (calls);
    }

  for (call = fun->call_list; call != NULL; call = call->next)
    {
      if (call->is_pasted)
	{
	  /* There can only be one is_pasted call per function_info.  */
	  BFD_ASSERT (!fun->sec->segment_mark);
	  fun->sec->segment_mark = 1;
	}
      if (!call->broken_cycle
	  && !mark_overlay_section (call->fun, info, param))
	return FALSE;
    }

  /* Don't put entry code into an overlay.  The overlay manager needs
     a stack!  Also, don't mark .ovl.init as an overlay.  */
  if (fun->lo + fun->sec->output_offset + fun->sec->output_section->vma
      == info->output_bfd->start_address
      || strncmp (fun->sec->output_section->name, ".ovl.init", 9) == 0)
    {
      fun->sec->linker_mark = 0;
      if (fun->rodata != NULL)
	fun->rodata->linker_mark = 0;
    }
  return TRUE;
}

/* If non-zero then unmark functions called from those within sections
   that we need to unmark.  Unfortunately this isn't reliable since the
   call graph cannot know the destination of function pointer calls.  */
#define RECURSE_UNMARK 0

struct _uos_param {
  asection *exclude_input_section;
  asection *exclude_output_section;
  unsigned long clearing;
};

/* Undo some of mark_overlay_section's work.  */

static bfd_boolean
unmark_overlay_section (struct function_info *fun,
			struct bfd_link_info *info,
			void *param)
{
  struct call_info *call;
  struct _uos_param *uos_param = param;
  unsigned int excluded = 0;

  if (fun->visit5)
    return TRUE;

  fun->visit5 = TRUE;

  excluded = 0;
  if (fun->sec == uos_param->exclude_input_section
      || fun->sec->output_section == uos_param->exclude_output_section)
    excluded = 1;

  if (RECURSE_UNMARK)
    uos_param->clearing += excluded;

  if (RECURSE_UNMARK ? uos_param->clearing : excluded)
    {
      fun->sec->linker_mark = 0;
      if (fun->rodata)
	fun->rodata->linker_mark = 0;
    }

  for (call = fun->call_list; call != NULL; call = call->next)
    if (!call->broken_cycle
	&& !unmark_overlay_section (call->fun, info, param))
      return FALSE;

  if (RECURSE_UNMARK)
    uos_param->clearing -= excluded;
  return TRUE;
}

struct _cl_param {
  unsigned int lib_size;
  asection **lib_sections;
};

/* Add sections we have marked as belonging to overlays to an array
   for consideration as non-overlay sections.  The array consist of
   pairs of sections, (text,rodata), for functions in the call graph.  */

static bfd_boolean
collect_lib_sections (struct function_info *fun,
		      struct bfd_link_info *info,
		      void *param)
{
  struct _cl_param *lib_param = param;
  struct call_info *call;
  unsigned int size;

  if (fun->visit6)
    return TRUE;

  fun->visit6 = TRUE;
  if (!fun->sec->linker_mark || !fun->sec->gc_mark || fun->sec->segment_mark)
    return TRUE;

  size = fun->sec->size;
  if (fun->rodata)
    size += fun->rodata->size;

  if (size <= lib_param->lib_size)
    {
      *lib_param->lib_sections++ = fun->sec;
      fun->sec->gc_mark = 0;
      if (fun->rodata && fun->rodata->linker_mark && fun->rodata->gc_mark)
	{
	  *lib_param->lib_sections++ = fun->rodata;
	  fun->rodata->gc_mark = 0;
	}
      else
	*lib_param->lib_sections++ = NULL;
    }

  for (call = fun->call_list; call != NULL; call = call->next)
    if (!call->broken_cycle)
      collect_lib_sections (call->fun, info, param);

  return TRUE;
}

/* qsort predicate to sort sections by call count.  */

static int
sort_lib (const void *a, const void *b)
{
  asection *const *s1 = a;
  asection *const *s2 = b;
  struct _spu_elf_section_data *sec_data;
  struct spu_elf_stack_info *sinfo;
  int delta;

  delta = 0;
  if ((sec_data = spu_elf_section_data (*s1)) != NULL
      && (sinfo = sec_data->u.i.stack_info) != NULL)
    {
      int i;
      for (i = 0; i < sinfo->num_fun; ++i)
	delta -= sinfo->fun[i].call_count;
    }

  if ((sec_data = spu_elf_section_data (*s2)) != NULL
      && (sinfo = sec_data->u.i.stack_info) != NULL)
    {
      int i;
      for (i = 0; i < sinfo->num_fun; ++i)
	delta += sinfo->fun[i].call_count;
    }

  if (delta != 0)
    return delta;

  return s1 - s2;
}

/* Remove some sections from those marked to be in overlays.  Choose
   those that are called from many places, likely library functions.  */

static unsigned int
auto_ovl_lib_functions (struct bfd_link_info *info, unsigned int lib_size)
{
  bfd *ibfd;
  asection **lib_sections;
  unsigned int i, lib_count;
  struct _cl_param collect_lib_param;
  struct function_info dummy_caller;
  struct spu_link_hash_table *htab;

  memset (&dummy_caller, 0, sizeof (dummy_caller));
  lib_count = 0;
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      asection *sec;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	if (sec->linker_mark
	    && sec->size < lib_size
	    && (sec->flags & SEC_CODE) != 0)
	  lib_count += 1;
    }
  lib_sections = bfd_malloc (lib_count * 2 * sizeof (*lib_sections));
  if (lib_sections == NULL)
    return (unsigned int) -1;
  collect_lib_param.lib_size = lib_size;
  collect_lib_param.lib_sections = lib_sections;
  if (!for_each_node (collect_lib_sections, info, &collect_lib_param,
		      TRUE))
    return (unsigned int) -1;
  lib_count = (collect_lib_param.lib_sections - lib_sections) / 2;

  /* Sort sections so that those with the most calls are first.  */
  if (lib_count > 1)
    qsort (lib_sections, lib_count, 2 * sizeof (*lib_sections), sort_lib);

  htab = spu_hash_table (info);
  for (i = 0; i < lib_count; i++)
    {
      unsigned int tmp, stub_size;
      asection *sec;
      struct _spu_elf_section_data *sec_data;
      struct spu_elf_stack_info *sinfo;

      sec = lib_sections[2 * i];
      /* If this section is OK, its size must be less than lib_size.  */
      tmp = sec->size;
      /* If it has a rodata section, then add that too.  */
      if (lib_sections[2 * i + 1])
	tmp += lib_sections[2 * i + 1]->size;
      /* Add any new overlay call stubs needed by the section.  */
      stub_size = 0;
      if (tmp < lib_size
	  && (sec_data = spu_elf_section_data (sec)) != NULL
	  && (sinfo = sec_data->u.i.stack_info) != NULL)
	{
	  int k;
	  struct call_info *call;

	  for (k = 0; k < sinfo->num_fun; ++k)
	    for (call = sinfo->fun[k].call_list; call; call = call->next)
	      if (call->fun->sec->linker_mark)
		{
		  struct call_info *p;
		  for (p = dummy_caller.call_list; p; p = p->next)
		    if (p->fun == call->fun)
		      break;
		  if (!p)
		    stub_size += ovl_stub_size (htab->params);
		}
	}
      if (tmp + stub_size < lib_size)
	{
	  struct call_info **pp, *p;

	  /* This section fits.  Mark it as non-overlay.  */
	  lib_sections[2 * i]->linker_mark = 0;
	  if (lib_sections[2 * i + 1])
	    lib_sections[2 * i + 1]->linker_mark = 0;
	  lib_size -= tmp + stub_size;
	  /* Call stubs to the section we just added are no longer
	     needed.  */
	  pp = &dummy_caller.call_list;
	  while ((p = *pp) != NULL)
	    if (!p->fun->sec->linker_mark)
	      {
		lib_size += ovl_stub_size (htab->params);
		*pp = p->next;
		free (p);
	      }
	    else
	      pp = &p->next;
	  /* Add new call stubs to dummy_caller.  */
	  if ((sec_data = spu_elf_section_data (sec)) != NULL
	      && (sinfo = sec_data->u.i.stack_info) != NULL)
	    {
	      int k;
	      struct call_info *call;

	      for (k = 0; k < sinfo->num_fun; ++k)
		for (call = sinfo->fun[k].call_list;
		     call;
		     call = call->next)
		  if (call->fun->sec->linker_mark)
		    {
		      struct call_info *callee;
		      callee = bfd_malloc (sizeof (*callee));
		      if (callee == NULL)
			return (unsigned int) -1;
		      *callee = *call;
		      if (!insert_callee (&dummy_caller, callee))
			free (callee);
		    }
	    }
	}
    }
  while (dummy_caller.call_list != NULL)
    {
      struct call_info *call = dummy_caller.call_list;
      dummy_caller.call_list = call->next;
      free (call);
    }
  for (i = 0; i < 2 * lib_count; i++)
    if (lib_sections[i])
      lib_sections[i]->gc_mark = 1;
  free (lib_sections);
  return lib_size;
}

/* Build an array of overlay sections.  The deepest node's section is
   added first, then its parent node's section, then everything called
   from the parent section.  The idea being to group sections to
   minimise calls between different overlays.  */

static bfd_boolean
collect_overlays (struct function_info *fun,
		  struct bfd_link_info *info,
		  void *param)
{
  struct call_info *call;
  bfd_boolean added_fun;
  asection ***ovly_sections = param;

  if (fun->visit7)
    return TRUE;

  fun->visit7 = TRUE;
  for (call = fun->call_list; call != NULL; call = call->next)
    if (!call->is_pasted && !call->broken_cycle)
      {
	if (!collect_overlays (call->fun, info, ovly_sections))
	  return FALSE;
	break;
      }

  added_fun = FALSE;
  if (fun->sec->linker_mark && fun->sec->gc_mark)
    {
      fun->sec->gc_mark = 0;
      *(*ovly_sections)++ = fun->sec;
      if (fun->rodata && fun->rodata->linker_mark && fun->rodata->gc_mark)
	{
	  fun->rodata->gc_mark = 0;
	  *(*ovly_sections)++ = fun->rodata;
	}
      else
	*(*ovly_sections)++ = NULL;
      added_fun = TRUE;

      /* Pasted sections must stay with the first section.  We don't
	 put pasted sections in the array, just the first section.
	 Mark subsequent sections as already considered.  */
      if (fun->sec->segment_mark)
	{
	  struct function_info *call_fun = fun;
	  do
	    {
	      for (call = call_fun->call_list; call != NULL; call = call->next)
		if (call->is_pasted)
		  {
		    call_fun = call->fun;
		    call_fun->sec->gc_mark = 0;
		    if (call_fun->rodata)
		      call_fun->rodata->gc_mark = 0;
		    break;
		  }
	      if (call == NULL)
		abort ();
	    }
	  while (call_fun->sec->segment_mark);
	}
    }

  for (call = fun->call_list; call != NULL; call = call->next)
    if (!call->broken_cycle
	&& !collect_overlays (call->fun, info, ovly_sections))
      return FALSE;

  if (added_fun)
    {
      struct _spu_elf_section_data *sec_data;
      struct spu_elf_stack_info *sinfo;

      if ((sec_data = spu_elf_section_data (fun->sec)) != NULL
	  && (sinfo = sec_data->u.i.stack_info) != NULL)
	{
	  int i;
	  for (i = 0; i < sinfo->num_fun; ++i)
	    if (!collect_overlays (&sinfo->fun[i], info, ovly_sections))
	      return FALSE;
	}
    }

  return TRUE;
}

struct _sum_stack_param {
  size_t cum_stack;
  size_t overall_stack;
  bfd_boolean emit_stack_syms;
};

/* Descend the call graph for FUN, accumulating total stack required.  */

static bfd_boolean
sum_stack (struct function_info *fun,
	   struct bfd_link_info *info,
	   void *param)
{
  struct call_info *call;
  struct function_info *max;
  size_t stack, cum_stack;
  const char *f1;
  bfd_boolean has_call;
  struct _sum_stack_param *sum_stack_param = param;
  struct spu_link_hash_table *htab;

  cum_stack = fun->stack;
  sum_stack_param->cum_stack = cum_stack;
  if (fun->visit3)
    return TRUE;

  has_call = FALSE;
  max = NULL;
  for (call = fun->call_list; call; call = call->next)
    {
      if (call->broken_cycle)
	continue;
      if (!call->is_pasted)
	has_call = TRUE;
      if (!sum_stack (call->fun, info, sum_stack_param))
	return FALSE;
      stack = sum_stack_param->cum_stack;
      /* Include caller stack for normal calls, don't do so for
	 tail calls.  fun->stack here is local stack usage for
	 this function.  */
      if (!call->is_tail || call->is_pasted || call->fun->start != NULL)
	stack += fun->stack;
      if (cum_stack < stack)
	{
	  cum_stack = stack;
	  max = call->fun;
	}
    }

  sum_stack_param->cum_stack = cum_stack;
  stack = fun->stack;
  /* Now fun->stack holds cumulative stack.  */
  fun->stack = cum_stack;
  fun->visit3 = TRUE;

  if (!fun->non_root
      && sum_stack_param->overall_stack < cum_stack)
    sum_stack_param->overall_stack = cum_stack;

  htab = spu_hash_table (info);
  if (htab->params->auto_overlay)
    return TRUE;

  f1 = func_name (fun);
  if (htab->params->stack_analysis)
    {
      if (!fun->non_root)
	info->callbacks->info (_("  %s: 0x%v\n"), f1, (bfd_vma) cum_stack);
      info->callbacks->minfo (_("%s: 0x%v 0x%v\n"),
			      f1, (bfd_vma) stack, (bfd_vma) cum_stack);

      if (has_call)
	{
	  info->callbacks->minfo (_("  calls:\n"));
	  for (call = fun->call_list; call; call = call->next)
	    if (!call->is_pasted && !call->broken_cycle)
	      {
		const char *f2 = func_name (call->fun);
		const char *ann1 = call->fun == max ? "*" : " ";
		const char *ann2 = call->is_tail ? "t" : " ";

		info->callbacks->minfo (_("   %s%s %s\n"), ann1, ann2, f2);
	      }
	}
    }

  if (sum_stack_param->emit_stack_syms)
    {
      char *name = bfd_malloc (18 + strlen (f1));
      struct elf_link_hash_entry *h;

      if (name == NULL)
	return FALSE;

      if (fun->global || ELF_ST_BIND (fun->u.sym->st_info) == STB_GLOBAL)
	sprintf (name, "__stack_%s", f1);
      else
	sprintf (name, "__stack_%x_%s", fun->sec->id & 0xffffffff, f1);

      h = elf_link_hash_lookup (&htab->elf, name, TRUE, TRUE, FALSE);
      free (name);
      if (h != NULL
	  && (h->root.type == bfd_link_hash_new
	      || h->root.type == bfd_link_hash_undefined
	      || h->root.type == bfd_link_hash_undefweak))
	{
	  h->root.type = bfd_link_hash_defined;
	  h->root.u.def.section = bfd_abs_section_ptr;
	  h->root.u.def.value = cum_stack;
	  h->size = 0;
	  h->type = 0;
	  h->ref_regular = 1;
	  h->def_regular = 1;
	  h->ref_regular_nonweak = 1;
	  h->forced_local = 1;
	  h->non_elf = 0;
	}
    }

  return TRUE;
}

/* SEC is part of a pasted function.  Return the call_info for the
   next section of this function.  */

static struct call_info *
find_pasted_call (asection *sec)
{
  struct _spu_elf_section_data *sec_data = spu_elf_section_data (sec);
  struct spu_elf_stack_info *sinfo = sec_data->u.i.stack_info;
  struct call_info *call;
  int k;

  for (k = 0; k < sinfo->num_fun; ++k)
    for (call = sinfo->fun[k].call_list; call != NULL; call = call->next)
      if (call->is_pasted)
	return call;
  abort ();
  return 0;
}

/* qsort predicate to sort bfds by file name.  */

static int
sort_bfds (const void *a, const void *b)
{
  bfd *const *abfd1 = a;
  bfd *const *abfd2 = b;

  return filename_cmp ((*abfd1)->filename, (*abfd2)->filename);
}

static unsigned int
print_one_overlay_section (FILE *script,
			   unsigned int base,
			   unsigned int count,
			   unsigned int ovlynum,
			   unsigned int *ovly_map,
			   asection **ovly_sections,
			   struct bfd_link_info *info)
{
  unsigned int j;

  for (j = base; j < count && ovly_map[j] == ovlynum; j++)
    {
      asection *sec = ovly_sections[2 * j];

      if (fprintf (script, "   %s%c%s (%s)\n",
		   (sec->owner->my_archive != NULL
		    ? sec->owner->my_archive->filename : ""),
		   info->path_separator,
		   sec->owner->filename,
		   sec->name) <= 0)
	return -1;
      if (sec->segment_mark)
	{
	  struct call_info *call = find_pasted_call (sec);
	  while (call != NULL)
	    {
	      struct function_info *call_fun = call->fun;
	      sec = call_fun->sec;
	      if (fprintf (script, "   %s%c%s (%s)\n",
			   (sec->owner->my_archive != NULL
			    ? sec->owner->my_archive->filename : ""),
			   info->path_separator,
			   sec->owner->filename,
			   sec->name) <= 0)
		return -1;
	      for (call = call_fun->call_list; call; call = call->next)
		if (call->is_pasted)
		  break;
	    }
	}
    }

  for (j = base; j < count && ovly_map[j] == ovlynum; j++)
    {
      asection *sec = ovly_sections[2 * j + 1];
      if (sec != NULL
	  && fprintf (script, "   %s%c%s (%s)\n",
		      (sec->owner->my_archive != NULL
		       ? sec->owner->my_archive->filename : ""),
		      info->path_separator,
		      sec->owner->filename,
		      sec->name) <= 0)
	return -1;

      sec = ovly_sections[2 * j];
      if (sec->segment_mark)
	{
	  struct call_info *call = find_pasted_call (sec);
	  while (call != NULL)
	    {
	      struct function_info *call_fun = call->fun;
	      sec = call_fun->rodata;
	      if (sec != NULL
		  && fprintf (script, "   %s%c%s (%s)\n",
			      (sec->owner->my_archive != NULL
			       ? sec->owner->my_archive->filename : ""),
			      info->path_separator,
			      sec->owner->filename,
			      sec->name) <= 0)
		return -1;
	      for (call = call_fun->call_list; call; call = call->next)
		if (call->is_pasted)
		  break;
	    }
	}
    }

  return j;
}

/* Handle --auto-overlay.  */

static void
spu_elf_auto_overlay (struct bfd_link_info *info)
{
  bfd *ibfd;
  bfd **bfd_arr;
  struct elf_segment_map *m;
  unsigned int fixed_size, lo, hi;
  unsigned int reserved;
  struct spu_link_hash_table *htab;
  unsigned int base, i, count, bfd_count;
  unsigned int region, ovlynum;
  asection **ovly_sections, **ovly_p;
  unsigned int *ovly_map;
  FILE *script;
  unsigned int total_overlay_size, overlay_size;
  const char *ovly_mgr_entry;
  struct elf_link_hash_entry *h;
  struct _mos_param mos_param;
  struct _uos_param uos_param;
  struct function_info dummy_caller;

  /* Find the extents of our loadable image.  */
  lo = (unsigned int) -1;
  hi = 0;
  for (m = elf_seg_map (info->output_bfd); m != NULL; m = m->next)
    if (m->p_type == PT_LOAD)
      for (i = 0; i < m->count; i++)
	if (m->sections[i]->size != 0)
	  {
	    if (m->sections[i]->vma < lo)
	      lo = m->sections[i]->vma;
	    if (m->sections[i]->vma + m->sections[i]->size - 1 > hi)
	      hi = m->sections[i]->vma + m->sections[i]->size - 1;
	  }
  fixed_size = hi + 1 - lo;

  if (!discover_functions (info))
    goto err_exit;

  if (!build_call_tree (info))
    goto err_exit;

  htab = spu_hash_table (info);
  reserved = htab->params->auto_overlay_reserved;
  if (reserved == 0)
    {
      struct _sum_stack_param sum_stack_param;

      sum_stack_param.emit_stack_syms = 0;
      sum_stack_param.overall_stack = 0;
      if (!for_each_node (sum_stack, info, &sum_stack_param, TRUE))
	goto err_exit;
      reserved = (sum_stack_param.overall_stack
		  + htab->params->extra_stack_space);
    }

  /* No need for overlays if everything already fits.  */
  if (fixed_size + reserved <= htab->local_store
      && htab->params->ovly_flavour != ovly_soft_icache)
    {
      htab->params->auto_overlay = 0;
      return;
    }

  uos_param.exclude_input_section = 0;
  uos_param.exclude_output_section
    = bfd_get_section_by_name (info->output_bfd, ".interrupt");

  ovly_mgr_entry = "__ovly_load";
  if (htab->params->ovly_flavour == ovly_soft_icache)
    ovly_mgr_entry = "__icache_br_handler";
  h = elf_link_hash_lookup (&htab->elf, ovly_mgr_entry,
			    FALSE, FALSE, FALSE);
  if (h != NULL
      && (h->root.type == bfd_link_hash_defined
	  || h->root.type == bfd_link_hash_defweak)
      && h->def_regular)
    {
      /* We have a user supplied overlay manager.  */
      uos_param.exclude_input_section = h->root.u.def.section;
    }
  else
    {
      /* If no user overlay manager, spu_elf_load_ovl_mgr will add our
	 builtin version to .text, and will adjust .text size.  */
      fixed_size += (*htab->params->spu_elf_load_ovl_mgr) ();
    }

  /* Mark overlay sections, and find max overlay section size.  */
  mos_param.max_overlay_size = 0;
  if (!for_each_node (mark_overlay_section, info, &mos_param, TRUE))
    goto err_exit;

  /* We can't put the overlay manager or interrupt routines in
     overlays.  */
  uos_param.clearing = 0;
  if ((uos_param.exclude_input_section
       || uos_param.exclude_output_section)
      && !for_each_node (unmark_overlay_section, info, &uos_param, TRUE))
    goto err_exit;

  bfd_count = 0;
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    ++bfd_count;
  bfd_arr = bfd_malloc (bfd_count * sizeof (*bfd_arr));
  if (bfd_arr == NULL)
    goto err_exit;

  /* Count overlay sections, and subtract their sizes from "fixed_size".  */
  count = 0;
  bfd_count = 0;
  total_overlay_size = 0;
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      asection *sec;
      unsigned int old_count;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      old_count = count;
      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	if (sec->linker_mark)
	  {
	    if ((sec->flags & SEC_CODE) != 0)
	      count += 1;
	    fixed_size -= sec->size;
	    total_overlay_size += sec->size;
	  }
	else if ((sec->flags & (SEC_ALLOC | SEC_LOAD)) == (SEC_ALLOC | SEC_LOAD)
		 && sec->output_section->owner == info->output_bfd
		 && strncmp (sec->output_section->name, ".ovl.init", 9) == 0)
	  fixed_size -= sec->size;
      if (count != old_count)
	bfd_arr[bfd_count++] = ibfd;
    }

  /* Since the overlay link script selects sections by file name and
     section name, ensure that file names are unique.  */
  if (bfd_count > 1)
    {
      bfd_boolean ok = TRUE;

      qsort (bfd_arr, bfd_count, sizeof (*bfd_arr), sort_bfds);
      for (i = 1; i < bfd_count; ++i)
	if (filename_cmp (bfd_arr[i - 1]->filename, bfd_arr[i]->filename) == 0)
	  {
	    if (bfd_arr[i - 1]->my_archive == bfd_arr[i]->my_archive)
	      {
		if (bfd_arr[i - 1]->my_archive && bfd_arr[i]->my_archive)
		  info->callbacks->einfo (_("%s duplicated in %s\n"),
					  bfd_arr[i]->filename,
					  bfd_arr[i]->my_archive->filename);
		else
		  info->callbacks->einfo (_("%s duplicated\n"),
					  bfd_arr[i]->filename);
		ok = FALSE;
	      }
	  }
      if (!ok)
	{
	  info->callbacks->einfo (_("sorry, no support for duplicate "
				    "object files in auto-overlay script\n"));
	  bfd_set_error (bfd_error_bad_value);
	  goto err_exit;
	}
    }
  free (bfd_arr);

  fixed_size += reserved;
  fixed_size += htab->non_ovly_stub * ovl_stub_size (htab->params);
  if (fixed_size + mos_param.max_overlay_size <= htab->local_store)
    {
      if (htab->params->ovly_flavour == ovly_soft_icache)
	{
	  /* Stubs in the non-icache area are bigger.  */
	  fixed_size += htab->non_ovly_stub * 16;
	  /* Space for icache manager tables.
	     a) Tag array, one quadword per cache line.
	     - word 0: ia address of present line, init to zero.  */
	  fixed_size += 16 << htab->num_lines_log2;
	  /* b) Rewrite "to" list, one quadword per cache line.  */
	  fixed_size += 16 << htab->num_lines_log2;
	  /* c) Rewrite "from" list, one byte per outgoing branch (rounded up
		to a power-of-two number of full quadwords) per cache line.  */
	  fixed_size += 16 << (htab->fromelem_size_log2
			       + htab->num_lines_log2);
	  /* d) Pointer to __ea backing store (toe), 1 quadword.  */
	  fixed_size += 16;
	}
      else
	{
	  /* Guess number of overlays.  Assuming overlay buffer is on
	     average only half full should be conservative.  */
	  ovlynum = (total_overlay_size * 2 * htab->params->num_lines
		     / (htab->local_store - fixed_size));
	  /* Space for _ovly_table[], _ovly_buf_table[] and toe.  */
	  fixed_size += ovlynum * 16 + 16 + 4 + 16;
	}
    }

  if (fixed_size + mos_param.max_overlay_size > htab->local_store)
    info->callbacks->einfo (_("non-overlay size of 0x%v plus maximum overlay "
			      "size of 0x%v exceeds local store\n"),
			    (bfd_vma) fixed_size,
			    (bfd_vma) mos_param.max_overlay_size);

  /* Now see if we should put some functions in the non-overlay area.  */
  else if (fixed_size < htab->params->auto_overlay_fixed)
    {
      unsigned int max_fixed, lib_size;

      max_fixed = htab->local_store - mos_param.max_overlay_size;
      if (max_fixed > htab->params->auto_overlay_fixed)
	max_fixed = htab->params->auto_overlay_fixed;
      lib_size = max_fixed - fixed_size;
      lib_size = auto_ovl_lib_functions (info, lib_size);
      if (lib_size == (unsigned int) -1)
	goto err_exit;
      fixed_size = max_fixed - lib_size;
    }

  /* Build an array of sections, suitably sorted to place into
     overlays.  */
  ovly_sections = bfd_malloc (2 * count * sizeof (*ovly_sections));
  if (ovly_sections == NULL)
    goto err_exit;
  ovly_p = ovly_sections;
  if (!for_each_node (collect_overlays, info, &ovly_p, TRUE))
    goto err_exit;
  count = (size_t) (ovly_p - ovly_sections) / 2;
  ovly_map = bfd_malloc (count * sizeof (*ovly_map));
  if (ovly_map == NULL)
    goto err_exit;

  memset (&dummy_caller, 0, sizeof (dummy_caller));
  overlay_size = (htab->local_store - fixed_size) / htab->params->num_lines;
  if (htab->params->line_size != 0)
    overlay_size = htab->params->line_size;
  base = 0;
  ovlynum = 0;
  while (base < count)
    {
      unsigned int size = 0, rosize = 0, roalign = 0;

      for (i = base; i < count; i++)
	{
	  asection *sec, *rosec;
	  unsigned int tmp, rotmp;
	  unsigned int num_stubs;
	  struct call_info *call, *pasty;
	  struct _spu_elf_section_data *sec_data;
	  struct spu_elf_stack_info *sinfo;
	  unsigned int k;

	  /* See whether we can add this section to the current
	     overlay without overflowing our overlay buffer.  */
	  sec = ovly_sections[2 * i];
	  tmp = align_power (size, sec->alignment_power) + sec->size;
	  rotmp = rosize;
	  rosec = ovly_sections[2 * i + 1];
	  if (rosec != NULL)
	    {
	      rotmp = align_power (rotmp, rosec->alignment_power) + rosec->size;
	      if (roalign < rosec->alignment_power)
		roalign = rosec->alignment_power;
	    }
	  if (align_power (tmp, roalign) + rotmp > overlay_size)
	    break;
	  if (sec->segment_mark)
	    {
	      /* Pasted sections must stay together, so add their
		 sizes too.  */
	      pasty = find_pasted_call (sec);
	      while (pasty != NULL)
		{
		  struct function_info *call_fun = pasty->fun;
		  tmp = (align_power (tmp, call_fun->sec->alignment_power)
			 + call_fun->sec->size);
		  if (call_fun->rodata)
		    {
		      rotmp = (align_power (rotmp,
					    call_fun->rodata->alignment_power)
			       + call_fun->rodata->size);
		      if (roalign < rosec->alignment_power)
			roalign = rosec->alignment_power;
		    }
		  for (pasty = call_fun->call_list; pasty; pasty = pasty->next)
		    if (pasty->is_pasted)
		      break;
		}
	    }
	  if (align_power (tmp, roalign) + rotmp > overlay_size)
	    break;

	  /* If we add this section, we might need new overlay call
	     stubs.  Add any overlay section calls to dummy_call.  */
	  pasty = NULL;
	  sec_data = spu_elf_section_data (sec);
	  sinfo = sec_data->u.i.stack_info;
	  for (k = 0; k < (unsigned) sinfo->num_fun; ++k)
	    for (call = sinfo->fun[k].call_list; call; call = call->next)
	      if (call->is_pasted)
		{
		  BFD_ASSERT (pasty == NULL);
		  pasty = call;
		}
	      else if (call->fun->sec->linker_mark)
		{
		  if (!copy_callee (&dummy_caller, call))
		    goto err_exit;
		}
	  while (pasty != NULL)
	    {
	      struct function_info *call_fun = pasty->fun;
	      pasty = NULL;
	      for (call = call_fun->call_list; call; call = call->next)
		if (call->is_pasted)
		  {
		    BFD_ASSERT (pasty == NULL);
		    pasty = call;
		  }
		else if (!copy_callee (&dummy_caller, call))
		  goto err_exit;
	    }

	  /* Calculate call stub size.  */
	  num_stubs = 0;
	  for (call = dummy_caller.call_list; call; call = call->next)
	    {
	      unsigned int stub_delta = 1;

	      if (htab->params->ovly_flavour == ovly_soft_icache)
		stub_delta = call->count;
	      num_stubs += stub_delta;

	      /* If the call is within this overlay, we won't need a
		 stub.  */
	      for (k = base; k < i + 1; k++)
		if (call->fun->sec == ovly_sections[2 * k])
		  {
		    num_stubs -= stub_delta;
		    break;
		  }
	    }
	  if (htab->params->ovly_flavour == ovly_soft_icache
	      && num_stubs > htab->params->max_branch)
	    break;
	  if (align_power (tmp, roalign) + rotmp
	      + num_stubs * ovl_stub_size (htab->params) > overlay_size)
	    break;
	  size = tmp;
	  rosize = rotmp;
	}

      if (i == base)
	{
	  info->callbacks->einfo (_("%B:%A%s exceeds overlay size\n"),
				  ovly_sections[2 * i]->owner,
				  ovly_sections[2 * i],
				  ovly_sections[2 * i + 1] ? " + rodata" : "");
	  bfd_set_error (bfd_error_bad_value);
	  goto err_exit;
	}

      while (dummy_caller.call_list != NULL)
	{
	  struct call_info *call = dummy_caller.call_list;
	  dummy_caller.call_list = call->next;
	  free (call);
	}

      ++ovlynum;
      while (base < i)
	ovly_map[base++] = ovlynum;
    }

  script = htab->params->spu_elf_open_overlay_script ();

  if (htab->params->ovly_flavour == ovly_soft_icache)
    {
      if (fprintf (script, "SECTIONS\n{\n") <= 0)
	goto file_err;

      if (fprintf (script,
		   " . = ALIGN (%u);\n"
		   " .ovl.init : { *(.ovl.init) }\n"
		   " . = ABSOLUTE (ADDR (.ovl.init));\n",
		   htab->params->line_size) <= 0)
	goto file_err;

      base = 0;
      ovlynum = 1;
      while (base < count)
	{
	  unsigned int indx = ovlynum - 1;
	  unsigned int vma, lma;

	  vma = (indx & (htab->params->num_lines - 1)) << htab->line_size_log2;
	  lma = vma + (((indx >> htab->num_lines_log2) + 1) << 18);

	  if (fprintf (script, " .ovly%u ABSOLUTE (ADDR (.ovl.init)) + %u "
			       ": AT (LOADADDR (.ovl.init) + %u) {\n",
		       ovlynum, vma, lma) <= 0)
	    goto file_err;

	  base = print_one_overlay_section (script, base, count, ovlynum,
					    ovly_map, ovly_sections, info);
	  if (base == (unsigned) -1)
	    goto file_err;

	  if (fprintf (script, "  }\n") <= 0)
	    goto file_err;

	  ovlynum++;
	}

      if (fprintf (script, " . = ABSOLUTE (ADDR (.ovl.init)) + %u;\n",
		   1 << (htab->num_lines_log2 + htab->line_size_log2)) <= 0)
	goto file_err;

      if (fprintf (script, "}\nINSERT AFTER .toe;\n") <= 0)
	goto file_err;
    }
  else
    {
      if (fprintf (script, "SECTIONS\n{\n") <= 0)
	goto file_err;

      if (fprintf (script,
		   " . = ALIGN (16);\n"
		   " .ovl.init : { *(.ovl.init) }\n"
		   " . = ABSOLUTE (ADDR (.ovl.init));\n") <= 0)
	goto file_err;

      for (region = 1; region <= htab->params->num_lines; region++)
	{
	  ovlynum = region;
	  base = 0;
	  while (base < count && ovly_map[base] < ovlynum)
	    base++;

	  if (base == count)
	    break;

	  if (region == 1)
	    {
	      /* We need to set lma since we are overlaying .ovl.init.  */
	      if (fprintf (script,
			   " OVERLAY : AT (ALIGN (LOADADDR (.ovl.init) + SIZEOF (.ovl.init), 16))\n {\n") <= 0)
		goto file_err;
	    }
	  else
	    {
	      if (fprintf (script, " OVERLAY :\n {\n") <= 0)
		goto file_err;
	    }

	  while (base < count)
	    {
	      if (fprintf (script, "  .ovly%u {\n", ovlynum) <= 0)
		goto file_err;

	      base = print_one_overlay_section (script, base, count, ovlynum,
						ovly_map, ovly_sections, info);
	      if (base == (unsigned) -1)
		goto file_err;

	      if (fprintf (script, "  }\n") <= 0)
		goto file_err;

	      ovlynum += htab->params->num_lines;
	      while (base < count && ovly_map[base] < ovlynum)
		base++;
	    }

	  if (fprintf (script, " }\n") <= 0)
	    goto file_err;
	}

      if (fprintf (script, "}\nINSERT BEFORE .text;\n") <= 0)
	goto file_err;
    }

  free (ovly_map);
  free (ovly_sections);

  if (fclose (script) != 0)
    goto file_err;

  if (htab->params->auto_overlay & AUTO_RELINK)
    (*htab->params->spu_elf_relink) ();

  xexit (0);

 file_err:
  bfd_set_error (bfd_error_system_call);
 err_exit:
  info->callbacks->einfo ("%F%P: auto overlay error: %E\n");
  xexit (1);
}

/* Provide an estimate of total stack required.  */

static bfd_boolean
spu_elf_stack_analysis (struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab;
  struct _sum_stack_param sum_stack_param;

  if (!discover_functions (info))
    return FALSE;

  if (!build_call_tree (info))
    return FALSE;

  htab = spu_hash_table (info);
  if (htab->params->stack_analysis)
    {
      info->callbacks->info (_("Stack size for call graph root nodes.\n"));
      info->callbacks->minfo (_("\nStack size for functions.  "
				"Annotations: '*' max stack, 't' tail call\n"));
    }

  sum_stack_param.emit_stack_syms = htab->params->emit_stack_syms;
  sum_stack_param.overall_stack = 0;
  if (!for_each_node (sum_stack, info, &sum_stack_param, TRUE))
    return FALSE;

  if (htab->params->stack_analysis)
    info->callbacks->info (_("Maximum stack required is 0x%v\n"),
			   (bfd_vma) sum_stack_param.overall_stack);
  return TRUE;
}

/* Perform a final link.  */

static bfd_boolean
spu_elf_final_link (bfd *output_bfd, struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);

  if (htab->params->auto_overlay)
    spu_elf_auto_overlay (info);

  if ((htab->params->stack_analysis
       || (htab->params->ovly_flavour == ovly_soft_icache
	   && htab->params->lrlive_analysis))
      && !spu_elf_stack_analysis (info))
    info->callbacks->einfo ("%X%P: stack/lrlive analysis error: %E\n");

  if (!spu_elf_build_stubs (info))
    info->callbacks->einfo ("%F%P: can not build overlay stubs: %E\n");

  return bfd_elf_final_link (output_bfd, info);
}

/* Called when not normally emitting relocs, ie. !info->relocatable
   and !info->emitrelocations.  Returns a count of special relocs
   that need to be emitted.  */

static unsigned int
spu_elf_count_relocs (struct bfd_link_info *info, asection *sec)
{
  Elf_Internal_Rela *relocs;
  unsigned int count = 0;

  relocs = _bfd_elf_link_read_relocs (sec->owner, sec, NULL, NULL,
				      info->keep_memory);
  if (relocs != NULL)
    {
      Elf_Internal_Rela *rel;
      Elf_Internal_Rela *relend = relocs + sec->reloc_count;

      for (rel = relocs; rel < relend; rel++)
	{
	  int r_type = ELF32_R_TYPE (rel->r_info);
	  if (r_type == R_SPU_PPU32 || r_type == R_SPU_PPU64)
	    ++count;
	}

      if (elf_section_data (sec)->relocs != relocs)
	free (relocs);
    }

  return count;
}

/* Functions for adding fixup records to .fixup */

#define FIXUP_RECORD_SIZE 4

#define FIXUP_PUT(output_bfd,htab,index,addr) \
	  bfd_put_32 (output_bfd, addr, \
		      htab->sfixup->contents + FIXUP_RECORD_SIZE * (index))
#define FIXUP_GET(output_bfd,htab,index) \
	  bfd_get_32 (output_bfd, \
		      htab->sfixup->contents + FIXUP_RECORD_SIZE * (index))

/* Store OFFSET in .fixup.  This assumes it will be called with an
   increasing OFFSET.  When this OFFSET fits with the last base offset,
   it just sets a bit, otherwise it adds a new fixup record.  */
static void
spu_elf_emit_fixup (bfd * output_bfd, struct bfd_link_info *info,
		    bfd_vma offset)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  asection *sfixup = htab->sfixup;
  bfd_vma qaddr = offset & ~(bfd_vma) 15;
  bfd_vma bit = ((bfd_vma) 8) >> ((offset & 15) >> 2);
  if (sfixup->reloc_count == 0)
    {
      FIXUP_PUT (output_bfd, htab, 0, qaddr | bit);
      sfixup->reloc_count++;
    }
  else
    {
      bfd_vma base = FIXUP_GET (output_bfd, htab, sfixup->reloc_count - 1);
      if (qaddr != (base & ~(bfd_vma) 15))
	{
	  if ((sfixup->reloc_count + 1) * FIXUP_RECORD_SIZE > sfixup->size)
	    (*_bfd_error_handler) (_("fatal error while creating .fixup"));
	  FIXUP_PUT (output_bfd, htab, sfixup->reloc_count, qaddr | bit);
	  sfixup->reloc_count++;
	}
      else
	FIXUP_PUT (output_bfd, htab, sfixup->reloc_count - 1, base | bit);
    }
}

/* Apply RELOCS to CONTENTS of INPUT_SECTION from INPUT_BFD.  */

static int
spu_elf_relocate_section (bfd *output_bfd,
			  struct bfd_link_info *info,
			  bfd *input_bfd,
			  asection *input_section,
			  bfd_byte *contents,
			  Elf_Internal_Rela *relocs,
			  Elf_Internal_Sym *local_syms,
			  asection **local_sections)
{
  Elf_Internal_Shdr *symtab_hdr;
  struct elf_link_hash_entry **sym_hashes;
  Elf_Internal_Rela *rel, *relend;
  struct spu_link_hash_table *htab;
  asection *ea;
  int ret = TRUE;
  bfd_boolean emit_these_relocs = FALSE;
  bfd_boolean is_ea_sym;
  bfd_boolean stubs;
  unsigned int iovl = 0;

  htab = spu_hash_table (info);
  stubs = (htab->stub_sec != NULL
	   && maybe_needs_stubs (input_section));
  iovl = overlay_index (input_section);
  ea = bfd_get_section_by_name (output_bfd, "._ea");
  symtab_hdr = &elf_tdata (input_bfd)->symtab_hdr;
  sym_hashes = (struct elf_link_hash_entry **) (elf_sym_hashes (input_bfd));

  rel = relocs;
  relend = relocs + input_section->reloc_count;
  for (; rel < relend; rel++)
    {
      int r_type;
      reloc_howto_type *howto;
      unsigned int r_symndx;
      Elf_Internal_Sym *sym;
      asection *sec;
      struct elf_link_hash_entry *h;
      const char *sym_name;
      bfd_vma relocation;
      bfd_vma addend;
      bfd_reloc_status_type r;
      bfd_boolean unresolved_reloc;
      enum _stub_type stub_type;

      r_symndx = ELF32_R_SYM (rel->r_info);
      r_type = ELF32_R_TYPE (rel->r_info);
      howto = elf_howto_table + r_type;
      unresolved_reloc = FALSE;
      h = NULL;
      sym = NULL;
      sec = NULL;
      if (r_symndx < symtab_hdr->sh_info)
	{
	  sym = local_syms + r_symndx;
	  sec = local_sections[r_symndx];
	  sym_name = bfd_elf_sym_name (input_bfd, symtab_hdr, sym, sec);
	  relocation = _bfd_elf_rela_local_sym (output_bfd, sym, &sec, rel);
	}
      else
	{
	  if (sym_hashes == NULL)
	    return FALSE;

	  h = sym_hashes[r_symndx - symtab_hdr->sh_info];

	  while (h->root.type == bfd_link_hash_indirect
		 || h->root.type == bfd_link_hash_warning)
	    h = (struct elf_link_hash_entry *) h->root.u.i.link;

	  relocation = 0;
	  if (h->root.type == bfd_link_hash_defined
	      || h->root.type == bfd_link_hash_defweak)
	    {
	      sec = h->root.u.def.section;
	      if (sec == NULL
		  || sec->output_section == NULL)
		/* Set a flag that will be cleared later if we find a
		   relocation value for this symbol.  output_section
		   is typically NULL for symbols satisfied by a shared
		   library.  */
		unresolved_reloc = TRUE;
	      else
		relocation = (h->root.u.def.value
			      + sec->output_section->vma
			      + sec->output_offset);
	    }
	  else if (h->root.type == bfd_link_hash_undefweak)
	    ;
	  else if (info->unresolved_syms_in_objects == RM_IGNORE
		   && ELF_ST_VISIBILITY (h->other) == STV_DEFAULT)
	    ;
	  else if (!info->relocatable
		   && !(r_type == R_SPU_PPU32 || r_type == R_SPU_PPU64))
	    {
	      bfd_boolean err;
	      err = (info->unresolved_syms_in_objects == RM_GENERATE_ERROR
		     || ELF_ST_VISIBILITY (h->other) != STV_DEFAULT);
	      if (!info->callbacks->undefined_symbol (info,
						      h->root.root.string,
						      input_bfd,
						      input_section,
						      rel->r_offset, err))
		return FALSE;
	    }
	  sym_name = h->root.root.string;
	}

      if (sec != NULL && discarded_section (sec))
	RELOC_AGAINST_DISCARDED_SECTION (info, input_bfd, input_section,
					 rel, 1, relend, howto, 0, contents);

      if (info->relocatable)
	continue;

      /* Change "a rt,ra,rb" to "ai rt,ra,0". */
      if (r_type == R_SPU_ADD_PIC
	  && h != NULL
	  && !(h->def_regular || ELF_COMMON_DEF_P (h)))
	{
	  bfd_byte *loc = contents + rel->r_offset;
	  loc[0] = 0x1c;
	  loc[1] = 0x00;
	  loc[2] &= 0x3f;
	}

      is_ea_sym = (ea != NULL
		   && sec != NULL
		   && sec->output_section == ea);

      /* If this symbol is in an overlay area, we may need to relocate
	 to the overlay stub.  */
      addend = rel->r_addend;
      if (stubs
	  && !is_ea_sym
	  && (stub_type = needs_ovl_stub (h, sym, sec, input_section, rel,
					  contents, info)) != no_stub)
	{
	  unsigned int ovl = 0;
	  struct got_entry *g, **head;

	  if (stub_type != nonovl_stub)
	    ovl = iovl;

	  if (h != NULL)
	    head = &h->got.glist;
	  else
	    head = elf_local_got_ents (input_bfd) + r_symndx;

	  for (g = *head; g != NULL; g = g->next)
	    if (htab->params->ovly_flavour == ovly_soft_icache
		? (g->ovl == ovl
		   && g->br_addr == (rel->r_offset
				     + input_section->output_offset
				     + input_section->output_section->vma))
		: g->addend == addend && (g->ovl == ovl || g->ovl == 0))
	      break;
	  if (g == NULL)
	    abort ();

	  relocation = g->stub_addr;
	  addend = 0;
	}
      else
	{
	  /* For soft icache, encode the overlay index into addresses.  */
	  if (htab->params->ovly_flavour == ovly_soft_icache
	      && (r_type == R_SPU_ADDR16_HI
		  || r_type == R_SPU_ADDR32 || r_type == R_SPU_REL32)
	      && !is_ea_sym)
	    {
	      unsigned int ovl = overlay_index (sec);
	      if (ovl != 0)
		{
		  unsigned int set_id = ((ovl - 1) >> htab->num_lines_log2) + 1;
		  relocation += set_id << 18;
		}
	    }
	}

      if (htab->params->emit_fixups && !info->relocatable
	  && (input_section->flags & SEC_ALLOC) != 0
	  && r_type == R_SPU_ADDR32)
	{
	  bfd_vma offset;
	  offset = rel->r_offset + input_section->output_section->vma
		   + input_section->output_offset;
	  spu_elf_emit_fixup (output_bfd, info, offset);
	}

      if (unresolved_reloc)
	;
      else if (r_type == R_SPU_PPU32 || r_type == R_SPU_PPU64)
	{
	  if (is_ea_sym)
	    {
	      /* ._ea is a special section that isn't allocated in SPU
		 memory, but rather occupies space in PPU memory as
		 part of an embedded ELF image.  If this reloc is
		 against a symbol defined in ._ea, then transform the
		 reloc into an equivalent one without a symbol
		 relative to the start of the ELF image.  */
	      rel->r_addend += (relocation
				- ea->vma
				+ elf_section_data (ea)->this_hdr.sh_offset);
	      rel->r_info = ELF32_R_INFO (0, r_type);
	    }
	  emit_these_relocs = TRUE;
	  continue;
	}
      else if (is_ea_sym)
	unresolved_reloc = TRUE;

      if (unresolved_reloc
	  && _bfd_elf_section_offset (output_bfd, info, input_section,
				      rel->r_offset) != (bfd_vma) -1)
	{
	  (*_bfd_error_handler)
	    (_("%B(%s+0x%lx): unresolvable %s relocation against symbol `%s'"),
	     input_bfd,
	     bfd_get_section_name (input_bfd, input_section),
	     (long) rel->r_offset,
	     howto->name,
	     sym_name);
	  ret = FALSE;
	}

      r = _bfd_final_link_relocate (howto,
				    input_bfd,
				    input_section,
				    contents,
				    rel->r_offset, relocation, addend);

      if (r != bfd_reloc_ok)
	{
	  const char *msg = (const char *) 0;

	  switch (r)
	    {
	    case bfd_reloc_overflow:
	      if (!((*info->callbacks->reloc_overflow)
		    (info, (h ? &h->root : NULL), sym_name, howto->name,
		     (bfd_vma) 0, input_bfd, input_section, rel->r_offset)))
		return FALSE;
	      break;

	    case bfd_reloc_undefined:
	      if (!((*info->callbacks->undefined_symbol)
		    (info, sym_name, input_bfd, input_section,
		     rel->r_offset, TRUE)))
		return FALSE;
	      break;

	    case bfd_reloc_outofrange:
	      msg = _("internal error: out of range error");
	      goto common_error;

	    case bfd_reloc_notsupported:
	      msg = _("internal error: unsupported relocation error");
	      goto common_error;

	    case bfd_reloc_dangerous:
	      msg = _("internal error: dangerous error");
	      goto common_error;

	    default:
	      msg = _("internal error: unknown error");
	      /* fall through */

	    common_error:
	      ret = FALSE;
	      if (!((*info->callbacks->warning)
		    (info, msg, sym_name, input_bfd, input_section,
		     rel->r_offset)))
		return FALSE;
	      break;
	    }
	}
    }

  if (ret
      && emit_these_relocs
      && !info->emitrelocations)
    {
      Elf_Internal_Rela *wrel;
      Elf_Internal_Shdr *rel_hdr;

      wrel = rel = relocs;
      relend = relocs + input_section->reloc_count;
      for (; rel < relend; rel++)
	{
	  int r_type;

	  r_type = ELF32_R_TYPE (rel->r_info);
	  if (r_type == R_SPU_PPU32 || r_type == R_SPU_PPU64)
	    *wrel++ = *rel;
	}
      input_section->reloc_count = wrel - relocs;
      /* Backflips for _bfd_elf_link_output_relocs.  */
      rel_hdr = _bfd_elf_single_rel_hdr (input_section);
      rel_hdr->sh_size = input_section->reloc_count * rel_hdr->sh_entsize;
      ret = 2;
    }

  return ret;
}

static bfd_boolean
spu_elf_finish_dynamic_sections (bfd *output_bfd ATTRIBUTE_UNUSED,
				 struct bfd_link_info *info ATTRIBUTE_UNUSED)
{
  return TRUE;
}

/* Adjust _SPUEAR_ syms to point at their overlay stubs.  */

static int
spu_elf_output_symbol_hook (struct bfd_link_info *info,
			    const char *sym_name ATTRIBUTE_UNUSED,
			    Elf_Internal_Sym *sym,
			    asection *sym_sec ATTRIBUTE_UNUSED,
			    struct elf_link_hash_entry *h)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);

  if (!info->relocatable
      && htab->stub_sec != NULL
      && h != NULL
      && (h->root.type == bfd_link_hash_defined
	  || h->root.type == bfd_link_hash_defweak)
      && h->def_regular
      && strncmp (h->root.root.string, "_SPUEAR_", 8) == 0)
    {
      struct got_entry *g;

      for (g = h->got.glist; g != NULL; g = g->next)
	if (htab->params->ovly_flavour == ovly_soft_icache
	    ? g->br_addr == g->stub_addr
	    : g->addend == 0 && g->ovl == 0)
	  {
	    sym->st_shndx = (_bfd_elf_section_from_bfd_section
			     (htab->stub_sec[0]->output_section->owner,
			      htab->stub_sec[0]->output_section));
	    sym->st_value = g->stub_addr;
	    break;
	  }
    }

  return 1;
}

static int spu_plugin = 0;

void
spu_elf_plugin (int val)
{
  spu_plugin = val;
}

/* Set ELF header e_type for plugins.  */

static void
spu_elf_post_process_headers (bfd *abfd,
			      struct bfd_link_info *info ATTRIBUTE_UNUSED)
{
  if (spu_plugin)
    {
      Elf_Internal_Ehdr *i_ehdrp = elf_elfheader (abfd);

      i_ehdrp->e_type = ET_DYN;
    }
}

/* We may add an extra PT_LOAD segment for .toe.  We also need extra
   segments for overlays.  */

static int
spu_elf_additional_program_headers (bfd *abfd, struct bfd_link_info *info)
{
  int extra = 0;
  asection *sec;

  if (info != NULL)
    {
      struct spu_link_hash_table *htab = spu_hash_table (info);
      extra = htab->num_overlays;
    }

  if (extra)
    ++extra;

  sec = bfd_get_section_by_name (abfd, ".toe");
  if (sec != NULL && (sec->flags & SEC_LOAD) != 0)
    ++extra;

  return extra;
}

/* Remove .toe section from other PT_LOAD segments and put it in
   a segment of its own.  Put overlays in separate segments too.  */

static bfd_boolean
spu_elf_modify_segment_map (bfd *abfd, struct bfd_link_info *info)
{
  asection *toe, *s;
  struct elf_segment_map *m, *m_overlay;
  struct elf_segment_map **p, **p_overlay;
  unsigned int i;

  if (info == NULL)
    return TRUE;

  toe = bfd_get_section_by_name (abfd, ".toe");
  for (m = elf_seg_map (abfd); m != NULL; m = m->next)
    if (m->p_type == PT_LOAD && m->count > 1)
      for (i = 0; i < m->count; i++)
	if ((s = m->sections[i]) == toe
	    || spu_elf_section_data (s)->u.o.ovl_index != 0)
	  {
	    struct elf_segment_map *m2;
	    bfd_vma amt;

	    if (i + 1 < m->count)
	      {
		amt = sizeof (struct elf_segment_map);
		amt += (m->count - (i + 2)) * sizeof (m->sections[0]);
		m2 = bfd_zalloc (abfd, amt);
		if (m2 == NULL)
		  return FALSE;
		m2->count = m->count - (i + 1);
		memcpy (m2->sections, m->sections + i + 1,
			m2->count * sizeof (m->sections[0]));
		m2->p_type = PT_LOAD;
		m2->next = m->next;
		m->next = m2;
	      }
	    m->count = 1;
	    if (i != 0)
	      {
		m->count = i;
		amt = sizeof (struct elf_segment_map);
		m2 = bfd_zalloc (abfd, amt);
		if (m2 == NULL)
		  return FALSE;
		m2->p_type = PT_LOAD;
		m2->count = 1;
		m2->sections[0] = s;
		m2->next = m->next;
		m->next = m2;
	      }
	    break;
	  }


  /* Some SPU ELF loaders ignore the PF_OVERLAY flag and just load all
     PT_LOAD segments.  This can cause the .ovl.init section to be
     overwritten with the contents of some overlay segment.  To work
     around this issue, we ensure that all PF_OVERLAY segments are
     sorted first amongst the program headers; this ensures that even
     with a broken loader, the .ovl.init section (which is not marked
     as PF_OVERLAY) will be placed into SPU local store on startup.  */

  /* Move all overlay segments onto a separate list.  */
  p = &elf_seg_map (abfd);
  p_overlay = &m_overlay;
  while (*p != NULL)
    {
      if ((*p)->p_type == PT_LOAD && (*p)->count == 1
	  && spu_elf_section_data ((*p)->sections[0])->u.o.ovl_index != 0)
	{
	  m = *p;
	  *p = m->next;
	  *p_overlay = m;
	  p_overlay = &m->next;
	  continue;
	}

      p = &((*p)->next);
    }

  /* Re-insert overlay segments at the head of the segment map.  */
  *p_overlay = elf_seg_map (abfd);
  elf_seg_map (abfd) = m_overlay;

  return TRUE;
}

/* Tweak the section type of .note.spu_name.  */

static bfd_boolean
spu_elf_fake_sections (bfd *obfd ATTRIBUTE_UNUSED,
		       Elf_Internal_Shdr *hdr,
		       asection *sec)
{
  if (strcmp (sec->name, SPU_PTNOTE_SPUNAME) == 0)
    hdr->sh_type = SHT_NOTE;
  return TRUE;
}

/* Tweak phdrs before writing them out.  */

static int
spu_elf_modify_program_headers (bfd *abfd, struct bfd_link_info *info)
{
  const struct elf_backend_data *bed;
  struct elf_obj_tdata *tdata;
  Elf_Internal_Phdr *phdr, *last;
  struct spu_link_hash_table *htab;
  unsigned int count;
  unsigned int i;

  if (info == NULL)
    return TRUE;

  bed = get_elf_backend_data (abfd);
  tdata = elf_tdata (abfd);
  phdr = tdata->phdr;
  count = elf_program_header_size (abfd) / bed->s->sizeof_phdr;
  htab = spu_hash_table (info);
  if (htab->num_overlays != 0)
    {
      struct elf_segment_map *m;
      unsigned int o;

      for (i = 0, m = elf_seg_map (abfd); m; ++i, m = m->next)
	if (m->count != 0
	    && (o = spu_elf_section_data (m->sections[0])->u.o.ovl_index) != 0)
	  {
	    /* Mark this as an overlay header.  */
	    phdr[i].p_flags |= PF_OVERLAY;

	    if (htab->ovtab != NULL && htab->ovtab->size != 0
		&& htab->params->ovly_flavour != ovly_soft_icache)
	      {
		bfd_byte *p = htab->ovtab->contents;
		unsigned int off = o * 16 + 8;

		/* Write file_off into _ovly_table.  */
		bfd_put_32 (htab->ovtab->owner, phdr[i].p_offset, p + off);
	      }
	  }
      /* Soft-icache has its file offset put in .ovl.init.  */
      if (htab->init != NULL && htab->init->size != 0)
	{
	  bfd_vma val = elf_section_data (htab->ovl_sec[0])->this_hdr.sh_offset;

	  bfd_put_32 (htab->init->owner, val, htab->init->contents + 4);
	}
    }

  /* Round up p_filesz and p_memsz of PT_LOAD segments to multiples
     of 16.  This should always be possible when using the standard
     linker scripts, but don't create overlapping segments if
     someone is playing games with linker scripts.  */
  last = NULL;
  for (i = count; i-- != 0; )
    if (phdr[i].p_type == PT_LOAD)
      {
	unsigned adjust;

	adjust = -phdr[i].p_filesz & 15;
	if (adjust != 0
	    && last != NULL
	    && phdr[i].p_offset + phdr[i].p_filesz > last->p_offset - adjust)
	  break;

	adjust = -phdr[i].p_memsz & 15;
	if (adjust != 0
	    && last != NULL
	    && phdr[i].p_filesz != 0
	    && phdr[i].p_vaddr + phdr[i].p_memsz > last->p_vaddr - adjust
	    && phdr[i].p_vaddr + phdr[i].p_memsz <= last->p_vaddr)
	  break;

	if (phdr[i].p_filesz != 0)
	  last = &phdr[i];
      }

  if (i == (unsigned int) -1)
    for (i = count; i-- != 0; )
      if (phdr[i].p_type == PT_LOAD)
	{
	unsigned adjust;

	adjust = -phdr[i].p_filesz & 15;
	phdr[i].p_filesz += adjust;

	adjust = -phdr[i].p_memsz & 15;
	phdr[i].p_memsz += adjust;
      }

  return TRUE;
}

bfd_boolean
spu_elf_size_sections (bfd * output_bfd, struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  if (htab->params->emit_fixups)
    {
      asection *sfixup = htab->sfixup;
      int fixup_count = 0;
      bfd *ibfd;
      size_t size;

      for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
	{
	  asection *isec;

	  if (bfd_get_flavour (ibfd) != bfd_target_elf_flavour)
	    continue;

	  /* Walk over each section attached to the input bfd.  */
	  for (isec = ibfd->sections; isec != NULL; isec = isec->next)
	    {
	      Elf_Internal_Rela *internal_relocs, *irelaend, *irela;
	      bfd_vma base_end;

	      /* If there aren't any relocs, then there's nothing more
	         to do.  */
	      if ((isec->flags & SEC_ALLOC) == 0
		  || (isec->flags & SEC_RELOC) == 0
		  || isec->reloc_count == 0)
		continue;

	      /* Get the relocs.  */
	      internal_relocs =
		_bfd_elf_link_read_relocs (ibfd, isec, NULL, NULL,
					   info->keep_memory);
	      if (internal_relocs == NULL)
		return FALSE;

	      /* 1 quadword can contain up to 4 R_SPU_ADDR32
	         relocations.  They are stored in a single word by
	         saving the upper 28 bits of the address and setting the
	         lower 4 bits to a bit mask of the words that have the
	         relocation.  BASE_END keeps track of the next quadword. */
	      irela = internal_relocs;
	      irelaend = irela + isec->reloc_count;
	      base_end = 0;
	      for (; irela < irelaend; irela++)
		if (ELF32_R_TYPE (irela->r_info) == R_SPU_ADDR32
		    && irela->r_offset >= base_end)
		  {
		    base_end = (irela->r_offset & ~(bfd_vma) 15) + 16;
		    fixup_count++;
		  }
	    }
	}

      /* We always have a NULL fixup as a sentinel */
      size = (fixup_count + 1) * FIXUP_RECORD_SIZE;
      if (!bfd_set_section_size (output_bfd, sfixup, size))
	return FALSE;
      sfixup->contents = (bfd_byte *) bfd_zalloc (info->input_bfds, size);
      if (sfixup->contents == NULL)
	return FALSE;
    }
  return TRUE;
}

#define TARGET_BIG_SYM		bfd_elf32_spu_vec
#define TARGET_BIG_NAME		"elf32-spu"
#define ELF_ARCH		bfd_arch_spu
#define ELF_TARGET_ID		SPU_ELF_DATA
#define ELF_MACHINE_CODE	EM_SPU
/* This matches the alignment need for DMA.  */
#define ELF_MAXPAGESIZE		0x80
#define elf_backend_rela_normal         1
#define elf_backend_can_gc_sections	1

#define bfd_elf32_bfd_reloc_type_lookup		spu_elf_reloc_type_lookup
#define bfd_elf32_bfd_reloc_name_lookup		spu_elf_reloc_name_lookup
#define elf_info_to_howto			spu_elf_info_to_howto
#define elf_backend_count_relocs		spu_elf_count_relocs
#define elf_backend_relocate_section		spu_elf_relocate_section
#define elf_backend_finish_dynamic_sections	spu_elf_finish_dynamic_sections
#define elf_backend_symbol_processing		spu_elf_backend_symbol_processing
#define elf_backend_link_output_symbol_hook	spu_elf_output_symbol_hook
#define elf_backend_object_p			spu_elf_object_p
#define bfd_elf32_new_section_hook		spu_elf_new_section_hook
#define bfd_elf32_bfd_link_hash_table_create	spu_elf_link_hash_table_create

#define elf_backend_additional_program_headers	spu_elf_additional_program_headers
#define elf_backend_modify_segment_map		spu_elf_modify_segment_map
#define elf_backend_modify_program_headers	spu_elf_modify_program_headers
#define elf_backend_post_process_headers        spu_elf_post_process_headers
#define elf_backend_fake_sections		spu_elf_fake_sections
#define elf_backend_special_sections		spu_elf_special_sections
#define bfd_elf32_bfd_final_link		spu_elf_final_link

#include "elf32-target.h"
@


1.108
log
@bfd/
	* elf-bfd.h (struct elf_obj_tdata): Rename segment_map to seg_map.
	Delete num_locals and num_globals.
	(elf_num_locals, elf_num_globals): Don't define.
	(elf_seg_map, elf_next_file_pos, elf_eh_frame_hdr, elf_linker,
	elf_stack_flags, elf_strtab_sec, elf_shstrtab_sec): Define.
	* bfd.c, * elf-eh-frame.c, * elf-nacl.c, * elf-vxworks.c, * elf.c,
	* elf32-arm.c, * elf32-lm32.c, * elf32-ppc.c, * elf32-rx.c,
	* elf32-spu.c, * elf64-hppa.c, * elfcode.h, * elflink.c,
	* elfnn-ia64.c, * elfxx-mips.c: Use newly defined elf_obj_tdata
	accessor macros.
	* elf.c (elf_map_symbols): Add pnum_locals param.  Return
	number of locals syms via new param.
	(swap_out_syms): Adjust to suit elf_map_symbols change.
ld/
	* emultempl/elf-generic.em: Use newly defined elf_obj_tdata
	accessor macros.
@
text
@d3 1
a3 2
   Copyright 2006, 2007, 2008, 2009, 2010, 2011, 2012
   Free Software Foundation, Inc.
d1145 1
a1145 1
   intructions, and a faster stub of four instructions.
@


1.107
log
@	* coff-arm.c (coff_arm_link_hash_table_create): Use bfd_zmalloc.
	* coff-h8300.c (h8300_coff_link_hash_table_create): Likewise.
	* m68klinux.c (linux_link_hash_table_create): Likewise.
	* sparclinux.c (linux_link_hash_table_create): Likewise.
	* sunos.c (sunos_link_hash_table_create): Likewise.
	* xcofflink.c (_bfd_xcoff_bfd_link_hash_table_create): Likewise.
	* elf-m10300.c (elf32_mn10300_link_hash_table_create): Likewise.
	* elf32-arm.c (elf32_arm_link_hash_table_create): Likewise.
	* elf32-avr.c (elf32_avr_link_hash_table_create): Likewise.
	* elf32-cr16.c (elf32_cr16_link_hash_table_create): Likewise.
	* elf32-cris.c (elf_cris_link_hash_table_create): Likewise.
	* elf32-hppa.c (elf32_hppa_link_hash_table_create): Likewise.
	* elf32-i386.c (elf_i386_link_hash_table_create): Likewise.
	* elf32-lm32.c (lm32_elf_link_hash_table_create): Likewise.
	* elf32-m32r.c (m32r_elf_link_hash_table_create): Likewise.
	* elf32-m68hc1x.c (m68hc11_elf_hash_table_create): Likewise.
	* elf32-m68k.c (elf_m68k_link_hash_table_create): Likewise.
	* elf32-metag.c (elf_metag_link_hash_table_create): Likewise.
	* elf32-nios2.c (nios2_elf32_link_hash_table_create): Likewise.
	* elf32-s390.c (elf_s390_link_hash_table_create): Likewise.
	* elf32-score.c (elf32_score_link_hash_table_create): Likewise.
	* elf32-spu.c (spu_elf_link_hash_table_create): Likewise.
	* elf32-tic6x.c (elf32_tic6x_link_hash_table_create): Likewise.
	* elf32-vax.c (elf_vax_link_hash_table_create): Likewise.
	* elf32-xgate.c (xgate_elf_bfd_link_hash_table_create): Likewise.
	* elf32-xtensa.c (elf_xtensa_link_hash_table_create): Likewise.
	* elf64-aarch64.c (elf64_aarch64_link_hash_table_create): Likewise.
	* elf64-s390.c (elf_s390_link_hash_table_create): Likewise.
	* elf64-sh64.c (sh64_elf64_link_hash_table_create): Likewise.
	* elf64-x86-64.c (elf_x86_64_link_hash_table_create): Likewise.
	* elfxx-mips.c (_bfd_mips_elf_link_hash_table_create): Likewise.
	* elflink.c (_bfd_elf_link_hash_table_create): Likewise.
	(_bfd_elf_link_hash_table_init): Assume zero fill table on entry.
@
text
@d2155 1
a2155 1
  for (m = elf_tdata (abfd)->segment_map; m != NULL; m = m->next)
d4178 1
a4178 1
  for (m = elf_tdata (info->output_bfd)->segment_map; m != NULL; m = m->next)
d5201 1
a5201 1
  for (m = elf_tdata (abfd)->segment_map; m != NULL; m = m->next)
d5251 1
a5251 1
  p = &elf_tdata (abfd)->segment_map;
d5269 2
a5270 2
  *p_overlay = elf_tdata (abfd)->segment_map;
  elf_tdata (abfd)->segment_map = m_overlay;
d5305 1
a5305 1
  count = tdata->program_header_size / bed->s->sizeof_phdr;
d5312 1
a5312 1
      for (i = 0, m = elf_tdata (abfd)->segment_map; m; ++i, m = m->next)
@


1.106
log
@Remove trailing white spaces in bfd

	* aout0.c: Remove trailing white spaces.
	* archive.c: Likewise.
	* archures.c: Likewise.
	* bfd-in.h: Likewise.
	* bfd-in2.h: Likewise.
	* coff-alpha.c: Likewise.
	* coff-i860.c: Likewise.
	* coff-mips.c: Likewise.
	* coff-ppc.c: Likewise.
	* coff-tic80.c: Likewise.
	* coff-x86_64.c: Likewise.
	* coff-z80.c: Likewise.
	* coffcode.h: Likewise.
	* coffgen.c: Likewise.
	* cofflink.c: Likewise.
	* compress.c: Likewise.
	* corefile.c: Likewise.
	* cpu-arm.c: Likewise.
	* cpu-avr.c: Likewise.
	* cpu-bfin.c: Likewise.
	* cpu-cr16.c: Likewise.
	* cpu-cr16c.c: Likewise.
	* cpu-crx.c: Likewise.
	* cpu-h8300.c: Likewise.
	* cpu-i386.c: Likewise.
	* cpu-lm32.c: Likewise.
	* cpu-m68k.c: Likewise.
	* cpu-moxie.c: Likewise.
	* cpu-msp430.c: Likewise.
	* cpu-sh.c: Likewise.
	* cpu-xc16x.c: Likewise.
	* dwarf2.c: Likewise.
	* ecofflink.c: Likewise.
	* ecoffswap.h: Likewise.
	* elf-ifunc.c: Likewise.
	* elf-m10300.c: Likewise.
	* elf-vxworks.c: Likewise.
	* elf32-avr.c: Likewise.
	* elf32-avr.h: Likewise.
	* elf32-cr16.c: Likewise.
	* elf32-cr16c.c: Likewise.
	* elf32-cris.c: Likewise.
	* elf32-crx.c: Likewise.
	* elf32-frv.c: Likewise.
	* elf32-hppa.c: Likewise.
	* elf32-i860.c: Likewise.
	* elf32-ip2k.c: Likewise.
	* elf32-iq2000.c: Likewise.
	* elf32-m32c.c: Likewise.
	* elf32-m68hc1x.c: Likewise.
	* elf32-msp430.c: Likewise.
	* elf32-mt.c: Likewise.
	* elf32-ppc.c: Likewise.
	* elf32-rl78.c: Likewise.
	* elf32-s390.c: Likewise.
	* elf32-score.h: Likewise.
	* elf32-sh-symbian.c: Likewise.
	* elf32-sh.c: Likewise.
	* elf32-spu.c: Likewise.
	* elf32-tic6x.c: Likewise.
	* elf32-v850.c: Likewise.
	* elf32-xc16x.c: Likewise.
	* elf32-xtensa.c: Likewise.
	* elf64-alpha.c: Likewise.
	* elf64-hppa.c: Likewise.
	* elf64-ppc.c: Likewise.
	* elf64-s390.c: Likewise.
	* elfcore.h: Likewise.
	* elflink.c: Likewise.
	* elfxx-mips.c: Likewise.
	* elfxx-sparc.c: Likewise.
	* elfxx-tilegx.c: Likewise.
	* ieee.c: Likewise.
	* libcoff.h: Likewise.
	* libpei.h: Likewise.
	* libxcoff.h: Likewise.
	* linker.c: Likewise.
	* mach-o-i386.c: Likewise.
	* mach-o-target.c: Likewise.
	* mach-o.c: Likewise.
	* mach-o.h: Likewise.
	* mmo.c: Likewise.
	* opncls.c: Likewise.
	* pdp11.c: Likewise.
	* pe-x86_64.c: Likewise.
	* peXXigen.c: Likewise.
	* pef-traceback.h: Likewise.
	* pei-x86_64.c: Likewise.
	* peicode.h: Likewise.
	* plugin.c: Likewise.
	* reloc.c: Likewise.
	* riscix.c: Likewise.
	* section.c: Likewise.
	* som.c: Likewise.
	* syms.c: Likewise.
	* tekhex.c: Likewise.
	* ticoff.h: Likewise.
	* vaxbsd.c: Likewise.
	* xcofflink.c: Likewise.
	* xtensa-isa.c: Likewise.
@
text
@d443 1
a443 1
  htab = bfd_malloc (sizeof (*htab));
a455 3
  memset (&htab->ovtab, 0,
	  sizeof (*htab) - offsetof (struct spu_link_hash_table, ovtab));

@


1.105
log
@	* elf-bfd.h (RELOC_AGAINST_DISCARDED_SECTION): Handle compound
	relocations.
	* elfxx-mips.c (mips_reloc_against_discarded_section): New
	function.
	(_bfd_mips_elf_relocate_section): Call it, in place of
	RELOC_AGAINST_DISCARDED_SECTION.
	* elf-m10200.c (mn10200_elf_relocate_section): Update arguments
	to RELOC_AGAINST_DISCARDED_SECTION.
	* elf-m10300.c (mn10300_elf_relocate_section): Likewise.
	* elf32-arm.c (elf32_arm_relocate_section): Likewise.
	* elf32-avr.c (elf32_avr_relocate_section): Likewise.
	* elf32-bfin.c (bfin_relocate_section): Likewise.
	(bfinfdpic_relocate_section): Likewise.
	* elf32-cr16.c (elf32_cr16_relocate_section): Likewise.
	* elf32-cr16c.c (elf32_cr16c_relocate_section): Likewise.
	* elf32-cris.c (cris_elf_relocate_section): Likewise.
	* elf32-crx.c (elf32_crx_relocate_section): Likewise.
	* elf32-d10v.c (elf32_d10v_relocate_section): Likewise.
	* elf32-epiphany.c (epiphany_elf_relocate_section): Likewise.
	* elf32-fr30.c (fr30_elf_relocate_section): Likewise.
	* elf32-frv.c (elf32_frv_relocate_section): Likewise.
	* elf32-h8300.c (elf32_h8_relocate_section): Likewise.
	* elf32-hppa.c (elf32_hppa_relocate_section): Likewise.
	* elf32-i370.c (i370_elf_relocate_section): Likewise.
	* elf32-i386.c (elf_i386_relocate_section): Likewise.
	* elf32-i860.c (elf32_i860_relocate_section): Likewise.
	* elf32-ip2k.c (ip2k_elf_relocate_section): Likewise.
	* elf32-iq2000.c (iq2000_elf_relocate_section): Likewise.
	* elf32-lm32.c (lm32_elf_relocate_section): Likewise.
	* elf32-m32c.c (m32c_elf_relocate_section): Likewise.
	* elf32-m32r.c (m32r_elf_relocate_section): Likewise.
	* elf32-m68hc1x.c (elf32_m68hc11_relocate_section): Likewise.
	* elf32-m68k.c (elf_m68k_relocate_section): Likewise.
	* elf32-mcore.c (mcore_elf_relocate_section): Likewise.
	* elf32-mep.c (mep_elf_relocate_section): Likewise.
	* elf32-moxie.c (moxie_elf_relocate_section): Likewise.
	* elf32-msp430.c (elf32_msp430_relocate_section): Likewise.
	* elf32-mt.c (mt_elf_relocate_section): Likewise.
	* elf32-openrisc.c (openrisc_elf_relocate_section): Likewise.
	* elf32-ppc.c (ppc_elf_relocate_section): Likewise.
	* elf32-rl78.c (rl78_elf_relocate_section): Likewise.
	* elf32-rx.c (rx_elf_relocate_section): Likewise.
	* elf32-s390.c (elf_s390_relocate_section): Likewise.
	* elf32-score.c (s3_bfd_score_elf_relocate_section): Likewise.
	* elf32-score7.c (s7_bfd_score_elf_relocate_section): Likewise.
	* elf32-sh.c (sh_elf_relocate_section): Likewise.
	* elf32-spu.c (spu_elf_relocate_section): Likewise.
	* elf32-tic6x.c (elf32_tic6x_relocate_section): Likewise.
	* elf32-tilepro.c (tilepro_elf_relocate_section): Likewise.
	* elf32-v850.c (v850_elf_relocate_section): Likewise.
	* elf32-vax.c (elf_vax_relocate_section): Likewise.
	* elf32-xc16x.c (elf32_xc16x_relocate_section): Likewise.
	* elf32-xstormy16.c (xstormy16_elf_relocate_section): Likewise.
	* elf32-xtensa.c (elf_xtensa_relocate_section): Likewise.
	* elf64-alpha.c (elf64_alpha_relocate_section_r): Likewise.
	(elf64_alpha_relocate_section): Likewise.
	* elf64-hppa.c (elf64_hppa_relocate_section): Likewise.
	* elf64-mmix.c (mmix_elf_relocate_section): Likewise.
	* elf64-ppc.c (ppc64_elf_relocate_section): Likewise.
	* elf64-s390.c (elf_s390_relocate_section): Likewise.
	* elf64-sh64.c (sh_elf64_relocate_section): Likewise.
	* elf64-x86-64.c (elf_x86_64_relocate_section): Likewise.
	* elfnn-ia64.c (elfNN_ia64_relocate_section): Likewise.
	* elfxx-sparc.c (_bfd_sparc_elf_relocate_section): Likewise.
	* elfxx-tilegx.c (tilegx_elf_relocate_section): Likewise.
@
text
@d1489 1
a1489 1
  
d1515 1
a1515 1
  
d2952 1
a2952 1
  
d2985 1
a2985 1
	     code only reads local symbols, and we need globals too.  */ 
d4084 1
a4084 1
	  
d4912 2
a4913 2
	  loc[0] = 0x1c; 
	  loc[1] = 0x00; 
@


1.104
log
@	PR ld/13991
bfd/
	* bfd/elf-bfd.h (_bfd_elf_link_just_syms): Define as
	_bfd_generic_link_just_syms.
	* bfd/elflink.c (_bfd_elf_link_just_syms): Delete.
	* bfd/linker.c (_bfd_generic_link_just_syms): Set sec_info_type.

	* bfd/bfd-in.h (discarded_section): Renamed from elf_discarded_section.
	* bfd/section.c (SEC_INFO_TYPE_NONE, SEC_INFO_TYPE_STABS,
	SEC_INFO_TYPE_MERGE, SEC_INFO_TYPE_EH_FRAME,
	SEC_INFO_TYPE_JUST_SYMS): Renamed from corresponding ELF_INFO_TYPE.
	* bfd/elf-eh-frame.c, * bfd/elf-m10200.c, * bfd/elf-m10300.c,
	* bfd/elf.c, * bfd/elf32-arm.c, * bfd/elf32-avr.c, * bfd/elf32-bfin.c,
	* bfd/elf32-cr16.c, * bfd/elf32-cr16c.c, * bfd/elf32-cris.c,
	* bfd/elf32-crx.c, * bfd/elf32-d10v.c, * bfd/elf32-epiphany.c,
	* bfd/elf32-fr30.c, * bfd/elf32-frv.c, * bfd/elf32-h8300.c,
	* bfd/elf32-hppa.c, * bfd/elf32-i370.c, * bfd/elf32-i386.c,
	* bfd/elf32-i860.c, * bfd/elf32-ip2k.c, * bfd/elf32-iq2000.c,
	* bfd/elf32-lm32.c, * bfd/elf32-m32c.c, * bfd/elf32-m32r.c,
	* bfd/elf32-m68hc1x.c, * bfd/elf32-m68k.c, * bfd/elf32-mcore.c,
	* bfd/elf32-mep.c, * bfd/elf32-moxie.c, * bfd/elf32-msp430.c,
	* bfd/elf32-mt.c, * bfd/elf32-openrisc.c, * bfd/elf32-ppc.c,
	* bfd/elf32-rl78.c, * bfd/elf32-rx.c, * bfd/elf32-s390.c,
	* bfd/elf32-score.c, * bfd/elf32-score7.c, * bfd/elf32-sh.c,
	* bfd/elf32-spu.c, * bfd/elf32-tic6x.c, * bfd/elf32-tilepro.c,
	* bfd/elf32-v850.c, * bfd/elf32-vax.c, * bfd/elf32-xc16x.c,
	* bfd/elf32-xstormy16.c, * bfd/elf32-xtensa.c, * bfd/elf64-alpha.c,
	* bfd/elf64-hppa.c, * bfd/elf64-ia64-vms.c, * bfd/elf64-mmix.c,
	* bfd/elf64-ppc.c, * bfd/elf64-s390.c, * bfd/elf64-sh64.c,
	* bfd/elf64-x86-64.c, * bfd/elflink.c, * bfd/elfnn-ia64.c,
	* bfd/elfxx-mips.c, * bfd/elfxx-sparc.c, * bfd/elfxx-tilegx.c,
	* bfd/reloc.c: Update all references.
	* bfd/bfd-in2.h: Regenerate.
ld/
	* ld/ldlang.c (size_input_section): Use sec_info_type rather than
	usrdata->flags.just_syms.
	* ld/ldwrite.c (build_link_order): Likewise.
	* ld/emultempl/hppaelf.em (build_section_lists): Likewise.
	* ld/emultempl/ppc64elf.em (build_toc_list): Likewise.
	* ld/emultempl/armelf.em (build_section_lists): Likewise.
	(after_allocation): Update for renamed sec_info_type value.
	* ld/emultempl/tic6xdsbt.em: Likewise.
@
text
@d4901 1
a4901 1
					 rel, relend, howto, contents);
@


1.103
log
@	* elf32-spu.c (build_stub): Fix malloc under-allocation.
@
text
@d4899 1
a4899 1
      if (sec != NULL && elf_discarded_section (sec))
@


1.102
log
@	PR ld/13177
bfd/
	* elflink.c (_bfd_elf_gc_mark_rsec): Set symbol "mark".
	(elf_gc_sweep_symbol): Don't test plt/got refcounts, instead test
	"mark".  Hide undefweak too.  Clear def_regular and ref_regular.
	* elf-m10300.c (mn10300_elf_relocate_section): Ignore unresolved
	reloc errors from garbage-collected code.
	* elf32-arm.c (elf32_arm_relocate_section): Likewise.
	* elf32-bfin.c (bfin_relocate_section): Likewise.
	(bfinfdpic_relocate_section): Likewise.
	* elf32-cris.c (cris_elf_relocate_section): Likewise.
	* elf32-frv.c (elf32_frv_relocate_section): Likewise.
	* elf32-i386.c (elf_i386_relocate_section): Likewise.
	* elf32-m32r.c (m32r_elf_relocate_section): Likewise.
	* elf32-m68k.c (elf_m68k_relocate_section): Likewise.
	* elf32-ppc.c (ppc_elf_relocate_section): Likewise.
	* elf32-s390.c (elf_s390_relocate_section): Likewise.
	* elf32-sh.c (sh_elf_relocate_section): Likewise.
	* elf32-spu.c (spu_elf_relocate_section): Likewise.
	* elf32-tilepro.c (tilepro_elf_relocate_section): Likewise.
	* elf32-xtensa.c (elf_xtensa_relocate_section): Likewise.
	* elf64-alpha.c (elf64_alpha_relocate_section): Likewise.
	* elf64-ppc.c (ppc64_elf_relocate_section): Likewise.
	* elf64-s390.c (elf_s390_relocate_section): Likewise.
	* elf64-sh64.c (sh_elf64_relocate_section): Likewise.
	* elf64-x86-64.c (elf_x86_64_relocate_section): Likewise.
	* elfxx-sparc.c (_bfd_sparc_elf_relocate_section): Likewise.
	* elfxx-tilegx.c (tilegx_elf_relocate_section): Likewise.
ld/testsuite/
	* ld-elf/elf.exp: Move test for shared lib support..
	* lib/ld-lib.exp (check_shared_lib_support): ..to here. Add m68hc1*,
	and s/ms1/mt/.
	(check_gc_sections_available): Match hppa*64 not hppa64.  Comment.
	* ld-gc/libpersonality.s: New.
	* ld-gc/personality.s, * ld-gc/personality.d: New.
	* ld-gc/gc.exp: Run personality test.
@
text
@d3 2
a4 1
   Copyright 2006, 2007, 2008, 2009, 2010 Free Software Foundation, Inc.
d1429 1
a1429 1
      name = bfd_malloc (len);
@


1.101
log
@ChangeLog libiberty/
2011-02-28  Kai Tietz  <kai.tietz@@onevision.com>

	* filename_cmp.c (filename_ncmp): New function.
	* functions.texi: Regenerated.

ChangeLog include/
2011-02-28  Kai Tietz  <kai.tietz@@onevision.com>

	* filenames.h (filename_ncmp): New prototype.

ChangeLog bfd/
2011-02-28  Kai Tietz  <kai.tietz@@onevision.com>

	* archive.c (_bfd_find_nested_archive): Use filename_(n)cmp.
	(adjust_relative_path): Likewise.
	(_bfd_construct_extended_name_table): Likewise.
	* corefile.c (generic_core_file_matches_executable_p): Likewise.
	* elf32-bfin.c (bfinfdpic_relocate_section): Likewise.
	* elf32-frv.c (elf32_frv_relocate_section): Likewise.
	* elf32-spu.c (sort_bfds): Likewise.
	(spu_elf_auto_overlay): Likewise.
	* syms.c (_bfd_stab_section_find_nearest_line): Likewise.
	* xcofflink.c (xcoff_set_import_path): Likewise.
	* xtensa-isa.c (xtensa_regfile_lookup): Likewise.
	(xtensa_regfile_lookup_shortname): Likewise.
@
text
@d5003 3
a5005 1
      if (unresolved_reloc)
@


1.101.4.1
log
@    PR ld/13991
    bfd/
    * bfd/elf-bfd.h (_bfd_elf_link_just_syms): Define as
    _bfd_generic_link_just_syms.
    * bfd/elflink.c (_bfd_elf_link_just_syms): Delete.
    * bfd/linker.c (_bfd_generic_link_just_syms): Set sec_info_type.

    * bfd/bfd-in.h (discarded_section): Renamed from elf_discarded_section.
    * bfd/section.c (SEC_INFO_TYPE_NONE, SEC_INFO_TYPE_STABS,
    SEC_INFO_TYPE_MERGE, SEC_INFO_TYPE_EH_FRAME,
    SEC_INFO_TYPE_JUST_SYMS): Renamed from corresponding ELF_INFO_TYPE.
    * bfd/elf-eh-frame.c, * bfd/elf-m10200.c, * bfd/elf-m10300.c,
    * bfd/elf.c, * bfd/elf32-arm.c, * bfd/elf32-avr.c, * bfd/elf32-bfin.c,
    * bfd/elf32-cr16.c, * bfd/elf32-cr16c.c, * bfd/elf32-cris.c,
    * bfd/elf32-crx.c, * bfd/elf32-d10v.c, * bfd/elf32-epiphany.c,
    * bfd/elf32-fr30.c, * bfd/elf32-frv.c, * bfd/elf32-h8300.c,
    * bfd/elf32-hppa.c, * bfd/elf32-i370.c, * bfd/elf32-i386.c,
    * bfd/elf32-i860.c, * bfd/elf32-ip2k.c, * bfd/elf32-iq2000.c,
    * bfd/elf32-lm32.c, * bfd/elf32-m32c.c, * bfd/elf32-m32r.c,
    * bfd/elf32-m68hc1x.c, * bfd/elf32-m68k.c, * bfd/elf32-mcore.c,
    * bfd/elf32-mep.c, * bfd/elf32-moxie.c, * bfd/elf32-msp430.c,
    * bfd/elf32-mt.c, * bfd/elf32-openrisc.c, * bfd/elf32-ppc.c,
    * bfd/elf32-rl78.c, * bfd/elf32-rx.c, * bfd/elf32-s390.c,
    * bfd/elf32-score.c, * bfd/elf32-score7.c, * bfd/elf32-sh.c,
    * bfd/elf32-spu.c, * bfd/elf32-tic6x.c, * bfd/elf32-tilepro.c,
    * bfd/elf32-v850.c, * bfd/elf32-vax.c, * bfd/elf32-xc16x.c,
    * bfd/elf32-xstormy16.c, * bfd/elf32-xtensa.c, * bfd/elf64-alpha.c,
    * bfd/elf64-hppa.c, * bfd/elf64-ia64-vms.c, * bfd/elf64-mmix.c,
    * bfd/elf64-ppc.c, * bfd/elf64-s390.c, * bfd/elf64-sh64.c,
    * bfd/elf64-x86-64.c, * bfd/elflink.c, * bfd/elfnn-ia64.c,
    * bfd/elfxx-mips.c, * bfd/elfxx-sparc.c, * bfd/elfxx-tilegx.c,
    * bfd/reloc.c: Update all references.
    * bfd/bfd-in2.h: Regenerate.
    ld/
    * ld/ldlang.c (size_input_section): Use sec_info_type rather than
    usrdata->flags.just_syms.
    * ld/ldwrite.c (build_link_order): Likewise.
    * ld/emultempl/hppaelf.em (build_section_lists): Likewise.
    * ld/emultempl/ppc64elf.em (build_toc_list): Likewise.
    * ld/emultempl/armelf.em (build_section_lists): Likewise.
    (after_allocation): Update for renamed sec_info_type value.
    * ld/emultempl/tic6xdsbt.em: Likewise.
@
text
@d4898 1
a4898 1
      if (sec != NULL && discarded_section (sec))
@


1.100
log
@	bfd/
	* elf-bfd.h (RELOC_AGAINST_DISCARDED_SECTION): Always call
	_bfd_clear_contents.  Pass it the input section.
	* libbfd-in.h (_bfd_clear_contents): Add input_section argument.
	* libbfd.h: Regenerate.
	* reloc.c (_bfd_clear_contents): Take input_section argument.
	Use non-zero for .debug_ranges.
	(bfd_generic_get_relocated_section_conten): Update _bfd_clear_contents
	call.

	* elf32-arm.c (elf32_arm_relocate_section): Use
	RELOC_AGAINST_DISCARDED_SECTION.
	* elf-m10200.c (mn10200_elf_relocate_section): Likewise.
	* elf-m10300.c (mn10300_elf_relocate_section): Likewise.
	* elf32-arm.c (elf32_arm_relocate_section): Likewise.
	* elf32-avr.c (elf32_avr_relocate_section): Likewise.
	* elf32-bfin.c (bfin_relocate_section): Likewise.
	(bfinfdpic_relocate_section): Likewise.
	* elf32-cr16.c (elf32_cr16_relocate_section): Likewise.
	* elf32-cr16c.c (elf32_cr16c_relocate_section): Likewise.
	* elf32-cris.c (cris_elf_relocate_section): Likewise.
	* elf32-crx.c (elf32_crx_relocate_section): Likewise.
	* elf32-d10v.c (elf32_d10v_relocate_section): Likewise.
	* elf32-fr30.c (fr30_elf_relocate_section): Likewise.
	* elf32-frv.c (elf32_frv_relocate_section): Likewise.
	* elf32-h8300.c (elf32_h8_relocate_section): Likewise.
	* elf32-hppa.c (elf32_hppa_relocate_section): Likewise.
	* elf32-i370.c (i370_elf_relocate_section): Likewise.
	* elf32-i860.c (elf32_i860_relocate_section): Likewise.
	* elf32-ip2k.c (ip2k_elf_relocate_section): Likewise.
	* elf32-iq2000.c (iq2000_elf_relocate_section): Likewise.
	* elf32-lm32.c (lm32_elf_relocate_section): Likewise.
	* elf32-m32c.c (m32c_elf_relocate_section): Likewise.
	* elf32-m32r.c (m32r_elf_relocate_section): Likewise.
	* elf32-m68hc1x.c (elf32_m68hc11_relocate_section): Likewise.
	* elf32-m68k.c (elf_m68k_relocate_section): Likewise.
	* elf32-mcore.c (mcore_elf_relocate_section): Likewise.
	* elf32-mep.c (mep_elf_relocate_section): Likewise.
	* elf32-moxie.c (moxie_elf_relocate_section): Likewise.
	* elf32-msp430.c (elf32_msp430_relocate_section): Likewise.
	* elf32-mt.c (mt_elf_relocate_section): Likewise.
	* elf32-openrisc.c (openrisc_elf_relocate_section): Likewise.
	* elf32-ppc.c (ppc_elf_relocate_section): Likewise.
	* elf32-rx.c (rx_elf_relocate_section): Likewise.
	* elf32-s390.c (elf_s390_relocate_section): Likewise.
	* elf32-score.c (s3_bfd_score_elf_relocate_section): Likewise.
	* elf32-score7.c (s7_bfd_score_elf_relocate_section): Likewise.
	* elf32-sh.c (sh_elf_relocate_section): Likewise.
	* elf32-spu.c (spu_elf_relocate_section): Likewise.
	* elf32-tic6x.c (elf32_tic6x_relocate_section): Likewise.
	* elf32-v850.c (v850_elf_relocate_section): Likewise.
	* elf32-vax.c (elf_vax_relocate_section): Likewise.
	* elf32-xc16x.c (elf32_xc16x_relocate_section): Likewise.
	* elf32-xstormy16.c (xstormy16_elf_relocate_section): Likewise.
	* elf32-xtensa.c (elf_xtensa_relocate_section): Likewise.
	* elf64-alpha.c (elf64_alpha_relocate_section_r): Likewise.
	(elf64_alpha_relocate_section): Likewise.
	* elf64-hppa.c (elf64_hppa_relocate_section): Likewise.
	* elf64-mmix.c (mmix_elf_relocate_section): Likewise.
	* elf64-ppc.c (ppc64_elf_relocate_section): Likewise.
	* elf64-s390.c (elf_s390_relocate_section): Likewise.
	* elf64-sh64.c (sh_elf64_relocate_section): Likewise.
	* elfxx-ia64.c (elfNN_ia64_relocate_section): Likewise.
	* elfxx-mips.c (_bfd_mips_elf_relocate_section): Likewise.
	* elfxx-sparc.c (_bfd_sparc_elf_relocate_section): Likewise.

	ld/testsuite/
	* ld-discard/zero-range.d, ld-discard/zero-range.s: New files.
@
text
@d4070 1
a4070 1
  return strcmp ((*abfd1)->filename, (*abfd2)->filename);
d4302 1
a4302 1
	if (strcmp (bfd_arr[i - 1]->filename, bfd_arr[i]->filename) == 0)
@


1.99
log
@bfd/
	* elf-bfd.h (struct bfd_elf_section_reloc_data): New structure.
	(struct bfd_elf_section_data): New members REL and RELA; delete
	members REL_HDR, REL_HDR2, REL_COUNT, REL_COUNT2, REL_IDX,
	REL_IDX2, REL_HASHES.
	(_bfd_elf_init_reloc_shdr): Adjust declaration.
	(_bfd_elf_single_rel_hdr): Declare.
	(RELOC_AGAINST_DISCARDED_SECTION): Use it.
	* elf.c (bfd_section_from_shdr): Adjusted to match changes in
	data structures.
	(_bfd_elf_init_reloc_shdr): New arg RELDATA.  Remove arg REL_HDR.
	All callers changed.  Allocate memory for the Elf_Internal_Shdr
	structure.
	(_bfd_elf_single_rel_hdr): New function.
	(struct fake_section_arg): New structure.
	(elf_fake_section): Expect to see a pointer to it in the third
	argument.  If doing a relocatable link, allocate both REL and RELA
	sections as needed.
	(assign_section_numbers): Adjusted to match changes in
	data structures.
	(_bfd_elf_compute_section_file_positions): Call elf_fake_sections
	with a struct fake_section_args argument.
	* elfcode.h (elf_write_relocs): Adjusted to match changes in
	data structures.
	(elf_slurp_reloc_table): Likewise.
	* elflink.c (_bfd_elf_link_read_relocs): Likewise.
	(_bfd_elf_link_size_reloc_section): Remove arg REL_HDR, replace with
	RELDATA.  Remove argument O.  All callers changed.  Remove code to
	discover the right rel_hdr and count.
	(_bfd_elf_link_output_relocs): Adjusted to match changes in
	data structures.
	(elf_link_adjust_relocs): Remove args REL_HDR, COUNT and REL_HASH;
	replace with RELDATA.  All callers changed.
	(elf_link_input_bfd): Correctly generate rel_hash data when both
	REL and RELA sections are present.
	(elf_reloc_link_order): Adjusted to match changes in
	data structures.
	(bfd_elf_final_link): Simplify code to count relocs.  Free the
	hashes array for both REL and RELA.
	(get_dynamic_reloc_section_name): Use _bfd_elf_single_reloc_hdr
	* elf32-m32r.c (m32r_elf_fake_sections, elf_backend_fake_sections):
	Delete.
	* elf32-tic6x.c (elf32_tic6x_fake_sections, elf_backend_fake_sections):
	Delete.
	(elf32_tic6x_rel_relocation_p): Adjusted to match changes in
	data structures.
 	* elf32-microblaze.c (microblaze_elf_check_relocs): Use
	_bfd_elf_single_rel_hdr.
	* elf32-ppc.c (ppc_elf_relax_section): Likewise.
	* elf32-spu.c (spu_elf_relocate_section): Likewise.
	* elf64-alpha.c (elf64_alpha_relocate_section): Likewise.
	* elf64-hppa.c (get_reloc_section): Likewise.
	* elf64-mips.c (mips_elf64_slurp_reloc_table): Adjusted to match
	changes in data structures.
	(mips_elf64_write_relocs): Use _bfd_elf_single_rel_hdr.
	* elf64-ppc.c (ppc64_elf_edit_opd): Likewise.
	(ppc64_elf_edit_toc): Likewise.
	(get_relocs): Adjusted to match changes in data structures.
	Allocate an Elf_Internal_Shdr structure if necessary.
	(ppc64_elf_finish_dynamic_sections): Use _bfd_elf_single_rel_hdr.
	* elf64-sparc.c (elf64_sparc_slurp_reloc_table): Adjusted to match
	changes in data structures.
	* elfxx-ia64.c (get_reloc_section): Use _bfd_elf_single_rel_hdr.
	* elfxx-mips.c (MIPS_RELOC_RELA_P): Remove macro.
	(mips_elf_rel_relocation_p): Adjusted to match changes in data
	structures.
	(_bfd_mips_elf_relocate_section): Use mips_elf_rel_relocation_p rather
	than MIPS_RELOC_RELOCA_P.
	* elfxx-sparc.c (_bfd_sparc_elf_check_relocs): Use
	_bfd_elf_single_rel_hdr.
	(_bfd_sparc_elf_relocate_section): Likewise.

ld/
	* emultempl/xtensaelf.em (replace_insn_sec_with_prop_sec): Use
	_bfd_elf_single_rel_hdr.
@
text
@d4899 2
a4900 9
	{
	  /* For relocs against symbols from removed linkonce sections,
	     or sections discarded by a linker script, we just want the
	     section contents zeroed.  Avoid any special processing.  */
	  _bfd_clear_contents (howto, input_bfd, contents + rel->r_offset);
	  rel->r_info = 0;
	  rel->r_addend = 0;
	  continue;
	}
@


1.98
log
@	* elf32-spu.c (spu_elf_size_sections): Omit fixups for non-alloc
	sections.
	(spu_elf_create_sections): Mark .fixup with SEC_LINKER_CREATED and
	set dynobj.
	(spu_elf_finish_dynamic_sections): New function.
	(elf_backend_finish_dynamic_sections): Define.
@
text
@d5094 1
a5094 1
      rel_hdr = &elf_section_data (input_section)->rel_hdr;
@


1.97
log
@Add target_id to elf_backend_data.

2010-08-25  H.J. Lu  <hongjiu.lu@@intel.com>

	PR ld/11944
	* elf-bfd.h (elf_backend_data): Add target_id.
	(bfd_elf_make_generic_object): Renamed to ...
	(bfd_elf_make_object): This.

	* elf.c (bfd_elf_make_generic_object): Removed.
	(bfd_elf_make_object): New.
	(bfd_elf_mkcorefile): Really treat it as an object file.

	* elf-m10300.c (ELF_TARGET_ID): New.
	* elf32-arm.c (ELF_TARGET_ID): Likewise.
	* elf32-bfin.c (ELF_TARGET_ID): Likewise.
	* elf32-cris.c (ELF_TARGET_ID): Likewise.
	* elf32-frv.c (ELF_TARGET_ID): Likewise.
	* elf32-i386.c (ELF_TARGET_ID): Likewise.
	* elf32-lm32.c (ELF_TARGET_ID): Likewise.
	* elf32-m32r.c (ELF_TARGET_ID): Likewise.
	* elf32-m68hc11.c (ELF_TARGET_ID): Likewise.
	* elf32-m68hc12.c (ELF_TARGET_ID): Likewise.
	* elf32-m68k.c (ELF_TARGET_ID): Likewise.
	* elf32-microblaze.c (ELF_TARGET_ID): Likewise.
	* elf32-ppc.c (ELF_TARGET_ID): Likewise.
	* elf32-s390.c (ELF_TARGET_ID): Likewise.
	* elf32-sh.c (ELF_TARGET_ID): Likewise.
	* elf32-sparc.c (ELF_TARGET_ID): Likewise.
	* elf32-spu.c (ELF_TARGET_ID): Likewise.
	* elf32-tic6x.c (ELF_TARGET_ID): Likewise.
	* elf32-xtensa.c (ELF_TARGET_ID): Likewise.
	* elf64-alpha.c (ELF_TARGET_ID): Likewise.
	* elf64-hppa.c (ELF_TARGET_ID): Likewise.
	* elf64-ppc.c (ELF_TARGET_ID): Likewise.
	* elf64-s390.c (ELF_TARGET_ID): Likewise.
	* elf64-x86-64.c (ELF_TARGET_ID): Likewise.
	* elfxx-ia64.c (ELF_TARGET_ID): Likewise.

	* elf32-hppa.c (elf32_hppa_mkobject): Removed.
	(bfd_elf32_mkobject): Likewise.
	(ELF_TARGET_ID): New.

	* elf32-mips.c (ELF_TARGET_ID): New.
	(bfd_elf32_mkobject): Removed.

	* elf64-mips.c (ELF_TARGET_ID): New.
	(bfd_elf64_mkobject): Removed.

	* elfn32-mips.c (ELF_TARGET_ID): New.
	(bfd_elf32_mkobject): Removed.

	* elfxx-mips.c (_bfd_mips_elf_mkobject): Removed.
	* elfxx-mips.h (_bfd_mips_elf_mkobject): Likewise.

	* elfxx-target.h (bfd_elfNN_mkobject): Default to
	bfd_elf_make_object.
	(ELF_TARGET_ID): New.  Default to GENERIC_ELF_DATA.
	(elfNN_bed): Initialize target_id.
@
text
@d605 6
a610 3
      ibfd = info->input_bfds;
      flags = SEC_LOAD | SEC_ALLOC | SEC_READONLY | SEC_HAS_CONTENTS
	      | SEC_IN_MEMORY;
d5102 7
d5415 2
a5416 1
	      if ((isec->flags & SEC_RELOC) == 0
d5471 1
@


1.96
log
@fix set but unused variable warnings
@
text
@d5448 1
@


1.95
log
@include/elf/
	* internal.h (ELF_SECTION_SIZE): Protect macro args with parentheses.
	Invert logic to clarify test for .tbss.
	(ELF_IS_SECTION_IN_SEGMENT): Rename to..
	(ELF_SECTION_IN_SEGMENT_1): ..this.  Add check_vma param.  Protect
	macro args with parentheses.
	(ELF_SECTION_IN_SEGMENT): Define.
	(ELF_IS_SECTION_IN_SEGMENT_FILE): Delete.
	(ELF_IS_SECTION_IN_SEGMENT_MEMORY): Delete.
bfd/
	* elf.c: Replace use of ELF_IS_SECTION_IN_SEGMENT and
	ELF_IS_SECTION_IN_SEGMENT_FILE with ELF_SECTION_IN_SEGMENT
	throughout file.
	(assign_file_positions_for_load_sections): Modify section in
	segment warning to ignore overlay vmas.
	* elf32-spu.c (spu_elf_object_p): Replace use of
	ELF_IS_SECTION_IN_SEGMENT_MEMORY with ELF_SECTION_IN_SEGMENT.
binutils/
	* readelf.c (process_program_headers): Replace use of
	ELF_IS_SECTION_IN_SEGMENT_MEMORY with ELF_SECTION_IN_SEGMENT.
@
text
@d3 1
a3 1
   Copyright 2006, 2007, 2008, 2009 Free Software Foundation, Inc.
a4829 1
      bfd_boolean warned;
a4835 1
      warned = FALSE;
a4890 1
	      warned = TRUE;
@


1.94
log
@        * elf-bfd.h (emum elf_object_id): Rename to elf_target_id.  Add
        entries for other architectures.
        (struct elf_link_hash_table): Add hash_table_id field.
        (elf_hash_table_id): New accessor macro.
        * elflink.c (_bfd_elf_link_hash_table_init): Add target_id
        parameter.
        * elf-m10300.c (elf32_mn10300_hash_table): Check table id before
        returning cast pointer.
        (elf32_mn10300_link_hash_table_create): Identify new table as
        containing MN10300 extensions.
        (mn10300_elf_relax_section): Check pointer returned by
        elf32_mn10300_hash_table.
        * elf32-arm.c: Likewise, except using ARM extensions.
        * elf32-avr.c: Likewise, except using AVR extensions.
        * elf32-bfin.c: Likewise, except using BFIN extensions.
        * elf32-cris.c: Likewise, except using CRIS extensions.
        * elf32-frv.c: Likewise, except using FRV extensions.
        * elf32-hppa.c: Likewise, except using HPPA32 extensions.
        * elf32-i386.c: Likewise, except using I386 extensions.
        * elf32-lm32.c: Likewise, except using LM32 extensions.
        * elf32-m32r.c: Likewise, except using M32RM extensions.
        * elf32-m68hc11.c: Likewise, except using M68HC11 extensions.
        * elf32-m68hc1x.c: Likewise, except using M68HC11 extensions.
        * elf32-m68hc1x.h: Likewise, except using M68HC11 extensions.
        * elf32-m68k.c: Likewise, except using M68K extensions.
        * elf32-microblaze.c: Likewise, except using MICROBLAZE extensions.
        * elf32-ppc.c: Likewise, except using PPC32 extensions.
        * elf32-s390.c: Likewise, except using S390 extensions.
        * elf32-sh.c: Likewise, except using SH extensions.
        * elf32-spu.c: Likewise, except using SPU extensions.
        * elf32-xtensa.c: Likewise, except using XTENSA extensions.
        * elf64-alpha.c: Likewise, except using ALPHA extensions.
        * elf64-hppa.c: Likewise, except using HPPA64 extensions.
        * elf64-ppc.c: Likewise, except using PPC64 extensions.
        * elf64-s390.c: Likewise, except using S390 extensions.
        * elf64-x86-64.c: Likewise, except using X86_64 extensions.
        * elfxx-ia64.c: Likewise, except using IA64 extensions.
        * elfxx-mips.c: Likewise, except using MIPS extensions.
        * elfxx-sparc.c: Likewise, except using SPARC extensions.
        * elfxx-sparc.h: Likewise, except using SPARC extensions.
        * elf32-cr16.c (struct elf32_cr16_link_hash_table): Delete
        redundant structure.
        (elf32_cr16_hash_table): Delete unused macro.
        (elf32_cr16_link_hash_traverse): Delete unused macro.
        * elf32-score.c: Likewise.
        * elf32-score7.c: Likewise.
        * elf32-vax.c: Likewise.
        * elf64-sh64.c: Likewise.

        * emultempl/alphaelf.em: Update value expected from elf_object_id.
        * emultempl/hppaelf.em: Likewise.
        * emultempl/mipself.em: Likewise.
        * emultempl/ppc32elf.em: Likewise.
        * emultempl/ppc64elf.em: Likewise.
@
text
@d275 2
a276 1
		if (ELF_IS_SECTION_IN_SEGMENT_MEMORY (shdr, phdr))
@


1.93
log
@Add -Wshadow to the gcc command line options used when compiling the binutils.
Fix up all warnings generated by the addition of this switch.
@
text
@d359 2
a360 1
  ((struct spu_link_hash_table *) ((p)->hash))
d447 2
a448 1
				      sizeof (struct elf_link_hash_entry)))
@


1.92
log
@	* elf32-spu.c (struct spu_link_hash_table): Remove overlay_fixed,
	reserved, and extra_stack_space members.
	(spu_elf_auto_overlay): Use auto_overlay_fixed, auto_overlay_reserved,
	and extra_stack_space members of htab->params instead.
@
text
@d4404 1
a4404 1
	  int k;
d4424 1
a4424 1
	      struct call_info *pasty = find_pasted_call (sec);
d4451 1
a4451 1
	  for (k = 0; k < sinfo->num_fun; ++k)
a4480 1
	      unsigned int k;
d5255 1
a5255 1
	  struct elf_segment_map *m = *p;
@


1.91
log
@2009-11-03  Alan Modra  <amodra@@bigpond.net.au>
	    Ulrich Weigand  <uweigand@@de.ibm.com>

	* elf32-spu.c (mark_functions_via_relocs): Handle non-branch relocs
	(jump tables or other references to code labels) as well.
@
text
@d334 1
a334 10
  /* Local store --auto-overlay should reserve for non-overlay
     functions and data.  */
  unsigned int overlay_fixed;
  /* Local store --auto-overlay should reserve for stack and heap.  */
  unsigned int reserved;
  /* If reserved is not specified, stack analysis will calculate a value
     for the stack.  This parameter adjusts that value to allow for
     negative sp access (the ABI says 2000 bytes below sp are valid,
     and the overlay manager uses some of this area).  */
  int extra_stack_space;
d4157 1
d4193 2
a4194 1
  if (htab->reserved == 0)
d4202 2
a4203 1
      htab->reserved = sum_stack_param.overall_stack + htab->extra_stack_space;
d4207 1
a4207 1
  if (fixed_size + htab->reserved <= htab->local_store
d4320 1
a4320 1
  fixed_size += htab->reserved;
d4359 1
a4359 1
  else if (fixed_size < htab->overlay_fixed)
d4364 2
a4365 2
      if (max_fixed > htab->overlay_fixed)
	max_fixed = htab->overlay_fixed;
@


1.90
log
@bfd/
	* elf32-spu.c (spu_elf_auto_overlay): Insert icache linker script
	after .toe instead of before .text section.  Set the LMA of all
	overlay sections to their icache IA address.
	(spu_elf_find_overlays): Determine icache set id without reference
	to the LMA.

ld/testsuite/
	* ld-spu/icache1.d: Update to new section layout.
@
text
@d2695 1
a2695 1
      bfd_boolean reject, is_call;
a2698 1
      reject = FALSE;
d2700 1
a2700 7
      if (r_type != R_SPU_REL16
	  && r_type != R_SPU_ADDR16)
	{
	  reject = TRUE;
	  if (!(call_tree && spu_hash_table (info)->params->auto_overlay))
	    continue;
	}
d2711 1
a2711 1
      if (!reject)
d2742 2
a2743 3
	      reject = TRUE;
	      if (!(call_tree && spu_hash_table (info)->params->auto_overlay)
		  || is_hint (insn))
d2748 1
a2748 1
      if (reject)
d2758 14
a2771 2
	    spu_hash_table (info)->non_ovly_stub += 1;
	  continue;
d2820 1
a2820 1
      callee->count = 1;
@


1.89
log
@	* elf32-spu.c (spu_elf_relocate_section): Correct 2009-07-24 logic.
@
text
@d681 2
a684 1
      bfd_vma lma_start = 0;
a692 4
	      if (strncmp (s0->name, ".ovl.init", 9) != 0)
		lma_start = s0->lma;
	      else
		lma_start = s->lma;
d717 4
a720 2
	      if (((s->vma - vma_start) & (htab->params->line_size - 1))
		  || ((s->lma - lma_start) & (htab->params->line_size - 1)))
d739 1
a739 1
		= ((s->lma - lma_start) >>  htab->line_size_log2) + 1;
a4532 3
  if (fprintf (script, "SECTIONS\n{\n") <= 0)
    goto file_err;

d4535 3
a4538 1
		   " .data.icache ALIGN (16) : { *(.ovtab) *(.data.icache) }\n"
d4553 1
a4553 1
	  lma = indx << htab->line_size_log2;
d4556 1
a4556 1
		       ": AT (ALIGN (LOADADDR (.ovl.init) + SIZEOF (.ovl.init), 16) + %u) {\n",
d4574 3
d4580 3
d4634 2
a4640 2
  if (fprintf (script, "}\nINSERT BEFORE .text;\n") <= 0)
    goto file_err;
@


1.89.2.1
log
@bfd/
	* elf32-spu.c (spu_elf_auto_overlay): Insert icache linker script
	after .toe instead of before .text section.  Set the LMA of all
	overlay sections to their icache IA address.
	(spu_elf_find_overlays): Determine icache set id without reference
	to the LMA.

ld/testsuite/
	* ld-spu/icache1.d: Update to new section layout.
@
text
@a680 2
      unsigned int prev_buf = 0, set_id = 0;

d683 1
d692 4
d720 2
a721 4
	      set_id = (num_buf == prev_buf)? set_id + 1 : 0;
	      prev_buf = num_buf;

	      if ((s->vma - vma_start) & (htab->params->line_size - 1))
d740 1
a740 1
		= (set_id << htab->num_lines_log2) + num_buf;
d4534 3
a4538 3
      if (fprintf (script, "SECTIONS\n{\n") <= 0)
	goto file_err;

d4540 1
d4555 1
a4555 1
	  lma = vma + (((indx >> htab->num_lines_log2) + 1) << 18);
d4558 1
a4558 1
			       ": AT (LOADADDR (.ovl.init) + %u) {\n",
a4575 3

      if (fprintf (script, "}\nINSERT AFTER .toe;\n") <= 0)
	goto file_err;
a4578 3
      if (fprintf (script, "SECTIONS\n{\n") <= 0)
	goto file_err;

a4629 2
      if (fprintf (script, "}\nINSERT BEFORE .text;\n") <= 0)
	goto file_err;
d4635 2
@


1.89.2.2
log
@2009-11-03  Alan Modra  <amodra@@bigpond.net.au>
	    Ulrich Weigand  <uweigand@@de.ibm.com>

	* elf32-spu.c (mark_functions_via_relocs): Handle non-branch relocs
	(jump tables or other references to code labels) as well.
@
text
@d2695 1
a2695 1
      bfd_boolean nonbranch, is_call;
d2699 1
d2701 7
a2707 1
      nonbranch = r_type != R_SPU_REL16 && r_type != R_SPU_ADDR16;
d2718 1
a2718 1
      if (!nonbranch)
d2749 3
a2751 2
	      nonbranch = TRUE;
	      if (is_hint (insn))
d2756 1
a2756 1
      if (nonbranch)
d2766 2
a2767 14
	    {
	      if (call_tree && spu_hash_table (info)->params->auto_overlay)
		spu_hash_table (info)->non_ovly_stub += 1;
	      /* If the symbol type is STT_FUNC then this must be a
		 function pointer initialisation.  */
	      continue;
	    }
	  /* Ignore data references.  */
	  if ((sym_sec->flags & (SEC_ALLOC | SEC_LOAD | SEC_CODE))
	      != (SEC_ALLOC | SEC_LOAD | SEC_CODE))
	    continue;
	  /* Otherwise we probably have a jump table reloc for
	     a switch statement or some other reference to a
	     code label.  */
d2816 1
a2816 1
      callee->count = nonbranch? 0 : 1;
@


1.89.2.3
log
@	* elf32-spu.c (struct spu_link_hash_table): Remove overlay_fixed,
	reserved, and extra_stack_space members.
	(spu_elf_auto_overlay): Use auto_overlay_fixed, auto_overlay_reserved,
	and extra_stack_space members of htab->params instead.
@
text
@d334 10
a343 1

a4165 1
  unsigned int reserved;
d4201 1
a4201 2
  reserved = htab->params->auto_overlay_reserved;
  if (reserved == 0)
d4209 1
a4209 2
      reserved = (sum_stack_param.overall_stack
		  + htab->params->extra_stack_space);
d4213 1
a4213 1
  if (fixed_size + reserved <= htab->local_store
d4326 1
a4326 1
  fixed_size += reserved;
d4365 1
a4365 1
  else if (fixed_size < htab->params->auto_overlay_fixed)
d4370 2
a4371 2
      if (max_fixed > htab->params->auto_overlay_fixed)
	max_fixed = htab->params->auto_overlay_fixed;
@


1.88
log
@bfd/
	* elf32-spu.h (spu_elf_params): Add member emit_fixups.
	(spu_elf_size_sections): Declare prototype.
	* elf32-spu.c (spu_link_hash_table): Add member sfixup.
	(FIXUP_RECORD_SIZE, FIXUP_GET, FIXUP_PUT): New macros.
	(spu_elf_emit_fixup): New function.
	(spu_elf_relocate_section): Emit fixup for each SPU_ADDR32.
	(spu_elf_size_sections): New function.
ld/
	* emulparams/elf32_spu.sh (OTHER_READONLY_SECTIONS): Add .fixup
	section and __fixup_start symbol.
	* emultempl/spuelf.em (params): Initialize emit_fixups member.
	(spu_before_allocation): Call spu_elf_size_sections.
	(OPTION_SPU_EMIT_FIXUPS): Define.
	(PARSE_AND_LIST_LONGOPTS): Add --emit-fixups.
	(PARSE_AND_LIST_ARGS_CASES): Handle --emit-fixups.
	* ld.texinfo (--emit-fixups): Document.
ld/testsuite/
	* ld-spu/fixup.d: New.
	* ld-spu/fixup.s: New.
@
text
@d4909 3
a4911 2
      if (r_type == R_SPU_ADD_PIC && h != NULL
	  && (h->def_regular || ELF_COMMON_DEF_P (h)))
@


1.87
log
@include/elf/
        * spu.h (R_SPU_ADD_PIC): New.
bfd/
        * reloc.c (BFD_RELOC_SPU_ADD_PIC): Define.
        * bfd-in2.h: Regenerate.
        * libbfd.h: Regenerate.
        * elf32-spu.c (elf_howto_table): Add entries SPU_ADD_PIC.
        (spu_elf_bfd_to_reloc_type): Handle SPU_ADD_PIC.
        (spu_elf_relocate_section): Patch instructions marked by SPU_ADD_PIC.
gas/
        * config/tc-spu.c (md_apply_fix): Handle SPU_ADD_PIC.
        * config/tc-spu.h (tc_fix_adjustable): Don't adjust for SPU_ADD_PIC.
        (TC_FORCE_RELOCATION): Emit relocs for SPU_ADD_PIC.
ld/testsuite/
        * ld-spu/pic.d: New.
        * ld-spu/pic.s: New.
        * ld-spu/picdef.s: New.
@
text
@d347 3
d564 1
d607 13
d4738 42
d4972 10
d5377 66
@


1.86
log
@	* elf32-spu.c (spu_elf_size_stubs): Do set up soft-icache manager
	data even when no stubs.
	(spu_elf_place_overlay_data, spu_elf_build_stubs): Adjust.
@
text
@d91 3
d141 2
d4849 10
@


1.85
log
@	* elf32-spu.c (mark_functions_via_relocs): Init broken_cycle field
	of malloc'd struct call_info.
	(pasted_function): Likewise, priority too.
@
text
@d1630 1
a1630 1
   Return 0 on error, 1 if no stubs, 2 otherwise.  */
a1649 3
  if (htab->stub_count == NULL)
    return 1;

d1651 6
a1656 17
  amt = (htab->num_overlays + 1) * sizeof (*htab->stub_sec);
  htab->stub_sec = bfd_zmalloc (amt);
  if (htab->stub_sec == NULL)
    return 0;

  flags = (SEC_ALLOC | SEC_LOAD | SEC_CODE | SEC_READONLY
	   | SEC_HAS_CONTENTS | SEC_IN_MEMORY);
  stub = bfd_make_section_anyway_with_flags (ibfd, ".stub", flags);
  htab->stub_sec[0] = stub;
  if (stub == NULL
      || !bfd_set_section_alignment (ibfd, stub,
				     ovl_stub_size_log2 (htab->params)))
    return 0;
  stub->size = htab->stub_count[0] * ovl_stub_size (htab->params);
  if (htab->params->ovly_flavour == ovly_soft_icache)
    /* Extra space for linked list entries.  */
    stub->size += htab->stub_count[0] * 16;
d1658 2
a1659 4
  for (i = 0; i < htab->num_overlays; ++i)
    {
      asection *osec = htab->ovl_sec[i];
      unsigned int ovl = spu_elf_section_data (osec)->u.o.ovl_index;
d1661 1
a1661 1
      htab->stub_sec[ovl] = stub;
d1666 17
a1682 1
      stub->size = htab->stub_count[ovl] * ovl_stub_size (htab->params);
d1710 2
a1754 1
  const char *ovout;
d1756 3
a1758 2
  if (htab->stub_count == NULL)
    return;
d1760 6
a1765 7
  (*htab->params->place_spu_section) (htab->stub_sec[0], NULL, ".text");

  for (i = 0; i < htab->num_overlays; ++i)
    {
      asection *osec = htab->ovl_sec[i];
      unsigned int ovl = spu_elf_section_data (osec)->u.o.ovl_index;
      (*htab->params->place_spu_section) (htab->stub_sec[ovl], osec, NULL);
d1771 7
a1777 4
  ovout = ".data";
  if (htab->params->ovly_flavour == ovly_soft_icache)
    ovout = ".bss";
  (*htab->params->place_spu_section) (htab->ovtab, NULL, ovout);
d1779 2
a1780 1
  (*htab->params->place_spu_section) (htab->toe, NULL, ".toe");
d1891 1
a1891 15
  if (htab->stub_count == NULL)
    return TRUE;

  for (i = 0; i <= htab->num_overlays; i++)
    if (htab->stub_sec[i]->size != 0)
      {
	htab->stub_sec[i]->contents = bfd_zalloc (htab->stub_sec[i]->owner,
						  htab->stub_sec[i]->size);
	if (htab->stub_sec[i]->contents == NULL)
	  return FALSE;
	htab->stub_sec[i]->rawsize = htab->stub_sec[i]->size;
	htab->stub_sec[i]->size = 0;
      }

  for (i = 0; i < 2; i++)
d1893 1
a1893 6
      h = htab->ovly_entry[i];
      BFD_ASSERT (h != NULL);

      if ((h->root.type == bfd_link_hash_defined
	   || h->root.type == bfd_link_hash_defweak)
	  && h->def_regular)
d1895 5
a1899 2
	  s = h->root.u.def.section->output_section;
	  if (spu_elf_section_data (s)->u.o.ovl_index)
d1901 8
a1908 4
	      (*_bfd_error_handler) (_("%s in overlay section"),
				     h->root.root.string);
	      bfd_set_error (bfd_error_bad_value);
	      return FALSE;
a1910 2
      else
	BFD_ASSERT (0);
d1913 12
a1924 4
  /* Fill in all the stubs.  */
  process_stubs (info, TRUE);
  if (!htab->stub_err)
    elf_link_hash_traverse (&htab->elf, build_spuear_stubs, info);
d1926 4
a1929 6
  if (htab->stub_err)
    {
      (*_bfd_error_handler) (_("overlay stub relocation overflow"));
      bfd_set_error (bfd_error_bad_value);
      return FALSE;
    }
d1931 1
a1931 3
  for (i = 0; i <= htab->num_overlays; i++)
    {
      if (htab->stub_sec[i]->size != htab->stub_sec[i]->rawsize)
d1933 1
a1933 1
	  (*_bfd_error_handler)  (_("stubs don't match calculated size"));
d1937 11
a1947 1
      htab->stub_sec[i]->rawsize = 0;
@


1.84
log
@	* elf32-spu.c (spu_elf_auto_overlay): Take into account section
	alignment when packing sections into overlays.
@
text
@d2788 1
d2882 2
@


1.83
log
@	* elf32-spu.c (needs_ovl_stub): Respect .brinfo lrlive bits
	also for calls.
@
text
@d4367 1
a4367 1
      unsigned int size = 0;
d4371 2
a4372 2
	  asection *sec;
	  unsigned int tmp;
d4382 10
a4391 4
	  tmp = size + sec->size;
	  if (ovly_sections[2 * i + 1])
	    tmp += ovly_sections[2 * i + 1]->size;
	  if (tmp > overlay_size)
d4401 2
a4402 1
		  tmp += call_fun->sec->size;
d4404 7
a4410 1
		    tmp += call_fun->rodata->size;
d4416 1
a4416 1
	  if (tmp > overlay_size)
d4473 2
a4474 2
	  if (tmp + num_stubs * ovl_stub_size (htab->params)
	      > overlay_size)
d4477 1
@


1.82
log
@	* elf32-spu.c (spu_elf_relocate_section): Match overlay number
	when looking for soft-icache stubs.
@
text
@d1017 5
a1021 1
      if (call || sym_type == STT_FUNC)
d1024 1
a1024 9
	{
	  ret = br000_ovl_stub;

	  if (branch)
	    {
	      unsigned int lrlive = (contents[1] & 0x70) >> 4;
	      ret += lrlive;
	    }
	}
@


1.81
log
@	* elf32-spu.c (struct call_info): New member broken_cycle.
	(remove_cycle): Instead of physically removing call_info structures
	to break call graph cycles, mark them using the broken_cycle flag.
	(mark_overlay_section): Respect broken_cycle flag.
	(unmark_overlay_section): Likewise.
	(collect_lib_sections): Likewise.
	(collect_overlays): Likewise.
	(sum_stack): Likewise.
@
text
@d4851 4
a4854 3
		? g->br_addr == (rel->r_offset
				 + input_section->output_offset
				 + input_section->output_section->vma)
@


1.80
log
@	* elf32-spu.c (insert_callee): Accumulate incoming callee->count.
	(mark_functions_via_relocs): Initialize callee->count to 1.
	(pasted_function): Likewise.
	(spu_elf_auto_overlay): Honor call counts when determining number
	of stubs required in software i-cache mode.
@
text
@d370 1
d3275 2
a3276 3
	  *callp = call->next;
	  free (call);
	  continue;
d3519 2
a3520 1
      if (!mark_overlay_section (call->fun, info, param))
d3580 2
a3581 1
    if (!unmark_overlay_section (call->fun, info, param))
d3632 2
a3633 1
    collect_lib_sections (call->fun, info, param);
d3827 1
a3827 1
    if (!call->is_pasted)
d3873 2
a3874 1
    if (!collect_overlays (call->fun, info, ovly_sections))
d3925 2
d3970 1
a3970 1
	    if (!call->is_pasted)
@


1.79
log
@	* elf-bfd.h (struct elf_backend_data
	<elf_backend_link_output_symbol_hook>): Return an int.
	* elf64-ppc.c (ppc64_elf_output_symbol_hook): Return 2 to drop
	symbols on deleted .opd entries.
	* elflink.c (elf_link_output_sym): Return without outputting sym
	if output_symbol_hook returns 2.
	(elf_link_output_extsym): Don't assign h->indx when symbol discarded.
	Abort if we must not discard sym.
	(elf_link_input_bfd): Similarly, don't set finfo->indices for
	local syms.
	(bfd_elf_final_link): Adjust elf_link_output_sym calls.
	* elf-vxworks.c (elf_vxworks_link_output_symbol_hook): Adjust for
	elf_backend_link_output_symbol_hook return type change.
	* elf32-arm.c (output_arch_syminfo): Likewise.
	(elf32_arm_output_map_sym, elf32_arm_output_stub_sym): Likewise.
	(elf32_arm_output_arch_local_syms): Likewise.
	* elf32-cr16c.c (elf32_cr16c_link_output_symbol_hook): Likewise.
	* elf32-score.c (s3_bfd_score_elf_link_output_symbol_hook): Likewise.
	(bfd_score_elf_link_output_symbol_hook): Likewise.
	* elf32-score.h (s7_bfd_score_elf_link_output_symbol_hook): Likewise.
	* elf32-score7.c (s7_bfd_score_elf_link_output_symbol_hook): Likewise.
	* elf32-sh64.c (sh64_elf_link_output_symbol_hook): Likewise.
	* elf32-spu.c (spu_elf_output_symbol_hook): Likewise.
	* elf32-v850.c (v850_elf_link_output_symbol_hook): Likewise.
	* elf64-hppa.c (elf64_hppa_link_output_symbol_hook): Likewise.
	* elf64-mmix.c (mmix_elf_link_output_symbol_hook): Likewise.
	* elf64-sh64.c (sh64_elf64_link_output_symbol_hook): Likewise.
	* elf64-sparc.c (elf64_sparc_output_arch_syms): Likewise.
	* elfxx-mips.c (_bfd_mips_elf_link_output_symbol_hook): Likewise.
	* elfxx-mips.h (_bfd_mips_elf_link_output_symbol_hook): Likewise.
@
text
@d2595 1
a2595 1
	p->count += 1;
a2602 1
  callee->count += 1;
d2792 1
a2792 1
      callee->count = 0;
d2884 1
a2884 1
	      callee->count = 0;
d4440 5
a4445 1
	      ++num_stubs;
d4451 1
a4451 1
		    --num_stubs;
@


1.78
log
@	* elf32-spu.c (mark_overlay_section): Move .init and .fini
	sections into the software icache.
@
text
@d4987 1
a4987 1
static bfd_boolean
d5019 1
a5019 1
  return TRUE;
@


1.77
log
@bfd/
	* elf32-spu.c (build_stub): Always build "compact" sofware
	i-cache stubs.

ld/
	* emultempl/spuelf.em (PARSE_AND_LIST_ARGS_CASES): Always use
	compact stubs with software i-cache.

ld/testsuite/
	* ld-spu/icache1.d: Update for compact stubs.
@
text
@d3401 3
a3403 1
	  || strncmp (fun->sec->name, ".text.ia.", 9) == 0))
@


1.76
log
@bfd/
	* elf32-spu.c (struct spu_link_hash_table): Add fromelem_size_log2.
	(spu_elf_setup): Initialize it.
	(spu_elf_size_stubs): Move .ovtab into .bss for software i-cache.
	Update to new-sytle cache manager data structures.
	(spu_elf_build_stubs): Generate new-style cache manager data
	structures and symbols.
	(spu_elf_auto_overlay): Update size computation.

ld/testsuite/
	* ld-spu/icache1.d: Update all addresses to accomodate icache
	buffer shifted down 0x800 bytes.
@
text
@d1274 2
a1275 1
  else if (htab->params->ovly_flavour == ovly_soft_icache)
d1361 26
a1386 55
      if (!htab->params->compact_stub)
	{
	  /* The branch that uses this stub goes to stub_addr + 12.  We'll
	     set up an xor pattern that can be used by the icache manager
	     to modify this branch to go directly to its destination.  */
	  g->stub_addr += 12;
	  br_dest = g->stub_addr;
	  if (irela == NULL)
	    {
	      /* Except in the case of _SPUEAR_ stubs, the branch in
		 question is the one in the stub itself.  */
	      BFD_ASSERT (stub_type == nonovl_stub);
	      g->br_addr = g->stub_addr;
	      br_dest = to;
	    }

	  bfd_put_32 (sec->owner, dest_ovl - 1,
		      sec->contents + sec->size + 0);
	  set_id = ((dest_ovl - 1) >> htab->num_lines_log2) + 1;
	  bfd_put_32 (sec->owner, (set_id << 18) | (dest & 0x3ffff),
		      sec->contents + sec->size + 4);
	  bfd_put_32 (sec->owner, (lrlive << 29) | (g->br_addr & 0x3ffff),
		      sec->contents + sec->size + 8);
	  bfd_put_32 (sec->owner, BRASL + ((to << 5) & 0x007fff80) + 75,
		      sec->contents + sec->size + 12);
	  patt = dest ^ br_dest;
	  if (irela != NULL && ELF32_R_TYPE (irela->r_info) == R_SPU_REL16)
	    patt = (dest - g->br_addr) ^ (br_dest - g->br_addr);
	  bfd_put_32 (sec->owner, (patt << 5) & 0x007fff80,
		      sec->contents + sec->size + 16 + (g->br_addr & 0xf));
	}
      else
	{
	  g->stub_addr += 4;
	  br_dest = g->stub_addr;
	  if (irela == NULL)
	    {
	      BFD_ASSERT (stub_type == nonovl_stub);
	      g->br_addr = g->stub_addr;
	      br_dest = to;
	    }

	  set_id = ((dest_ovl - 1) >> htab->num_lines_log2) + 1;
	  bfd_put_32 (sec->owner, (set_id << 18) | (dest & 0x3ffff),
		      sec->contents + sec->size);
	  bfd_put_32 (sec->owner, BRASL + ((to << 5) & 0x007fff80) + 75,
		      sec->contents + sec->size + 4);
	  bfd_put_32 (sec->owner, (lrlive << 29) | (g->br_addr & 0x3ffff),
		      sec->contents + sec->size + 8);
	  patt = dest ^ br_dest;
	  if (irela != NULL && ELF32_R_TYPE (irela->r_info) == R_SPU_REL16)
	    patt = (dest - g->br_addr) ^ (br_dest - g->br_addr);
	  bfd_put_32 (sec->owner, (patt << 5) & 0x007fff80,
		      sec->contents + sec->size + 12);
	}
@


1.75
log
@bfd/
	* elf32-spu.c (spu_elf_modify_segment_map): Move all PF_OVERLAY
	segments first amongst the program headers.

ld/testsuite/
	* ld-spu/icache.d: Update file offsets.
	* ld-spu/ovl.d: Likewise.
	* ld-spu/ovl1.d: Likewise.
@
text
@d325 1
d465 2
d471 6
a1715 7
  flags = (SEC_ALLOC | SEC_LOAD
	   | SEC_HAS_CONTENTS | SEC_IN_MEMORY);
  htab->ovtab = bfd_make_section_anyway_with_flags (ibfd, ".ovtab", flags);
  if (htab->ovtab == NULL
      || !bfd_set_section_alignment (ibfd, htab->ovtab, 4))
    return 0;

d1720 12
a1731 3
	 b) Linked list elements, max_branch per line quadwords.  */
      htab->ovtab->size = 16 * ((1 + htab->params->max_branch)
				<< htab->num_lines_log2);
d1733 1
d1756 6
d1803 1
a1803 1
    ovout = ".data.icache";
d1986 1
a1986 1
      bfd_vma off, icache_base, linklist;
d2001 12
a2012 18
      icache_base = htab->ovl_sec[0]->vma;
      linklist = (htab->ovtab->output_section->vma
		  + htab->ovtab->output_offset
		  + off);
      for (i = 0; i < htab->params->num_lines; i++)
	{
	  bfd_vma line_end = icache_base + ((i + 1) << htab->line_size_log2);
	  bfd_vma stub_base = line_end - htab->params->max_branch * 32;
	  bfd_vma link_elem = linklist + i * htab->params->max_branch * 16;
	  bfd_vma locator = link_elem - stub_base / 2;

	  bfd_put_32 (htab->ovtab->owner, locator, p + 4);
	  bfd_put_16 (htab->ovtab->owner, link_elem, p + 8);
	  bfd_put_16 (htab->ovtab->owner, link_elem, p + 10);
	  bfd_put_16 (htab->ovtab->owner, link_elem, p + 12);
	  bfd_put_16 (htab->ovtab->owner, link_elem, p + 14);
	  p += 16;
	}
d2014 1
a2014 1
      h = define_ovtab_symbol (htab, "__icache_linked_list");
d2018 1
a2018 1
      h->size = htab->params->max_branch << (htab->num_lines_log2 + 4);
d2020 13
a2032 1
      p += h->size;
d2041 12
d2059 18
d4328 3
a4330 3
	     - word 0: ia address of present line, init to zero.
	     - word 1: link locator.  link_elem=stub_addr/2+locator
	     - halfwords 4-7: head/tail pointers for linked lists.  */
d4332 4
a4335 4
	  /* b) Linked list elements, max_branch per line.  */
	  fixed_size += htab->params->max_branch << (htab->num_lines_log2 + 4);
	  /* c) Indirect branch descriptors, 8 quadwords.  */
	  fixed_size += 8 * 16;
@


1.74
log
@	* elf32-spu.c (spu_elf_relocate_section): Only encode overlay index
	into addresses for relocation types that look at high bits.  Remove
	special handling of relocation overflow warnings.
@
text
@d5048 2
a5049 1
  struct elf_segment_map *m;
d5096 31
@


1.73
log
@	* elf32-spu.c (mark_functions_via_relocs): Handle cycles in the
	control flow graph between fragments of a function.
@
text
@a4707 1
      bfd_boolean overlay_encoded;
a4791 1
      overlay_encoded = FALSE;
d4829 2
a4837 1
		  overlay_encoded = TRUE;
a4889 5
	      /* FIXME: We don't want to warn on most references
		 within an overlay to itself, but this may silence a
		 warning that should be reported.  */
	      if (overlay_encoded && sec == input_section)
		break;
@


1.72
log
@	* elf32-spu.c (spu_elf_size_stubs): Even in software i-cache mode,
	generate only a 16-byte .toe section.
	(spu_elf_build_stubs, spu_elf_auto_overlay): Likewise.
@
text
@d2790 8
a2797 1
	    callee->fun->start = caller;
@


1.71
log
@bfd/
	* elf32-spu.c (spu_elf_size_stubs): Split out section placement to..
	(spu_elf_place_overlay_data): ..here.  New function.
	* elf32-spu.h (spu_elf_place_overlay_data): Declare.
ld/
	* emultempl/spuelf.em (spu_before_allocation): Call
	spu_elf_place_overlay_data.
ld/testsuite/
	* ld-spu/icache1.d: Update for changed overlay manager placement.
	* ld-spu/ovl.d: Likewise.
	* ld-spu/ovl2.d: Likewise.
@
text
@d1751 1
a1751 1
  htab->toe->size = htab->params->ovly_flavour == ovly_soft_icache ? 256 : 16;
d2091 1
a2091 1
  h->size = htab->params->ovly_flavour == ovly_soft_icache ? 16 * 16 : 16;
d4275 2
a4276 2
	  /* d) Pointers to __ea backing store, 16 quadwords.  */
	  fixed_size += 16 * 16;
@


1.70
log
@	* elf32-spu.c (spu_elf_find_overlays): Don't use .ovl.init lma as
	start of overlays.
	(spu_elf_build_stubs): Don't define __icache_tagbase.  Define
	__icache_tag_array and __icache_tag_array_size.
@
text
@a1662 1
  const char *ovout;
a1692 1
  (*htab->params->place_spu_section) (stub, NULL, ".text");
a1704 1
      (*htab->params->place_spu_section) (stub, osec, NULL);
a1727 1
      (*htab->params->place_spu_section) (htab->init, NULL, ".ovl.init");
a1745 4
  ovout = ".data";
  if (htab->params->ovly_flavour == ovly_soft_icache)
    ovout = ".data.icache";
  (*htab->params->place_spu_section) (htab->ovtab, NULL, ovout);
a1751 1
  (*htab->params->place_spu_section) (htab->toe, NULL, ".toe");
d1756 35
@


1.69
log
@bfd/
	* elf32-spu.c (spu_elf_find_overlays): Separate error return from
	"no overlays" return.  If there are overlays, create overlay
	manager entry symbols here, so that..
	(spu_elf_build_stubs): ..we don't need to set them up here.
	Simplify entry symbol tests.
	* elf32-spu.h (spu_elf_find_overlays): Update prototype.
ld/
	* emultempl/spuelf.em (spu_before_allocation): Report errors from
	spu_elf_find_overlays.
@
text
@d660 4
a663 1
	      lma_start = s0->lma;
d1944 1
a1944 1
      h = define_ovtab_symbol (htab, "__icache_tagbase");
d1950 7
@


1.68
log
@bfd/
	* elf32-spu.h (struct spu_elf_params): ovly_flavour now only 1 bit.
	Add compact_stub.
	(emum _ovly_flavour): Delete ovly_compact, ovly_none.
	* elf32-spu.c (struct spu_link_hash_table): Replace ovly_load and
	ovly_return fields with ovly_entry[2].  Adjust all users.
	(spu_elf_find_overlays): Set ovly_entry[1] from __icache_call_handler
	when soft-icache.
	(spu_elf_build_stubs): Likewise.
	(ovl_stub_size): Change arg to spu_elf_params pointer.  Adjust for
	ovly_flavour changes.  Update all callers.
	(ovl_stub_size_log2): New function.
	(build_stub): Handle compact icache stubs.  Use different manager
	entry point for stubs in non-icache area.
	(spu_elf_size_stubs): Don't allocate space for indirect branch
	descriptors.
	(spu_elf_build_stubs): And don't built them.
ld/
	* emultempl/spu_icache.S: Add new entry to dummy handler.
	* emultempl/spu_icache.o_c: Regenerate.
	* emultempl/spuelf.em (params): Init new field.
	(no_overlays): New static var.
	(spu_before_allocation): Use it.
	(OPTION_SPU_COMPACT_STUBS): Define.
	(PARSE_AND_LIST_LONGOPTS, PARSE_AND_LIST_OPTIONS): Add compact-stubs.
	(PARSE_AND_LIST_ARGS_CASES): Handle compact-stubs.  Adjust no-overlays
	handling.
ld/testsuite/
	* ld-spu/icache1.d: Update for fixed set_id, new manager entry, and
	reduced data.
@
text
@d606 2
a607 1
/* Identify overlays in the output bfd, and number them.  */
d609 1
a609 1
bfd_boolean
d617 4
a620 1
  const char *ovly_mgr_entry;
d623 1
a623 1
    return FALSE;
d628 1
a628 1
    return FALSE;
d640 1
a640 1
      return FALSE;
d692 1
a692 1
		  return FALSE;
d700 1
a700 1
		  return FALSE;
d720 1
a720 1
	      return FALSE;
d761 1
a761 1
		      return FALSE;
d775 25
a799 11
  ovly_mgr_entry = "__ovly_load";
  if (htab->params->ovly_flavour == ovly_soft_icache)
    ovly_mgr_entry = "__icache_br_handler";
  htab->ovly_entry[0] = elf_link_hash_lookup (&htab->elf, ovly_mgr_entry,
					      FALSE, FALSE, FALSE);
  ovly_mgr_entry = "__ovly_return";
  if (htab->params->ovly_flavour == ovly_soft_icache)
    ovly_mgr_entry = "__icache_call_handler";
  htab->ovly_entry[1] = elf_link_hash_lookup (&htab->elf, ovly_mgr_entry,
					      FALSE, FALSE, FALSE);
  return ovl_index != 0;
d918 1
a918 1
      if (h == htab->ovly_entry[0]|| h == htab->ovly_entry[1])
d1884 1
a1884 2
  h = htab->ovly_entry[0];
  if (h == NULL)
d1886 2
a1887 1
      const char *ovly_mgr_entry = "__ovly_load";
d1889 15
a1903 43
      if (htab->params->ovly_flavour == ovly_soft_icache)
	ovly_mgr_entry = "__icache_br_handler";
      h = elf_link_hash_lookup (&htab->elf, ovly_mgr_entry,
				FALSE, FALSE, FALSE);
      htab->ovly_entry[0] = h;
    }
  BFD_ASSERT (h != NULL
	      && (h->root.type == bfd_link_hash_defined
		  || h->root.type == bfd_link_hash_defweak)
	      && h->def_regular);

  s = h->root.u.def.section->output_section;
  if (spu_elf_section_data (s)->u.o.ovl_index)
    {
      (*_bfd_error_handler) (_("%s in overlay section"),
			     h->root.root.string);
      bfd_set_error (bfd_error_bad_value);
      return FALSE;
    }

  h = htab->ovly_entry[1];
  if (h == NULL)
    {
      const char *ovly_mgr_entry = "__ovly_return";

      if (htab->params->ovly_flavour == ovly_soft_icache)
	ovly_mgr_entry = "__icache_call_handler";
      h = elf_link_hash_lookup (&htab->elf, ovly_mgr_entry,
				FALSE, FALSE, FALSE);
      htab->ovly_entry[1] = h;
    }
  BFD_ASSERT (h != NULL
	      && (h->root.type == bfd_link_hash_defined
		  || h->root.type == bfd_link_hash_defweak)
	      && h->def_regular);

  s = h->root.u.def.section->output_section;
  if (spu_elf_section_data (s)->u.o.ovl_index)
    {
      (*_bfd_error_handler) (_("%s in overlay section"),
			     h->root.root.string);
      bfd_set_error (bfd_error_bad_value);
      return FALSE;
d5178 1
a5178 1
#define bfd_elf32_bfd_reloc_name_lookup	spu_elf_reloc_name_lookup
@


1.67
log
@	* elf32-spu.c (spu_elf_check_vma): Do not reset auto_overlay
	parameter just because fixed sections fit into local store.
	(spu_elf_auto_overlay): Do not declare as "noreturn".  Skip
	generating overlays if fixed sections plus reserved stack
	and heap space fit into local store.
@
text
@d314 1
a314 3
  struct elf_link_hash_entry *ovly_load;
  struct elf_link_hash_entry *ovly_return;
  unsigned long ovly_load_r_symndx;
d774 6
a779 4
  htab->ovly_load = elf_link_hash_lookup (&htab->elf, ovly_mgr_entry,
					  FALSE, FALSE, FALSE);
  if (htab->params->ovly_flavour != ovly_soft_icache)
    htab->ovly_return = elf_link_hash_lookup (&htab->elf, "__ovly_return",
d900 1
a900 1
      if (h == htab->ovly_load || h == htab->ovly_return)
d1103 2
a1104 1
   intructions, and a faster stub of four instructions.  */
d1107 1
a1107 1
ovl_stub_size (enum _ovly_flavour ovly_flavour)
d1109 7
a1115 1
  return 8 << ovly_flavour;
d1205 3
a1207 3
  to = (htab->ovly_load->root.u.def.value
	+ htab->ovly_load->root.u.def.section->output_offset
	+ htab->ovly_load->root.u.def.section->output_section->vma);
d1216 2
a1217 1
  switch (htab->params->ovly_flavour)
a1218 1
    case ovly_normal:
d1231 4
a1234 3
      break;

    case ovly_compact:
d1243 3
a1245 3
      break;

    case ovly_soft_icache:
d1325 61
a1385 28
      /* The branch that uses this stub goes to stub_addr + 12.  We'll
         set up an xor pattern that can be used by the icache manager
	 to modify this branch to go directly to its destination.  */
      g->stub_addr += 12;
      br_dest = g->stub_addr;
      if (irela == NULL)
	{
	  /* Except in the case of _SPUEAR_ stubs, the branch in
	     question is the one in the stub itself.  */
	  BFD_ASSERT (stub_type == nonovl_stub);
	  g->br_addr = g->stub_addr;
	  br_dest = to;
	}

      bfd_put_32 (sec->owner, dest_ovl - 1,
		  sec->contents + sec->size + 0);
      set_id = ((dest_ovl - 1) >> htab->num_lines_log2) + 1;
      bfd_put_32 (sec->owner, (set_id << 18) | (dest & 0x3ffff),
		  sec->contents + sec->size + 4);
      bfd_put_32 (sec->owner, (lrlive << 29) | (g->br_addr & 0x3ffff),
		  sec->contents + sec->size + 8);
      bfd_put_32 (sec->owner, BRASL + ((to << 5) & 0x007fff80) + 75,
		  sec->contents + sec->size + 12);
      patt = dest ^ br_dest;
      if (irela != NULL && ELF32_R_TYPE (irela->r_info) == R_SPU_REL16)
	patt = (dest - g->br_addr) ^ (br_dest - g->br_addr);
      bfd_put_32 (sec->owner, (patt << 5) & 0x007fff80,
		  sec->contents + sec->size + 16 + (g->br_addr & 0xf));
d1389 3
a1391 1
      break;
d1393 1
a1393 4
    default:
      abort ();
    }
  sec->size += ovl_stub_size (htab->params->ovly_flavour);
d1433 1
a1433 1
	  h->size = ovl_stub_size (htab->params->ovly_flavour);
d1630 2
a1631 1
/* Allocate space for overlay call and return stubs.  */
d1667 1
a1667 1
				     htab->params->ovly_flavour + 3))
d1669 1
a1669 1
  stub->size = htab->stub_count[0] * ovl_stub_size (htab->params->ovly_flavour);
d1683 1
a1683 1
					 htab->params->ovly_flavour + 3))
d1685 1
a1685 1
      stub->size = htab->stub_count[ovl] * ovl_stub_size (htab->params->ovly_flavour);
d1700 3
a1702 5
	 b) Linked list elements, max_branch per line quadwords.
	 c) Indirect branch descriptors, 8 quadwords.  */
      htab->ovtab->size = 16 * (((1 + htab->params->max_branch)
				 << htab->num_lines_log2)
				+ 8);
d1866 1
a1866 1
  h = htab->ovly_load;
d1875 1
a1875 1
      htab->ovly_load = h;
d1891 2
a1892 2
  h = htab->ovly_return;
  if (h == NULL && htab->params->ovly_flavour != ovly_soft_icache)
d1894 5
a1898 1
      h = elf_link_hash_lookup (&htab->elf, "__ovly_return",
d1900 14
a1913 1
      htab->ovly_return = h;
d1949 1
a1949 3
#define BI_HANDLER "__icache_ptr_handler0"
      char name[sizeof (BI_HANDLER)];
      bfd_vma off, icache_base, linklist, bihand;
a1983 25
      h = elf_link_hash_lookup (&htab->elf, "__icache_bi_handler",
				 FALSE, FALSE, FALSE);
      bihand = 0;
      if (h != NULL
	  && (h->root.type == bfd_link_hash_defined
	      || h->root.type == bfd_link_hash_defweak)
	  && h->def_regular)
	bihand = (h->root.u.def.value
		  + h->root.u.def.section->output_offset
		  + h->root.u.def.section->output_section->vma);
      memcpy (name, BI_HANDLER, sizeof (BI_HANDLER));
      for (i = 0; i < 8; i++)
	{
	  name[sizeof (BI_HANDLER) - 2] = '0' + i;
	  h = define_ovtab_symbol (htab, name);
	  if (h == NULL)
	    return FALSE;
	  h->root.u.def.value = off;
	  h->size = 16;
	  bfd_put_32 (htab->ovtab->owner, bihand, p);
	  bfd_put_32 (htab->ovtab->owner, i << 28, p + 8);
	  p += 16;
	  off += 16;
	}

d3684 1
a3684 1
		    stub_size += ovl_stub_size (htab->params->ovly_flavour);
d3702 1
a3702 1
		lib_size += ovl_stub_size (htab->params->ovly_flavour);
d4232 1
a4232 1
  fixed_size += htab->non_ovly_stub * ovl_stub_size (htab->params->ovly_flavour);
d4394 1
a4394 1
	  if (tmp + num_stubs * ovl_stub_size (htab->params->ovly_flavour)
@


1.66
log
@	* elf32-spu.c (build_stub): Correct icache set_id.
	(spu_elf_relocate_section): Likewise.
@
text
@a2064 3
  /* No need for overlays if it all fits.  */
  if (htab->params->ovly_flavour != ovly_soft_icache)
    htab->params->auto_overlay = 0;
a4034 3
static void spu_elf_auto_overlay (struct bfd_link_info *)
     ATTRIBUTE_NORETURN;

d4076 20
a4099 1
  htab = spu_hash_table (info);
a4201 10
  if (htab->reserved == 0)
    {
      struct _sum_stack_param sum_stack_param;

      sum_stack_param.emit_stack_syms = 0;
      sum_stack_param.overall_stack = 0;
      if (!for_each_node (sum_stack, info, &sum_stack_param, TRUE))
	goto err_exit;
      htab->reserved = sum_stack_param.overall_stack + htab->extra_stack_space;
    }
@


1.65
log
@	* elf32-spu.c (find_function_stack_adjust): Handle sf instruction
	used to update stack pointer.
@
text
@d1333 1
a1333 1
      set_id = (dest_ovl - 1) >> htab->num_lines_log2;
d4771 1
a4771 1
		  unsigned int set_id = (ovl - 1) >> htab->num_lines_log2;
d4773 1
a4773 1
		  overlay_encoded = set_id != 0;
@


1.64
log
@	* elf32-spu.c (spu_elf_find_overlays): Call bfd_set_error on errors.
	(find_function): Likewise.
	(pasted_function): Don't error if no prior function found.
	(discover_functions): Revert 2008-12-10 change.  Extend first
	function range to start of section.
@
text
@d2136 13
@


1.63
log
@	* elf32-spu.c (spu_elf_build_stubs): Define __icache_neg_log2_linesize.
	Define __icache_ptr_handler*, not __icache_ptr___icache_bi_handler*.
@
text
@d689 1
d697 1
d717 1
d758 1
d2480 1
d2752 1
a2752 1
pasted_function (asection *sec, struct bfd_link_info *info)
d2801 3
a2803 2
  info->callbacks->einfo (_("%A link_order not found\n"), sec);
  return FALSE;
a2826 1

d2881 1
a2881 2
	    || ELF_ST_TYPE (sy->st_info) == STT_FUNC
	    || ELF_ST_TYPE (sy->st_info) == STT_SECTION)
d3011 1
a3011 1
		if (sinfo != NULL)
d3021 2
d3026 1
a3026 1
		else if (!pasted_function (sec, info))
@


1.62
log
@bfd/
	* elf32-spu.h (struct spu_elf_params): Add non_ia_text.
	* elf32-spu.c (mark_overlay_section): Only include .text.ia.*
	sections in soft-icache lines unless non_ia_text.  Don't add
	rodata if doing so would exceed line size.
ld/
	* emultempl/spuelf.em (params): Init new field.
	(OPTION_SPU_NON_IA_TEXT): Define.
	(PARSE_AND_LIST_LONGOPTS, PARSE_AND_LIST_OPTIONS): Add --non-ia-text.
	(PARSE_AND_LIST_ARGS_CASES): Handle OPTION_SPU_NON_IA_TEXT.
@
text
@d1889 1
a1889 1
#define BI_HANDLER "__icache_ptr___icache_bi_handler0"
d1958 6
@


1.61
log
@	* elf32-spu.c (spu_elf_build_stubs): Make __icache_base absolute.
@
text
@d3282 1
d3288 4
a3291 1
  if (!fun->sec->linker_mark)
d3303 2
a3304 1
      if (spu_hash_table (info)->params->auto_overlay & OVERLAY_RODATA)
d3355 13
a3367 3
		  fun->rodata->linker_mark = 1;
		  fun->rodata->gc_mark = 1;
		  fun->rodata->flags &= ~SEC_CODE;
a3371 3
      size = fun->sec->size;
      if (fun->rodata)
	size += fun->rodata->size;
@


1.60
log
@	* elf32-spu.c (remove_cycles): Always set call->max_depth.
@
text
@d1954 2
a1955 2
      h->root.u.def.value = 0;
      h->root.u.def.section = htab->ovl_sec[0];
@


1.59
log
@	* elf32-spu.c (spu_elf_auto_overlay): Correct vma mask.
@
text
@d3143 1
a3145 1
	  call->max_depth = depth + !call->is_pasted;
@


1.58
log
@bfd/
	* elf32-spu.c (struct spu_link_hash_table): Add init, line_size_log2,
	num_lines_log2.
	(struct got_entry): Add br_addr.
	(struct call_info): Add priority.
	(struct function_info): Add lr_store and sp_adjust.
	(spu_elf_setup): Init line_size_log2 and num_lines_log2.
	(spu_elf_find_overlays): For soft-icache, mark any section within cache
	area as an overlay, and check that no other overlays exist.  Look up
	icache overlay manager entry sym.
	(BRA_STUBS, BRA, BRASL): Define.
	(enum _stub_type): Replace ovl_stub with call_ovl_stub and br*_ovl_stub.
	(needs_ovl_stub): Adjust for soft-icache.  Return priority encoded
	in branch insn.
	(count_stub, build_stub): Support soft-icache.
	(build_spuear_stubs, process_stubs): Adjust build_stub call.
	(spu_elf_size_stubs): Size soft-icache stubs.
	(overlay_index): New function.
	(spu_elf_build_stubs): Make static.  Support soft-icache.
	(spu_elf_check_vma): Don't turn off auto_overlay if soft-icache.
	(find_function_stack_adjust): Save lr store and stack adjust insn
	offsets.
	(maybe_insert_function): Adjust find_function_stack_adjust call.
	(mark_functions_via_relocs): Retrieve priority.
	(remove_cycles): Only warn about pruned arcs when stack_analysis.
	(sort_calls): Sort by priority first.
	(mark_overlay_section): Ignore .ovl.init.
	(sum_stack): Only print when stack_analysis.
	(print_one_overlay_section): New function, extracted from..
	(spu_elf_auto_overlay): ..here.  Support soft-icache overlays.
	(spu_elf_stack_analysis): Only print when htab->stack_analysis.
	(spu_elf_final_link): Call spu_elf_stack_analysis for lrlive
	analysis.  Call spu_elf_build_stubs.
	(spu_elf_relocate_section): For soft-icache encode overlay index
	into addresses.
	(spu_elf_output_symbol_hook): Support soft-icache.
	(spu_elf_modify_program_headers: Likewise.
	* elf32-spu.h (struct spu_elf_params): Add lrlive_analysis.  Rename
	num_regions to num_lines.  Add line_size and max_branch.
	(enum _ovly_flavour): Add ovly_soft_icache.
	(spu_elf_build_stubs): Delete.
gas/
	* config/tc-spu.c (md_pseudo_table): Add "brinfo".
	(brinfo): New var.
	(md_assemble): Poke brinfo into branch instructions.
	(spu_brinfo): New function.
	(md_apply_fix): Don't assume insn fields start off at zero, mask
	them to remove possible brinfo.
ld/
	* emultempl/spuelf.em (params): Init new fields.
	(num_lines_set, line_size_set, icache_mgr, icache_mgr_stream): New vars.
	(spu_place_special_section): Adjust placement for soft-icache.  Pad
	soft-icache section to a fixed size.  Clear addr_tree.
	(spu_elf_load_ovl_mgr): Support soft-icache.  Map overlay manager
	sections a little more intelligently.
	(gld${EMULATION_NAME}_finish): Don't call spu_elf_build_stubs.
	(OPTION_SPU_NUM_LINES): Rename from OPTION_SPU_NUM_REGIONS.
	(OPTION_SPU_SOFT_ICACHE, OPTION_SPU_LINE_SIZE): Define.
	(OPTION_SPU_LRLIVE): Define.
	(PARSE_AND_LIST_LONGOPTS): Add new soft-icache options.
	(PARSE_AND_LIST_OPTIONS): Likewise.
	(PARSE_AND_LIST_ARGS_CASES): Handle them.
	* emultempl/spu_icache.S: Dummy file.
	* emultempl/spu_icache.o_c: Regenerate.
	* Makefile.am (eelf32_spu.c): Depend on spu_icache.o_c.
	(spu_icache.o_c): Add rule to build.
	(CLEANFILES): Zap temp files.
	(EXTRA_DIST): Add spu_icache.o_c.
	* Makefile.in: Regenerate.
ld/testsuite/
	* ld-spu/ovl.d: Allow for absolute branches in stubs.
	* ld-spu/ovl2.d: Likewise.
@
text
@d4375 1
a4375 1
	  vma = (indx & (htab->num_lines_log2 - 1)) << htab->line_size_log2;
@


1.57
log
@bfd/
	* elf32-spu.h (struct spu_elf_params): Add num_regions.
	* elf32-spu.c (spu_elf_auto_overlay): Handle multiple overlay regions.
ld/
	* emultempl/spuelf.em (params): Init new field.
	(OPTION_SPU_NUM_REGIONS): Define.
	(PARSE_AND_LIST_LONGOPTS, PARSE_AND_LIST_OPTIONS): Add --num-regions.
	(PARSE_AND_LIST_ARGS_CASES): Handle --num-regions.
@
text
@d3 1
a3 1
   Copyright 2006, 2007, 2008 Free Software Foundation, Inc.
d304 1
d324 4
d353 4
a356 1
  bfd_vma addend;
d371 1
d394 4
d431 3
d468 2
d618 1
a643 2
  /* Look for overlapping vmas.  Any with overlap must be overlays.
     Count them.  Also count the number of overlay regions.  */
d645 1
a645 1
  for (ovl_index = 0, num_buf = 0, i = 1; i < n; i++)
d647 24
a670 2
      s = alloc_sec[i];
      if (s->vma < ovl_end)
d672 3
a674 1
	  asection *s0 = alloc_sec[i - 1];
d676 5
a680 1
	  if (spu_elf_section_data (s0)->u.o.ovl_index == 0)
d682 21
a702 3
	      alloc_sec[ovl_index] = s0;
	      spu_elf_section_data (s0)->u.o.ovl_index = ++ovl_index;
	      spu_elf_section_data (s0)->u.o.ovl_buf = ++num_buf;
d704 7
a710 4
	  alloc_sec[ovl_index] = s;
	  spu_elf_section_data (s)->u.o.ovl_index = ++ovl_index;
	  spu_elf_section_data (s)->u.o.ovl_buf = num_buf;
	  if (s0->vma != s->vma)
d712 3
a714 3
	      info->callbacks->einfo (_("%X%P: overlay sections %A and %A "
					"do not start at the same address.\n"),
				      s0, s);
d717 45
a761 1
	  if (ovl_end < s->vma + s->size)
a763 2
      else
	ovl_end = s->vma + s->size;
d769 4
a772 1
  htab->ovly_load = elf_link_hash_lookup (&htab->elf, "__ovly_load",
d774 3
a776 2
  htab->ovly_return = elf_link_hash_lookup (&htab->elf, "__ovly_return",
					    FALSE, FALSE, FALSE);
d780 6
a786 1
#define BR	0x32000000
d856 9
a864 1
  ovl_stub,
d884 1
a884 1
  bfd_boolean branch;
d886 1
d904 1
a904 1
	ret = ovl_stub;
a906 5
  /* Usually, symbols in non-overlay sections don't need stubs.  */
  if (spu_elf_section_data (sym_sec->output_section)->u.o.ovl_index == 0
      && !htab->params->non_overlay_stubs)
    return ret;

d914 2
a917 2
      bfd_byte insn[4];

d930 3
a932 1
      if (is_branch (contents) || is_hint (contents))
d934 2
a935 2
	  branch = TRUE;
	  if ((contents[0] & 0xfd) == 0x31
d966 9
a974 3
  if (sym_type != STT_FUNC
      && !branch
      && (sym_sec->flags & SEC_CODE) == 0)
d981 14
a994 1
    ret = ovl_stub;
d997 8
a1004 2
     address of a function and passing it out somehow.  */
  return !branch && sym_type == STT_FUNC ? nonovl_stub : ret;
d1042 6
d1120 10
a1129 1
   br __ovly_load  */
d1132 1
a1132 1
build_stub (struct spu_link_hash_table *htab,
d1141 2
a1142 1
  unsigned int ovl, dest_ovl;
d1145 2
a1146 1
  bfd_vma addend, from, to;
d1161 21
a1181 5
  for (g = *head; g != NULL; g = g->next)
    if (g->addend == addend && (g->ovl == ovl || g->ovl == 0))
      break;
  if (g == NULL)
    abort ();
d1183 2
a1184 2
  if (g->ovl == 0 && ovl != 0)
    return TRUE;
d1186 3
a1188 2
  if (g->stub_addr != (bfd_vma) -1)
    return TRUE;
d1214 6
a1219 2
      bfd_put_32 (sec->owner, BR + (((to - (from + 12)) << 5) & 0x007fff80),
		  sec->contents + sec->size + 12);
d1223 6
a1228 2
      bfd_put_32 (sec->owner, BRSL + (((to - from) << 5) & 0x007fff80) + 75,
		  sec->contents + sec->size);
d1233 113
d1450 1
a1450 1
      return build_stub (htab, NULL, NULL, nonovl_stub, h, NULL,
d1562 1
a1562 1
		  if (!build_stub (htab, ibfd, isec, stub_type, h, irela,
d1597 1
d1625 3
a1643 13
 /* htab->ovtab consists of two arrays.
    .	struct {
    .	  u32 vma;
    .	  u32 size;
    .	  u32 file_off;
    .	  u32 buf;
    .	} _ovly_table[];
    .
    .	struct {
    .	  u32 mapped;
    .	} _ovly_buf_table[];
    .  */

d1651 39
a1689 2
  htab->ovtab->size = htab->num_overlays * 16 + 16 + htab->num_buf * 4;
  (*htab->params->place_spu_section) (htab->ovtab, NULL, ".data");
d1695 1
a1695 1
  htab->toe->size = 16;
d1747 9
d1799 1
a1799 1
bfd_boolean
d1823 11
a1833 2
  h = elf_link_hash_lookup (&htab->elf, "__ovly_load", FALSE, FALSE, FALSE);
  htab->ovly_load = h;
d1848 7
a1854 2
  h = elf_link_hash_lookup (&htab->elf, "__ovly_return", FALSE, FALSE, FALSE);
  htab->ovly_return = h;
d1879 3
a1885 1
  /* Write out _ovly_table.  */
d1887 1
a1887 4
  /* set low bit of .size to mark non-overlay area as present.  */
  p[7] = 1;
  obfd = htab->ovtab->output_section->owner;
  for (s = obfd->sections; s != NULL; s = s->next)
d1889 75
a1963 1
      unsigned int ovl_index = spu_elf_section_data (s)->u.o.ovl_index;
d1965 15
a1979 1
      if (ovl_index != 0)
d1981 6
a1986 2
	  unsigned long off = ovl_index * 16;
	  unsigned int ovl_buf = spu_elf_section_data (s)->u.o.ovl_buf;
d1988 6
a1993 4
	  bfd_put_32 (htab->ovtab->owner, s->vma, p + off);
	  bfd_put_32 (htab->ovtab->owner, (s->size + 15) & -16, p + off + 4);
	  /* file_off written later in spu_elf_modify_program_headers.  */
	  bfd_put_32 (htab->ovtab->owner, ovl_buf, p + off + 12);
a1994 1
    }
d1996 5
a2000 5
  h = define_ovtab_symbol (htab, "_ovly_table");
  if (h == NULL)
    return FALSE;
  h->root.u.def.value = 16;
  h->size = htab->num_overlays * 16;
d2002 5
a2006 5
  h = define_ovtab_symbol (htab, "_ovly_table_end");
  if (h == NULL)
    return FALSE;
  h->root.u.def.value = htab->num_overlays * 16 + 16;
  h->size = 0;
d2008 5
a2012 5
  h = define_ovtab_symbol (htab, "_ovly_buf_table");
  if (h == NULL)
    return FALSE;
  h->root.u.def.value = htab->num_overlays * 16 + 16;
  h->size = htab->num_buf * 4;
d2014 6
a2019 5
  h = define_ovtab_symbol (htab, "_ovly_buf_table_end");
  if (h == NULL)
    return FALSE;
  h->root.u.def.value = htab->num_overlays * 16 + 16 + htab->num_buf * 4;
  h->size = 0;
d2026 1
a2026 1
  h->size = 16;
d2056 2
a2057 1
  htab->params->auto_overlay = 0;
d2062 4
a2065 1
   Search for stack adjusting insns, and return the sp delta.  */
d2068 4
a2071 1
find_function_stack_adjust (asection *sec, bfd_vma offset)
d2086 3
d2090 5
a2094 1
	continue;
a2095 2
      rt = buf[3] & 0x7f;
      ra = ((buf[2] & 0x3f) << 1) | (buf[3] >> 7);
d2109 1
d2122 1
d2323 5
a2327 1
  sinfo->fun[i].stack = -find_function_stack_adjust (sec, off);
d2547 1
d2604 6
d2690 1
d3153 4
a3156 1
	  if (!spu_hash_table (info)->params->auto_overlay)
d3233 1
a3233 1
/* qsort predicate to sort calls by max_depth then count.  */
d3242 4
d3401 1
a3401 1
     a stack!  */
d3403 2
a3404 1
      == info->output_bfd->start_address)
d3492 1
d3830 16
a3845 14
  if (!fun->non_root)
    info->callbacks->info (_("  %s: 0x%v\n"), f1, (bfd_vma) cum_stack);
  info->callbacks->minfo (_("%s: 0x%v 0x%v\n"),
			  f1, (bfd_vma) stack, (bfd_vma) cum_stack);

  if (has_call)
    {
      info->callbacks->minfo (_("  calls:\n"));
      for (call = fun->call_list; call; call = call->next)
	if (!call->is_pasted)
	  {
	    const char *f2 = func_name (call->fun);
	    const char *ann1 = call->fun == max ? "*" : " ";
	    const char *ann2 = call->is_tail ? "t" : " ";
d3847 3
a3849 2
	    info->callbacks->minfo (_("   %s%s %s\n"), ann1, ann2, f2);
	  }
d3918 81
d4018 1
d4050 4
a4053 1
  h = elf_link_hash_lookup (&htab->elf, "__ovly_load",
d4112 4
d4166 26
a4191 5
      /* Guess number of overlays.  Assuming overlay buffer is on
	 average only half full should be conservative.  */
      ovlynum = total_overlay_size * 2 / (htab->local_store - fixed_size);
      /* Space for _ovly_table[], _ovly_buf_table[] and toe.  */
      fixed_size += ovlynum * 16 + 16 + 4 + 16;
d4229 3
a4231 1
  overlay_size = (htab->local_store - fixed_size) / htab->params->num_regions;
d4322 3
a4327 1
	  
d4358 1
a4358 1
  for (region = 1; region <= htab->params->num_regions; region++)
d4360 8
a4367 1
      ovlynum = region;
d4369 8
a4376 2
      while (base < count && ovly_map[base] < ovlynum)
	base++;
d4378 15
a4392 2
      if (base == count)
	break;
d4394 10
a4403 1
      if (fprintf (script, " OVERLAY :\n {\n") <= 0)
d4406 1
a4406 1
      while (base < count)
d4408 7
a4414 4
	  unsigned int j;
	  
	  if (fprintf (script, "  .ovly%u {\n", ovlynum) <= 0)
	    goto file_err;
d4416 8
a4423 1
	  for (j = base; j < count && ovly_map[j] == ovlynum; j++)
d4425 1
a4425 8
	      asection *sec = ovly_sections[2 * j];

	      if (fprintf (script, "   %s%c%s (%s)\n",
			   (sec->owner->my_archive != NULL
			    ? sec->owner->my_archive->filename : ""),
			   info->path_separator,
			   sec->owner->filename,
			   sec->name) <= 0)
a4426 19
	      if (sec->segment_mark)
		{
		  struct call_info *call = find_pasted_call (sec);
		  while (call != NULL)
		    {
		      struct function_info *call_fun = call->fun;
		      sec = call_fun->sec;
		      if (fprintf (script, "   %s%c%s (%s)\n",
				   (sec->owner->my_archive != NULL
				    ? sec->owner->my_archive->filename : ""),
				   info->path_separator,
				   sec->owner->filename,
				   sec->name) <= 0)
			goto file_err;
		      for (call = call_fun->call_list; call; call = call->next)
			if (call->is_pasted)
			  break;
		    }
		}
d4429 1
a4429 1
	  for (j = base; j < count && ovly_map[j] == ovlynum; j++)
d4431 9
a4439 8
	      asection *sec = ovly_sections[2 * j + 1];
	      if (sec != NULL
		  && fprintf (script, "   %s%c%s (%s)\n",
			      (sec->owner->my_archive != NULL
			       ? sec->owner->my_archive->filename : ""),
			      info->path_separator,
			      sec->owner->filename,
			      sec->name) <= 0)
d4442 3
a4444 21
	      sec = ovly_sections[2 * j];
	      if (sec->segment_mark)
		{
		  struct call_info *call = find_pasted_call (sec);
		  while (call != NULL)
		    {
		      struct function_info *call_fun = call->fun;
		      sec = call_fun->rodata;
		      if (sec != NULL
			  && fprintf (script, "   %s%c%s (%s)\n",
				      (sec->owner->my_archive != NULL
				       ? sec->owner->my_archive->filename : ""),
				      info->path_separator,
				      sec->owner->filename,
				      sec->name) <= 0)
			goto file_err;
		      for (call = call_fun->call_list; call; call = call->next)
			if (call->is_pasted)
			  break;
		    }
		}
d4447 1
a4447 1
	  if (fprintf (script, "  }\n") <= 0)
a4448 5

	  base = j;
	  ovlynum += htab->params->num_regions;
	  while (base < count && ovly_map[base] < ovlynum)
	    base++;
a4450 2
      if (fprintf (script, " }\n") <= 0)
	goto file_err;
d4488 6
a4493 3
  info->callbacks->info (_("Stack size for call graph root nodes.\n"));
  info->callbacks->minfo (_("\nStack size for functions.  "
			    "Annotations: '*' max stack, 't' tail call\n"));
d4500 3
a4502 2
  info->callbacks->info (_("Maximum stack required is 0x%v\n"),
			 (bfd_vma) sum_stack_param.overall_stack);
d4516 3
a4518 1
  if (htab->params->stack_analysis
d4520 4
a4523 1
    info->callbacks->einfo ("%X%P: stack analysis error: %E\n");
d4580 1
d4585 1
d4606 1
d4691 49
d4741 3
a4743 1
      if (r_type == R_SPU_PPU32 || r_type == R_SPU_PPU64)
d4761 1
a4761 2

      if (is_ea_sym)
a4775 29
      /* If this symbol is in an overlay area, we may need to relocate
	 to the overlay stub.  */
      addend = rel->r_addend;
      if (stubs
	  && (stub_type = needs_ovl_stub (h, sym, sec, input_section, rel,
					  contents, info)) != no_stub)
	{
	  unsigned int ovl = 0;
	  struct got_entry *g, **head;

	  if (stub_type != nonovl_stub)
	    ovl = (spu_elf_section_data (input_section->output_section)
		   ->u.o.ovl_index);

	  if (h != NULL)
	    head = &h->got.glist;
	  else
	    head = elf_local_got_ents (input_bfd) + r_symndx;

	  for (g = *head; g != NULL; g = g->next)
	    if (g->addend == addend && (g->ovl == ovl || g->ovl == 0))
	      break;
	  if (g == NULL)
	    abort ();

	  relocation = g->stub_addr;
	  addend = 0;
	}

d4789 5
d4883 3
a4885 1
	if (g->addend == 0 && g->ovl == 0)
d5046 2
a5047 1
	    if (htab->ovtab != NULL && htab->ovtab->size != 0)
d5056 7
@


1.56
log
@bfd/
	* elf32-spu.g (struct spu_elf_params, enum _ovly_flavour): New.
	(spu_elf_setup): Declare.
	(spu_elf_create_sections, spu_elf_size_stubs): Update prototype.
	(spu_elf_build_stubs, spu_elf_check_vma): Likewise.
	* elf32-spu.c (struct spu_link_hash_table): Add "params". Remove
	various other fields now in "params".  Adjust code throughout.
	(struct call_info, struct function_info): Move earlier in file.
	(struct spu_elf_stack_info): Likewise.
	(spu_elf_setup): New function.
	(spu_elf_create_sections): Remove args other than "info".
	(spu_elf_size_stubs, spu_elf_build_stubs, spu_elf_check_vma): Likewise.
	(maybe_needs_stubs): Remove "output_bfd" arg.  Adjust all calls.
	(interesting_section): Similarly with "obfd" arg.
	(needs_ovl_stub): Adjust output_section test.
	(allocate_spuear_stubs): Likewise.
	(OVL_STUB_SIZE): Don't define.
	(ovl_stub_size): New function, use in place of OVL_STUB_SIZE.
	(build_stub): Test params->ovly_flavour rather than OVL_STUB_SIZE.
	(spu_elf_auto_overlay): Remove args other than "info".  Make use
	of size returned from spu_elf_load_ovl_mgr.
	(spu_elf_stack_analysis): Remove args other than "info".
	(spu_elf_relocate_section): Tidy setting of "ea".
ld/
	* emultempl/spuelf.em (params): New var, used instead of various others.
	Adjust use throughout file.
	(spu_after_open): Call spu_elf_setup.
	(spu_place_special_section): Tidy.
	(spu_elf_load_ovl_mgr): Return total size of sections loaded.  Move
	code setting overlay section alignment to..
	(spu_before_allocation): ..here.
@
text
@d3447 1
a3447 1
  int ovlynum;
d3449 1
d3629 3
a3631 5

  script = (*htab->params->spu_elf_open_overlay_script) ();

  if (fprintf (script, "SECTIONS\n{\n OVERLAY :\n {\n") <= 0)
    goto file_err;
d3634 1
a3634 1
  overlay_size = htab->local_store - fixed_size;
a3639 1
      unsigned int j;
d3742 28
a3769 1
      if (fprintf (script, "  .ovly%d {\n", ++ovlynum) <= 0)
d3771 2
a3772 1
      for (j = base; j < i; j++)
d3774 4
a3777 1
	  asection *sec = ovly_sections[2 * j];
d3779 1
a3779 8
	  if (fprintf (script, "   %s%c%s (%s)\n",
		       (sec->owner->my_archive != NULL
			? sec->owner->my_archive->filename : ""),
		       info->path_separator,
		       sec->owner->filename,
		       sec->name) <= 0)
	    goto file_err;
	  if (sec->segment_mark)
d3781 10
a3790 2
	      struct call_info *call = find_pasted_call (sec);
	      while (call != NULL)
d3792 16
a3807 12
		  struct function_info *call_fun = call->fun;
		  sec = call_fun->sec;
		  if (fprintf (script, "   %s%c%s (%s)\n",
			       (sec->owner->my_archive != NULL
				? sec->owner->my_archive->filename : ""),
			       info->path_separator,
			       sec->owner->filename,
			       sec->name) <= 0)
		    goto file_err;
		  for (call = call_fun->call_list; call; call = call->next)
		    if (call->is_pasted)
		      break;
a3809 1
	}
d3811 11
a3821 11
      for (j = base; j < i; j++)
	{
	  asection *sec = ovly_sections[2 * j + 1];
	  if (sec != NULL
	      && fprintf (script, "   %s%c%s (%s)\n",
			  (sec->owner->my_archive != NULL
			   ? sec->owner->my_archive->filename : ""),
			  info->path_separator,
			  sec->owner->filename,
			  sec->name) <= 0)
	    goto file_err;
d3823 2
a3824 5
	  sec = ovly_sections[2 * j];
	  if (sec->segment_mark)
	    {
	      struct call_info *call = find_pasted_call (sec);
	      while (call != NULL)
d3826 17
a3842 13
		  struct function_info *call_fun = call->fun;
		  sec = call_fun->rodata;
		  if (sec != NULL
		      && fprintf (script, "   %s%c%s (%s)\n",
				  (sec->owner->my_archive != NULL
				   ? sec->owner->my_archive->filename : ""),
				  info->path_separator,
				  sec->owner->filename,
				  sec->name) <= 0)
		    goto file_err;
		  for (call = call_fun->call_list; call; call = call->next)
		    if (call->is_pasted)
		      break;
a3844 1
	}
d3846 2
a3847 2
      if (fprintf (script, "  }\n") <= 0)
	goto file_err;
d3849 4
a3852 5
      while (dummy_caller.call_list != NULL)
	{
	  struct call_info *call = dummy_caller.call_list;
	  dummy_caller.call_list = call->next;
	  free (call);
d3855 2
a3856 1
      base = i;
d3858 2
d3862 1
a3862 1
  if (fprintf (script, " }\n}\nINSERT AFTER .text;\n") <= 0)
@


1.55
log
@	* elf32-spu.c (define_ovtab_symbol): Don't abort on symbols
	defined in linker scripts.
	(discover_functions): Consider STT_SECTION symbols too.
	(collect_lib_sections): Don't cut short call tree traversal
	when function size is too large.
@
text
@d300 2
a337 20
  /* Stash various callbacks for --auto-overlay.  */
  void (*spu_elf_load_ovl_mgr) (void);
  FILE *(*spu_elf_open_overlay_script) (void);
  void (*spu_elf_relink) (void);

  /* Bit 0 set if --auto-overlay.
     Bit 1 set if --auto-relink.
     Bit 2 set if --overlay-rodata.  */
  unsigned int auto_overlay : 3;
#define AUTO_OVERLAY 1
#define AUTO_RELINK 2
#define OVERLAY_RODATA 4

  /* Set if we should emit symbols for stubs.  */
  unsigned int emit_stub_syms:1;

  /* Set if we want stubs on calls out of overlay regions to
     non-overlay regions.  */
  unsigned int non_overlay_stubs : 1;

a339 6

  /* Set if stack size analysis should be done.  */
  unsigned int stack_analysis : 1;

  /* Set if __stack_* syms will be emitted.  */
  unsigned int emit_stack_syms : 1;
d355 63
d447 7
d528 1
a528 3
spu_elf_create_sections (struct bfd_link_info *info,
			 int stack_analysis,
			 int emit_stack_syms)
a530 5
  struct spu_link_hash_table *htab = spu_hash_table (info);

  /* Stash some options away where we can get at them later.  */
  htab->stack_analysis = stack_analysis;
  htab->emit_stack_syms = emit_stack_syms;
a667 7
/* Support two sizes of overlay stubs, a slower more compact stub of two
   intructions, and a faster stub of four instructions.  */
#ifndef OVL_STUB_SIZE
/* Default to faster.  */
#define OVL_STUB_SIZE 16
/* #define OVL_STUB_SIZE 8 */
#endif
d719 1
a719 1
maybe_needs_stubs (asection *input_section, bfd *output_bfd)
d726 1
a726 2
  if (input_section->output_section == NULL
      || input_section->output_section->owner != output_bfd)
d763 1
a763 2
      || sym_sec->output_section == NULL
      || sym_sec->output_section->owner != info->output_bfd
d783 1
a783 1
      && !htab->non_overlay_stubs)
d944 9
d978 1
a978 1
  unsigned int ovl;
d981 1
a981 1
  bfd_vma addend, val, from, to;
d1015 2
a1016 5
  val = to - from;
  if (OVL_STUB_SIZE == 16)
    val -= 12;
  if (((dest | to | from) & 3) != 0
      || val + 0x40000 >= 0x80000)
d1021 1
a1021 1
  ovl = spu_elf_section_data (dest_sec->output_section)->u.o.ovl_index;
d1023 1
a1023 1
  if (OVL_STUB_SIZE == 16)
d1025 2
a1026 1
      bfd_put_32 (sec->owner, ILA + ((ovl << 7) & 0x01ffff80) + 78,
d1032 1
a1032 1
      bfd_put_32 (sec->owner, BR + ((val << 5) & 0x007fff80),
d1034 4
a1037 4
    }
  else if (OVL_STUB_SIZE == 8)
    {
      bfd_put_32 (sec->owner, BRSL + ((val << 5) & 0x007fff80) + 75,
d1039 3
d1043 2
a1044 3
      val = (dest & 0x3ffff) | (ovl << 18);
      bfd_put_32 (sec->owner, val,
		  sec->contents + sec->size + 4);
d1046 1
a1046 3
  else
    abort ();
  sec->size += OVL_STUB_SIZE;
d1048 1
a1048 1
  if (htab->emit_stub_syms)
d1086 2
a1087 2
	  h->root.u.def.value = sec->size - OVL_STUB_SIZE;
	  h->size = OVL_STUB_SIZE;
d1117 1
a1117 2
      && sym_sec->output_section != NULL
      && sym_sec->output_section->owner == info->output_bfd
d1120 1
a1120 1
	  || htab->non_overlay_stubs))
d1142 1
a1142 2
      && sym_sec->output_section != NULL
      && sym_sec->output_section->owner == info->output_bfd
d1145 1
a1145 1
	  || htab->non_overlay_stubs))
d1187 1
a1187 1
	  if (!maybe_needs_stubs (isec, info->output_bfd))
d1286 1
a1286 4
spu_elf_size_stubs (struct bfd_link_info *info,
		    void (*place_spu_section) (asection *, asection *,
					       const char *),
		    int non_overlay_stubs)
d1288 1
a1288 1
  struct spu_link_hash_table *htab = spu_hash_table (info);
a1294 1
  htab->non_overlay_stubs = non_overlay_stubs;
d1298 1
d1317 2
a1318 1
      || !bfd_set_section_alignment (ibfd, stub, 3 + (OVL_STUB_SIZE > 8)))
d1320 2
a1321 2
  stub->size = htab->stub_count[0] * OVL_STUB_SIZE;
  (*place_spu_section) (stub, NULL, ".text");
d1330 2
a1331 1
	  || !bfd_set_section_alignment (ibfd, stub, 3 + (OVL_STUB_SIZE > 8)))
d1333 2
a1334 2
      stub->size = htab->stub_count[ovl] * OVL_STUB_SIZE;
      (*place_spu_section) (stub, osec, NULL);
d1358 1
a1358 1
  (*place_spu_section) (htab->ovtab, NULL, ".data");
d1365 1
a1365 1
  (*place_spu_section) (htab->toe, NULL, ".toe");
d1460 1
a1460 1
spu_elf_build_stubs (struct bfd_link_info *info, int emit_syms)
a1468 1
  htab->emit_stub_syms = emit_syms;
d1588 1
a1588 10
spu_elf_check_vma (struct bfd_link_info *info,
		   int auto_overlay,
		   unsigned int lo,
		   unsigned int hi,
		   unsigned int overlay_fixed,
		   unsigned int reserved,
		   int extra_stack_space,
		   void (*spu_elf_load_ovl_mgr) (void),
		   FILE *(*spu_elf_open_overlay_script) (void),
		   void (*spu_elf_relink) (void))
d1594 2
a1596 2
  if (auto_overlay & AUTO_OVERLAY)
    htab->auto_overlay = auto_overlay;
a1597 6
  htab->overlay_fixed = overlay_fixed;
  htab->reserved = reserved;
  htab->extra_stack_space = extra_stack_space;
  htab->spu_elf_load_ovl_mgr = spu_elf_load_ovl_mgr;
  htab->spu_elf_open_overlay_script = spu_elf_open_overlay_script;
  htab->spu_elf_relink = spu_elf_relink;
d1609 1
a1609 1
  htab->auto_overlay = 0;
a1758 63
struct call_info
{
  struct function_info *fun;
  struct call_info *next;
  unsigned int count;
  unsigned int max_depth;
  unsigned int is_tail : 1;
  unsigned int is_pasted : 1;
};

struct function_info
{
  /* List of functions called.  Also branches to hot/cold part of
     function.  */
  struct call_info *call_list;
  /* For hot/cold part of function, point to owner.  */
  struct function_info *start;
  /* Symbol at start of function.  */
  union {
    Elf_Internal_Sym *sym;
    struct elf_link_hash_entry *h;
  } u;
  /* Function section.  */
  asection *sec;
  asection *rodata;
  /* Where last called from, and number of sections called from.  */
  asection *last_caller;
  unsigned int call_count;
  /* Address range of (this part of) function.  */
  bfd_vma lo, hi;
  /* Stack usage.  */
  int stack;
  /* Distance from root of call tree.  Tail and hot/cold branches
     count as one deeper.  We aren't counting stack frames here.  */
  unsigned int depth;
  /* Set if global symbol.  */
  unsigned int global : 1;
  /* Set if known to be start of function (as distinct from a hunk
     in hot/cold section.  */
  unsigned int is_func : 1;
  /* Set if not a root node.  */
  unsigned int non_root : 1;
  /* Flags used during call tree traversal.  It's cheaper to replicate
     the visit flags than have one which needs clearing after a traversal.  */
  unsigned int visit1 : 1;
  unsigned int visit2 : 1;
  unsigned int marking : 1;
  unsigned int visit3 : 1;
  unsigned int visit4 : 1;
  unsigned int visit5 : 1;
  unsigned int visit6 : 1;
  unsigned int visit7 : 1;
};

struct spu_elf_stack_info
{
  int num_fun;
  int max_fun;
  /* Variable size array describing functions, one per contiguous
     address range belonging to a function.  */
  struct function_info fun[1];
};

d2060 1
a2060 1
interesting_section (asection *s, bfd *obfd)
d2062 1
a2062 2
  return (s->output_section != NULL
	  && s->output_section->owner == obfd
d2084 1
a2084 1
  if (!interesting_section (sec, info->output_bfd)
d2115 1
a2115 1
	  if (!(call_tree && spu_hash_table (info)->auto_overlay))
d2124 1
a2124 2
	  || sym_sec->output_section == NULL
	  || sym_sec->output_section->owner != info->output_bfd)
d2154 1
a2154 1
	      if (!(call_tree && spu_hash_table (info)->auto_overlay)
d2365 1
a2365 1
	      if (interesting_section (sec, info->output_bfd))
d2403 1
a2403 1
	    if (s != NULL && interesting_section (s, info->output_bfd))
d2445 1
a2445 1
	if (interesting_section (sec, info->output_bfd))
d2486 1
a2486 1
	    if (interesting_section (sec, info->output_bfd))
d2521 1
a2521 1
	    if (interesting_section (sec, info->output_bfd))
d2680 1
a2680 1
	  if (!spu_hash_table (info)->auto_overlay)
d2740 1
a2740 1
  if (!spu_hash_table (info)->auto_overlay
d2819 1
a2819 1
      if (spu_hash_table (info)->auto_overlay & OVERLAY_RODATA)
d3075 1
d3107 1
d3139 1
a3139 1
		    stub_size += OVL_STUB_SIZE;
d3157 1
a3157 1
		lib_size += OVL_STUB_SIZE;
d3344 1
a3344 1
  if (htab->auto_overlay)
d3435 1
a3435 1
static void spu_elf_auto_overlay (struct bfd_link_info *, void (*) (void))
d3439 1
a3439 2
spu_elf_auto_overlay (struct bfd_link_info *info,
		      void (*spu_elf_load_ovl_mgr) (void))
d3496 1
a3496 7
      asection *text = bfd_get_section_by_name (info->output_bfd, ".text");
      if (text != NULL)
	fixed_size -= text->size;
      spu_elf_load_ovl_mgr ();
      text = bfd_get_section_by_name (info->output_bfd, ".text");
      if (text != NULL)
	fixed_size += text->size;
d3588 1
a3588 1
  fixed_size += htab->non_ovly_stub * OVL_STUB_SIZE;
d3629 1
a3629 1
  script = htab->spu_elf_open_overlay_script ();
d3647 1
a3647 1
	  unsigned int stub_size;
d3712 1
a3712 1
	  stub_size = 0;
d3717 1
a3717 1
	      stub_size += OVL_STUB_SIZE;
d3723 1
a3723 1
		    stub_size -= OVL_STUB_SIZE;
d3727 2
a3728 1
	  if (tmp + stub_size > overlay_size)
d3832 2
a3833 2
  if (htab->auto_overlay & AUTO_RELINK)
    htab->spu_elf_relink ();
d3847 1
a3847 1
spu_elf_stack_analysis (struct bfd_link_info *info, int emit_stack_syms)
d3849 1
d3858 1
d3863 1
a3863 1
  sum_stack_param.emit_stack_syms = emit_stack_syms;
d3880 2
a3881 2
  if (htab->auto_overlay)
    spu_elf_auto_overlay (info, htab->spu_elf_load_ovl_mgr);
d3883 2
a3884 2
  if (htab->stack_analysis
      && !spu_elf_stack_analysis (info, htab->emit_stack_syms))
d3937 1
a3937 1
  asection *ea = bfd_get_section_by_name (output_bfd, "._ea");
d3945 2
a3946 1
	   && maybe_needs_stubs (input_section, output_bfd));
@


1.54
log
@	* elf32-spu.c (find_function_stack_adjust): Don't limit number
	of insns scanned.  Correct sp tests.  Handle "fsmbi" and "andbi".
	(mark_detached_root): New function.
	(build_call_tree): Call it.
	(sort_calls): Don't do void* arithmetic.
@
text
@d1404 1
a1404 1
  else
d1412 7
d2444 2
a2445 1
	    || ELF_ST_TYPE (sy->st_info) == STT_FUNC)
d3058 1
a3058 6
  if (size > lib_param->lib_size)
    return TRUE;

  *lib_param->lib_sections++ = fun->sec;
  fun->sec->gc_mark = 0;
  if (fun->rodata && fun->rodata->linker_mark && fun->rodata->gc_mark)
d3060 9
a3068 2
      *lib_param->lib_sections++ = fun->rodata;
      fun->rodata->gc_mark = 0;
a3069 2
  else
    *lib_param->lib_sections++ = NULL;
@


1.53
log
@	* elflink.c (bfd_elf_final_link): Move code reading relocs to..
	* elf32-spu.c (spu_elf_count_relocs): ..here.  Adjust params.
	* elf-bfd.h (struct elf_backend_data): Update elf_backend_count_relocs
	params.
@
text
@a1593 1
  int unrecog;
d1597 1
a1597 1
  for (unrecog = 0; offset + 4 <= sec->size && unrecog < 32; offset += 4)
d1623 1
a1623 1
	      if (imm > 0)
d1634 5
a1638 1
	    return reg[rt];
d1651 1
a1651 1
		    goto unknown_insn;
d1672 9
a1680 2
      else if ((buf[0] == 0x33 && imm == 1 /* brsl .+4 */)
	       || (buf[0] == 0x08 && (buf[1] & 0xe0) == 0 /* sf */))
d1682 11
a1692 1
	  /* Used in pic reg load.  Say rt is trashed.  */
a1698 2
    unknown_insn:
      ++unrecog;
d2739 17
d2790 4
a2793 1
  return for_each_node (remove_cycles, info, &depth, TRUE);
d2813 1
a2813 1
  return c1 - c2;
@


1.52
log
@bfd/
	PR 6789
	* elf.c (assign_file_positions_for_load_sections): Call
	_bfd_elf_map_sections_to_segments, not elf_modify_segment_map.
	(get_program_header_size): Protect against NULL info.
	(_bfd_elf_map_sections_to_segments): Likewise.
	* elf32-spu.c (spu_elf_additional_program_headers): Likewise.
ld/testsuite/
	* ld-elf/extract-symbol-1sec.d: Correct section lma.
@
text
@d3898 1
a3898 1
spu_elf_count_relocs (asection *sec, Elf_Internal_Rela *relocs)
d3900 1
a3901 1
  Elf_Internal_Rela *relend = relocs + sec->reloc_count;
d3903 3
a3905 1
  for (; relocs < relend; relocs++)
d3907 12
a3918 3
      int r_type = ELF32_R_TYPE (relocs->r_info);
      if (r_type == R_SPU_PPU32 || r_type == R_SPU_PPU64)
	++count;
@


1.51
log
@	* elf32-spu.c (spu_elf_auto_overlay): Use the maximum possible
	if --fixed-space request is too large.
@
text
@d4248 1
a4248 2
  struct spu_link_hash_table *htab = spu_hash_table (info);
  int extra = htab->num_overlays;
d4251 6
@


1.51.2.1
log
@bfd/
	PR 6789
	* elf.c (assign_file_positions_for_load_sections): Call
	_bfd_elf_map_sections_to_segments, not elf_modify_segment_map.
	(get_program_header_size): Protect against NULL info.
	(_bfd_elf_map_sections_to_segments): Likewise.
	* elf32-spu.c (spu_elf_additional_program_headers): Likewise.
ld/testsuite/
	* ld-elf/extract-symbol-1sec.d: Correct section lma.
@
text
@d4248 2
a4249 1
  int extra = 0;
a4251 6
  if (info != NULL)
    {
      struct spu_link_hash_table *htab = spu_hash_table (info);
      extra = htab->num_overlays;
    }

@


1.50
log
@	* elf32-spu.c (mark_overlay_section): Move code calculating
	max_overlay_size to correct block.
	(spu_elf_auto_overlay): Don't use %x in einfo error message.
@
text
@d3611 1
a3611 2
  if (fixed_size < htab->overlay_fixed
      && htab->overlay_fixed + mos_param.max_overlay_size < htab->local_store)
d3613 6
a3618 1
      unsigned int lib_size = htab->overlay_fixed - fixed_size;
d3622 1
a3622 1
      fixed_size = htab->overlay_fixed - lib_size;
@


1.49
log
@	* elf32-spu.c (spu_elf_relocate_section): Expand
	RELOC_FOR_GLOBAL_SYMBOL.  Don't warn about undefined symbols for
	R_SPU_PPU32 and R_SPU_PPU64 relocations.
@
text
@d2810 2
d2819 1
a2822 1
	  unsigned int size;
a2876 5
	  size = fun->sec->size;
	  if (fun->rodata)
	    size += fun->rodata->size;
	  if (mos_param->max_overlay_size < size)
	    mos_param->max_overlay_size = size;
d2878 5
d3605 4
a3608 3
    info->callbacks->einfo (_("non-overlay plus maximum overlay size "
			      "of 0x%x exceeds local store\n"),
			    fixed_size + mos_param.max_overlay_size);
@


1.48
log
@	* elf32-spu.c (needs_ovl_stub): Correctly return nonovl_stub for
	non-branch insns.
@
text
@d3969 45
a4013 4
	  RELOC_FOR_GLOBAL_SYMBOL (info, input_bfd, input_section, rel,
				   r_symndx, symtab_hdr, sym_hashes,
				   h, sec, relocation,
				   unresolved_reloc, warned);
@


1.47
log
@	* elf32-spu.c (build_stub): Allow wraparound on stub branches.
	(allocate_spuear_stubs, build_spuear_stubs): Return value from
	count_stub/build_stub.
	(spu_elf_build_stubs): Correct location of stub reloc error message.
@
text
@d822 1
a822 1
    return ovl_stub;
@


1.46
log
@bfd/
	* elf32-spu.c (struct spu_link_hash_table): Add extra_stack_space.
	(spu_elf_check_vma): Add extra_stack_space param, copy to htab.
	(spu_elf_auto_overlay): Use it.
	(RECURSE_UNMARK): Define as 0.
	(unmark_overlay_section): Heed RECURSE_UNMARK.
	* elf32-spu.h (spu_elf_check_vma): Update prototype.
ld/
	* emultempl/spuelf.em (extra_stack_space): New variable.
	(gld${EMULATION_NAME}_finish): Pass it to spu_elf_check_vma.
	(PARSE_AND_LIST_LONGOPTS, PARSE_AND_LIST_OPTIONS,
	PARSE_AND_LIST_ARGS_CASES): Handle --extra-stack-space.
	* emultempl/spu_ovl.S: Mask interrupts during dma and update of
	overlay manager structures.
	* emultempl/spu_ovl.o: Regenerate.
@
text
@d980 1
a980 1
      || val + 0x20000 >= 0x40000)
d1086 1
a1086 1
      count_stub (htab, NULL, NULL, nonovl_stub, h, NULL);
d1112 2
a1113 2
      build_stub (htab, NULL, NULL, nonovl_stub, h, NULL,
		  h->root.u.def.value, sym_sec);
d1464 2
a1466 1
  elf_link_hash_traverse (&htab->elf, build_spuear_stubs, info);
d1468 5
a1472 1
    return FALSE;
a1484 7
  if (htab->stub_err)
    {
      (*_bfd_error_handler) (_("overlay stub relocation overflow"));
      bfd_set_error (bfd_error_bad_value);
      return FALSE;
    }

@


1.45
log
@	* elf32-spu.c (spu_elf_auto_overlay): Add valid area below sp
	to stack calculation.
@
text
@d328 5
d1556 1
d1571 1
d2933 5
d2965 2
a2966 1
  uos_param->clearing += excluded;
d2968 1
a2968 1
  if (uos_param->clearing)
d2979 2
a2980 1
  uos_param->clearing -= excluded;
d3591 1
a3591 1
      htab->reserved = sum_stack_param.overall_stack + 2000;
@


1.44
log
@include/
	* bfdlink.h (struct bfd_link_info): Add "path_separator".
bfd/
	* elf32-spu.c (spu_elf_auto_overlay): Relax requirement that
	file names be unique.  Specify archive:path in overlay script.
ld/
	* ldlang.c (name_match): New function.
	(unique_section_p, walk_wild_consider_section): Use it here.
	(walk_wild_section_general): And here.
	(archive_path): New function.
	(walk_wild): Match archive:path filespecs.
	(open_input_bfds): Don't load archive:path files.
	* emultempl/spuelf.em (choose_target): Set path_separator.
	* emulparams/elf32_spu.sh: Add ._ea.* sections to ._ea output.
@
text
@d3577 1
a3577 1
      htab->reserved = sum_stack_param.overall_stack;
@


1.43
log
@	* elf32-spu.c (get_sym_h): Don't attempt to read global syms.
	(process_stubs): Likewise.
	(discover_functions): Don't used cached symbols.
	(maybe_insert_function): Correct condition under which function
	array is realloc'd.
	(mark_functions_via_relocs): Delete unused variable.
@
text
@d3547 1
a3547 1
	    if (bfd_arr[i - 1]->my_archive && bfd_arr[i]->my_archive)
d3549 1
a3549 1
		if (bfd_arr[i - 1]->my_archive == bfd_arr[i]->my_archive)
d3551 2
a3552 2
					  bfd_arr[i - 1]->filename,
					  bfd_arr[i - 1]->my_archive->filename);
d3554 3
a3556 4
		  info->callbacks->einfo (_("%s in both %s and %s\n"),
					  bfd_arr[i - 1]->filename,
					  bfd_arr[i - 1]->my_archive->filename,
					  bfd_arr[i]->my_archive->filename);
a3557 12
	    else if (bfd_arr[i - 1]->my_archive)
	      info->callbacks->einfo (_("%s in %s and as an object\n"),
				      bfd_arr[i - 1]->filename,
				      bfd_arr[i - 1]->my_archive->filename);
	    else if (bfd_arr[i]->my_archive)
	      info->callbacks->einfo (_("%s in %s and as an object\n"),
				      bfd_arr[i]->filename,
				      bfd_arr[i]->my_archive->filename);
	    else
	      info->callbacks->einfo (_("%s duplicated\n"),
				      bfd_arr[i]->filename);
	    ok = FALSE;
a3560 4
	  /* FIXME: modify plain object files from foo.o to ./foo.o
	     and emit EXCLUDE_FILE to handle the duplicates in
	     archives.  There is a pathological case we can't handle:
	     We may have duplicate file names within a single archive.  */
d3736 5
a3740 3
	  if (fprintf (script, "   [%c]%s (%s)\n",
		       sec->owner->filename[0],
		       sec->owner->filename + 1,
d3750 5
a3754 3
		  if (fprintf (script, "   [%c]%s (%s)\n",
			       sec->owner->filename[0],
			       sec->owner->filename + 1,
d3767 7
a3773 4
	  if (sec != NULL && fprintf (script, "   [%c]%s (%s)\n",
				      sec->owner->filename[0],
				      sec->owner->filename + 1,
				      sec->name) <= 0)
d3784 7
a3790 4
		  if (sec != NULL && fprintf (script, "   [%c]%s (%s)\n",
					      sec->owner->filename[0],
					      sec->owner->filename + 1,
					      sec->name) <= 0)
@


1.42
log
@	* elf32-spu.c (spu_elf_object_p): New function.
	(elf_backend_object_p): Define.
	(build_stub): Correct second word of 8 byte overlay stubs.
	(spu_elf_relocate_section): Formatting.
@
text
@d451 3
a453 11
	    {
	      size_t symcount = symtab_hdr->sh_info;

	      /* If we are reading symbols into the contents, then
		 read the global syms too.  This is done to cache
		 syms for later stack analysis.  */
	      if ((unsigned char **) locsymsp == &symtab_hdr->contents)
		symcount = symtab_hdr->sh_size / symtab_hdr->sh_entsize;
	      locsyms = bfd_elf_get_elf_syms (ibfd, symtab_hdr, symcount, 0,
					      NULL, NULL, NULL);
	    }
a1127 1
      void *psyms;
a1136 5
      /* Arrange to read and keep global syms for later stack analysis.  */
      psyms = &local_syms;
      if (htab->stack_analysis)
	psyms = &symtab_hdr->contents;

d1186 1
a1186 1
	      if (!get_sym_h (&h, &sym, &sym_sec, psyms, r_indx, ibfd))
d1850 1
a1850 4
  if (++i < sinfo->num_fun)
    memmove (&sinfo->fun[i + 1], &sinfo->fun[i],
	     (sinfo->num_fun - i) * sizeof (sinfo->fun[i]));
  else if (i >= sinfo->max_fun)
d1864 4
a2096 1
  Elf_Internal_Sym *syms;
a2110 1
  syms = *(Elf_Internal_Sym **) psyms;
d2390 10
a2399 1
      syms = (Elf_Internal_Sym *) symtab_hdr->contents;
d2401 1
a2401 7
	{
	  syms = bfd_elf_get_elf_syms (ibfd, symtab_hdr, symcount, 0,
				       NULL, NULL, NULL);
	  symtab_hdr->contents = (void *) syms;
	  if (syms == NULL)
	    return FALSE;
	}
@


1.41
log
@	* elf32-spu.c (spu_elf_relocate_section): Rename is_ea to is_ea_sym.
@
text
@d244 38
d1006 1
a1006 1
      val = (dest & 0x3ffff) | (ovl << 14);
d3957 1
d4038 10
a4047 3
      if (stubs)
	{
	  enum _stub_type stub_type;
d4049 4
a4052 6
	  stub_type = needs_ovl_stub (h, sym, sec, input_section, rel,
				      contents, info);
	  if (stub_type != no_stub)
	    {
	      unsigned int ovl = 0;
	      struct got_entry *g, **head;
d4054 5
a4058 3
	      if (stub_type != nonovl_stub)
		ovl = (spu_elf_section_data (input_section->output_section)
		       ->u.o.ovl_index);
d4060 2
a4061 14
	      if (h != NULL)
		head = &h->got.glist;
	      else
		head = elf_local_got_ents (input_bfd) + r_symndx;

	      for (g = *head; g != NULL; g = g->next)
		if (g->addend == addend && (g->ovl == ovl || g->ovl == 0))
		  break;
	      if (g == NULL)
		abort ();

	      relocation = g->stub_addr;
	      addend = 0;
	    }
d4393 1
@


1.40
log
@bfd/
	* elf32-spu.c (spu_elf_special_sections): Add "._ea".
	(spu_elf_relocate_section): Handle relocations against symbols
	defined in ._ea specially.
binutils/
	* embedspu.sh: Take note of R_SPU_PPU32/64 relocs without a symbol,
	and if present, put image in ".data.speelf".  Put program handle
	in ".data.spehandle".
ld/emulparams/
	* elf32_spu.sh (OTHER_SECTIONS): Add "._ea".
	* elf32ppc.sh: If building with spu support, put ".data.spehandle"
	sections at the start of ".data" and provide a symbol to locate
	the directory of embedded spe programs.
ld/testsuite/
	* ld-spu/ear.s: Align various sections.
	* ld-spu/embed.rd: Update.
@
text
@d3894 1
a3894 1
  bfd_boolean is_ea;
d3958 4
a3961 3
      is_ea = (ea != NULL
	       && sec != NULL
	       && sec->output_section == ea);
d3964 1
a3964 1
	  if (is_ea)
d3981 1
a3981 1
      if (is_ea)
@


1.39
log
@	* elf32-spu.c (spu_elf_build_stubs): Correct error message.
	(mark_functions_via_relocs): Remove premature init of symtab_hdr.
	(collect_overlays): Commment typo fix.
@
text
@d94 1
d3891 1
d3894 1
d3909 1
a3909 1
      unsigned long r_symndx;
a3921 6
      if (r_type == R_SPU_PPU32 || r_type == R_SPU_PPU64)
	{
	  emit_these_relocs = TRUE;
	  continue;
	}

d3958 25
a4083 1
      && !info->relocatable
@


1.38
log
@bfd/
	* elf32-spu.c: Include libiberty.h.
	(struct spu_link_hash_table): Add local_stire, overlay_fixed, reserved,
	non_ovly_stub, spu_elf_load_ovl_mgr, spu_elf_open_overlay_script,
	spu_elf_relink, auto_overlay fields.
	(AUTO_OVERLAY, AUTO_RELINK, OVERLAY_RODATA): Define.
	(needs_ovl_stub): Flip test so that call to non-function warning
	is emitted during relocate_section rather than earlier.
	(spu_elf_check_vma): Stash --auto-overlay parameters, and clear
	auto_overlay if no section exceeds local store.
	(struct call_info): Add count, max_depth, is_pasted fields.
	(struct function_info): Add rodata, last_caller, call_count,
	depth, new visit flags.
	(insert_callee): Increment call count.
	(copy_callee): New function.
	(mark_functions_via_relocs): Investigate all reloc types to count
	possible function pointer stubs for --auto-overlay.  Track
	last_caller and increment function call_count.
	(pasted_function): Insert a "call" into call info for pasted section.
	(remove_cycles): Track max depth of calls.  Don't emit call graph
	pruning warning for --auto-overlay.
	(build_call_tree): Don't transfer_calls for --auto-overlay.
	Adjust remove_cycles call.
	(sort_calls, sort_lib, sort_bfds): New functions.
	(struct _mos_param, struct _uos_param, struct _cl_param): New.
	(mark_overlay_section, unmark_overlay_section): New functions.
	(collect_lib_sectios, auto_ovl_lib_functions): New functions.
	(collect_overlays, find_pasted_call): New functions.
	(sum_stack): Deal with is_pasted "calls".  Exit before printing
	when --auto-overlay.
	(spu_elf_auto_overlay): New function.
	(spu_elf_final_link): Call spu_elf_auto_overlay.
	* elf32-spu.h (spu_elf_check_vma): Update prototype.
ld/
	* emultempl/spuelf.em (auto_overlay, auto_overlay_file,
	auto_overlay_fixed, auto_overlay_reserved, my_argc, my_argv): New vars.
	(spu_before_allocation): Warn on --auto-overlay and existing overlays.
	(struct tflist, clean_tmp): Move.
	(new_tmp_file): New function, extracted from..
	(embedded_spu_file): ..here.
	(spu_elf_open_overlay_script, spu_elf_relink): New function.
	(gld${EMULATION_NAME}_finish): Pass a bunch of --auto-overlay params.
	Warn on --auto-overlay and zero local store.
	(gld${EMULATION_NAME}_choose_target): New function to stash argv.
	(OPTION_SPU_AUTO_OVERLAY, OPTION_SPU_AUTO_RELINK,
	OPTION_SPU_OVERLAY_RODATA, OPTION_SPU_FIXED_SPACE,
	OPTION_SPU_RESERVED_SPACE, OPTION_SPU_NO_AUTO_OVERLAY): Define.
	(PARSE_AND_LIST_LONGOPTS): Add entries for new options.
	(PARSE_AND_LIST_OPTIONS): Likewise.
	(PARSE_AND_LIST_ARGS_CASES): Likewise.
	(LDEMUL_CHOOSE_TARGET): Define.
@
text
@d1424 1
a1424 1
			     h->root.u.def.section->owner);
d2070 1
a2070 1
  Elf_Internal_Shdr *symtab_hdr = &elf_tdata (sec->owner)->symtab_hdr;
d3159 1
a3159 1
   added first, the its parent node's section, then everything called
@


1.37
log
@	* elf32-spu.c (allocate_spuear_stubs): Ensure _SPUEAR_ symbol
	is defined in overlay section before creating a stub.
	(build_spuear_stubs): Likewise.
	(spu_elf_size_stubs, spu_elf_build_stubs): Adjust calls.
@
text
@d22 1
d282 23
d748 1
a748 1
	      && contents == insn)
d1517 1
a1517 1
   LO .. HI inclusive.  */
d1520 9
a1528 1
spu_elf_check_vma (struct bfd_link_info *info, bfd_vma lo, bfd_vma hi)
d1532 1
d1535 9
d1553 2
d1690 2
d1693 1
d1710 4
d1718 3
d1726 4
a1729 1
  /* Flags used during call tree traversal.  */
a1730 1
  unsigned int non_root : 1;
d1734 4
d1997 3
a1999 1
/* Add CALLEE to CALLER call list if not already present.  */
d2017 1
d2025 1
d2030 15
d2097 1
a2097 2
      unsigned char insn[4];
      bfd_boolean is_call;
d2101 1
d2105 5
a2109 1
	continue;
d2120 32
a2151 5
      if (!bfd_get_section_contents (sec->owner, sec, insn,
				     irela->r_offset, 4))
	return FALSE;
      if (!is_branch (insn))
	continue;
d2153 1
a2153 2
      if ((sym_sec->flags & (SEC_ALLOC | SEC_LOAD | SEC_CODE))
	  != (SEC_ALLOC | SEC_LOAD | SEC_CODE))
d2155 9
a2163 7
	  if (!call_tree)
	    warned = TRUE;
	  if (!call_tree || !warned)
	    info->callbacks->einfo (_("%B(%A+0x%v): call to non-code section"
				      " %B(%A), stack analysis incomplete\n"),
				    sec->owner, sec, irela->r_offset,
				    sym_sec->owner, sym_sec);
a2166 2
      is_call = (insn[0] & 0xfd) == 0x31;

d2210 7
d2287 15
a2301 2
	    fun->start = fun_start;
	  return TRUE;
d2641 1
a2641 1
/* Remove cycles from the call graph.  */
d2646 1
a2646 1
	       void *param ATTRIBUTE_UNUSED)
d2649 2
d2652 1
d2661 2
a2662 1
	  if (!remove_cycles (call->fun, info, 0))
d2664 2
d2669 4
a2672 2
	  const char *f1 = func_name (fun);
	  const char *f2 = func_name (call->fun);
d2674 4
a2677 3
	  info->callbacks->info (_("Stack analysis will ignore the call "
				   "from %s to %s\n"),
				 f1, f2);
d2685 1
d2695 1
d2712 2
a2713 1
  if (!for_each_node (transfer_calls, info, 0, FALSE))
d2722 520
a3241 1
  return for_each_node (remove_cycles, info, 0, TRUE);
d3261 1
d3263 1
d3270 1
d3274 2
d3282 1
a3282 1
      if (!call->is_tail)
d3301 4
d3311 1
a3311 1
  if (fun->call_list)
d3315 5
a3319 4
	{
	  const char *f2 = func_name (call->fun);
	  const char *ann1 = call->fun == max ? "*" : " ";
	  const char *ann2 = call->is_tail ? "t" : " ";
d3321 2
a3322 2
	  info->callbacks->minfo (_("   %s%s %s\n"), ann1, ann2, f2);
	}
a3326 1
      struct spu_link_hash_table *htab = spu_hash_table (info);
d3361 449
d3844 3
@


1.36
log
@	* elf32-spu.c (insert_callee): Reorder call list so most recent
	call is always first.
	(interesting_section): Move.
	(mark_functions_via_relocs): Fold interesting_section and
	reloc_count tests in callers to here.  Simplify output section
	owner test.
	(discover_functions): Set "gaps" when no symbols and some
	"interesting_section".  Run pasted_function loop for no symbol
	bfds.
	(for_each_node, transfer_calls): New functions.
	(mark_non_root): Adjust to suit for_each_node.
	(call_graph_traverse): Likewise.  Fix memory leak.  Rename to..
	(remove_cycles): ..this.
	(build_call_tree): Use for_each_node and transfer_calls.
	(struct _sum_stack_param): New.
	(sum_stack): Adjust to suit for_each_node.  Return error on
	malloc failure.  Move code to print root node cumulative stack from..
	(spu_elf_stack_analysis): ..here.  Use for_each_node.
@
text
@d1011 4
d1018 7
a1024 1
      && strncmp (h->root.root.string, "_SPUEAR_", 8) == 0)
a1025 2
      struct spu_link_hash_table *htab = inf;

d1037 4
d1044 7
a1050 1
      && strncmp (h->root.root.string, "_SPUEAR_", 8) == 0)
a1051 2
      struct spu_link_hash_table *htab = inf;

d1053 1
a1053 1
		  h->root.u.def.value, h->root.u.def.section);
d1213 1
a1213 1
  elf_link_hash_traverse (&htab->elf, allocate_spuear_stubs, htab);
d1411 1
a1411 1
  elf_link_hash_traverse (&htab->elf, build_spuear_stubs, htab);
@


1.35
log
@bfd/
	* elf32-spu.c (spu_elf_create_sections): Remove output_bfd parameter.
	(spu_elf_find_overlays, spu_elf_size_stubs): Likewise
	(process_stubs, discover_functions, build_call_tree): Likewise.
	(spu_elf_stack_analysis): Likewise.
	(spu_elf_check_vma): Likewise.  Move.
	(struct call_info): Make "is_tail" a bitfield.
	(insert_callee): Clear fun->start and set fun->is_func if we find
	a non-tail call.
	* elf32-spu.h (spu_elf_create_sections): Update prototype.
	(spu_elf_find_overlays, spu_elf_size_stubs, spu_elf_check_vma): Ditto.
ld/
	* emultempl/spuelf.em: Update calls to elf32-spu.c funcs.
@
text
@d1926 3
a1928 2
  struct call_info *p;
  for (p = caller->call_list; p != NULL; p = p->next)
d1939 4
d1950 13
d1980 4
d2018 1
a2018 1
	  || sym_sec->output_section->owner != sec->output_section->owner)
a2168 13
/* We're only interested in code sections.  Testing SEC_IN_MEMORY excludes
   overlay stub sections.  */

static bfd_boolean
interesting_section (asection *s, bfd *obfd)
{
  return (s->output_section != NULL
	  && s->output_section->owner == obfd
	  && ((s->flags & (SEC_ALLOC | SEC_LOAD | SEC_CODE | SEC_IN_MEMORY))
	      == (SEC_ALLOC | SEC_LOAD | SEC_CODE))
	  && s->size != 0);
}

d2210 10
a2219 1
	continue;
d2307 2
a2308 6
	    if (interesting_section (sec, info->output_bfd)
		&& sec->reloc_count != 0)
	      {
		if (!mark_functions_via_relocs (sec, info, FALSE))
		  return FALSE;
	      }
d2350 9
d2408 68
d2478 4
a2481 2
static void
mark_non_root (struct function_info *fun)
d2485 2
d2491 1
a2491 2
      if (!call->fun->visit1)
	mark_non_root (call->fun);
d2493 1
d2498 4
a2501 2
static void
call_graph_traverse (struct function_info *fun, struct bfd_link_info *info)
d2512 4
a2515 1
	call_graph_traverse (call->fun, info);
d2525 1
d2531 1
d2550 3
a2552 4
	{
	  if (!interesting_section (sec, info->output_bfd)
	      || sec->reloc_count == 0)
	    continue;
d2554 4
a2557 40
	  if (!mark_functions_via_relocs (sec, info, TRUE))
	    return FALSE;
	}

      /* Transfer call info from hot/cold section part of function
	 to main entry.  */
      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	{
	  struct _spu_elf_section_data *sec_data;
	  struct spu_elf_stack_info *sinfo;

	  if ((sec_data = spu_elf_section_data (sec)) != NULL
	      && (sinfo = sec_data->u.i.stack_info) != NULL)
	    {
	      int i;
	      for (i = 0; i < sinfo->num_fun; ++i)
		{
		  struct function_info *start = sinfo->fun[i].start;

		  if (start != NULL)
		    {
		      struct call_info *call;

		      while (start->start != NULL)
			start = start->start;
		      call = sinfo->fun[i].call_list;
		      while (call != NULL)
			{
			  struct call_info *call_next = call->next;
			  if (!insert_callee (start, call))
			    free (call);
			  call = call_next;
			}
		      sinfo->fun[i].call_list = NULL;
		      sinfo->fun[i].non_root = TRUE;
		    }
		}
	    }
	}
    }
d2560 2
a2561 23
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      asection *sec;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	{
	  struct _spu_elf_section_data *sec_data;
	  struct spu_elf_stack_info *sinfo;

	  if ((sec_data = spu_elf_section_data (sec)) != NULL
	      && (sinfo = sec_data->u.i.stack_info) != NULL)
	    {
	      int i;
	      for (i = 0; i < sinfo->num_fun; ++i)
		if (!sinfo->fun[i].visit1)
		  mark_non_root (&sinfo->fun[i]);
	    }
	}
    }
d2565 2
a2566 23
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      asection *sec;

      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	{
	  struct _spu_elf_section_data *sec_data;
	  struct spu_elf_stack_info *sinfo;

	  if ((sec_data = spu_elf_section_data (sec)) != NULL
	      && (sinfo = sec_data->u.i.stack_info) != NULL)
	    {
	      int i;
	      for (i = 0; i < sinfo->num_fun; ++i)
		if (!sinfo->fun[i].non_root)
		  call_graph_traverse (&sinfo->fun[i], info);
	    }
	}
    }
d2568 5
a2572 2
  return TRUE;
}
d2576 1
a2576 1
static bfd_vma
d2579 1
a2579 1
	   int emit_stack_syms)
d2582 2
a2583 3
  struct function_info *max = NULL;
  bfd_vma max_stack = fun->stack;
  bfd_vma stack;
d2585 1
d2587 2
d2590 1
a2590 1
    return max_stack;
d2592 1
d2595 3
a2597 1
      stack = sum_stack (call->fun, info, emit_stack_syms);
d2603 1
a2603 1
      if (max_stack < stack)
d2605 1
a2605 1
	  max_stack = stack;
d2610 10
d2621 2
d2624 1
a2624 1
			  f1, (bfd_vma) fun->stack, max_stack);
d2639 1
a2639 5
  /* Now fun->stack holds cumulative stack.  */
  fun->stack = max_stack;
  fun->visit3 = TRUE;

  if (emit_stack_syms)
d2645 7
a2651 6
      if (name != NULL)
	{
	  if (fun->global || ELF_ST_BIND (fun->u.sym->st_info) == STB_GLOBAL)
	    sprintf (name, "__stack_%s", f1);
	  else
	    sprintf (name, "__stack_%x_%s", fun->sec->id & 0xffffffff, f1);
d2653 17
a2669 18
	  h = elf_link_hash_lookup (&htab->elf, name, TRUE, TRUE, FALSE);
	  free (name);
	  if (h != NULL
	      && (h->root.type == bfd_link_hash_new
		  || h->root.type == bfd_link_hash_undefined
		  || h->root.type == bfd_link_hash_undefweak))
	    {
	      h->root.type = bfd_link_hash_defined;
	      h->root.u.def.section = bfd_abs_section_ptr;
	      h->root.u.def.value = max_stack;
	      h->size = 0;
	      h->type = 0;
	      h->ref_regular = 1;
	      h->def_regular = 1;
	      h->ref_regular_nonweak = 1;
	      h->forced_local = 1;
	      h->non_elf = 0;
	    }
d2673 1
a2673 1
  return max_stack;
d2681 1
a2681 2
  bfd *ibfd;
  bfd_vma max_stack = 0;
a2691 4
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->link_next)
    {
      extern const bfd_target bfd_elf32_spu_vec;
      asection *sec;
d2693 4
a2696 31
      if (ibfd->xvec != &bfd_elf32_spu_vec)
	continue;

      for (sec = ibfd->sections; sec != NULL; sec = sec->next)
	{
	  struct _spu_elf_section_data *sec_data;
	  struct spu_elf_stack_info *sinfo;

	  if ((sec_data = spu_elf_section_data (sec)) != NULL
	      && (sinfo = sec_data->u.i.stack_info) != NULL)
	    {
	      int i;
	      for (i = 0; i < sinfo->num_fun; ++i)
		{
		  if (!sinfo->fun[i].non_root)
		    {
		      bfd_vma stack;
		      const char *f1;

		      stack = sum_stack (&sinfo->fun[i], info,
					 emit_stack_syms);
		      f1 = func_name (&sinfo->fun[i]);
		      info->callbacks->info (_("  %s: 0x%v\n"),
					      f1, stack);
		      if (max_stack < stack)
			max_stack = stack;
		    }
		}
	    }
	}
    }
d2698 2
a2699 1
  info->callbacks->info (_("Maximum stack required is 0x%v\n"), max_stack);
@


1.34
log
@	* elf32-spu.c (process_stubs, spu_elf_relocate_section): Move
	common code to..
	(maybe_needs_stub): ..here, a new function that also omits stubs
	for .eh_frame, and..
	(needs_ovl_stub): ..here.  Create stubs for labels in code section
	referenced by switch jump table.
	(spu_elf_find_overlays): Set htab->ovly_load and htab->ovly_return.
	(enum _insn_type): Delete.
	(enum _stub_type): New.
	(count_stub, build_stub): Adjust.
	(allocate_spuear_stubs, build_spuear_stubs): Adjust.
@
text
@d422 1
a422 2
spu_elf_create_sections (bfd *output_bfd,
			 struct bfd_link_info *info,
d453 1
a453 1
      name_len = strlen (bfd_get_filename (output_bfd)) + 1;
d469 1
a469 1
	      bfd_get_filename (output_bfd), name_len);
d494 1
a494 1
spu_elf_find_overlays (bfd *output_bfd, struct bfd_link_info *info)
d502 1
a502 1
  if (output_bfd->section_count < 2)
d505 2
a506 1
  alloc_sec = bfd_malloc (output_bfd->section_count * sizeof (*alloc_sec));
d511 1
a511 1
  for (n = 0, s = output_bfd->sections; s != NULL; s = s->next)
d1046 1
a1046 3
process_stubs (bfd *output_bfd,
	       struct bfd_link_info *info,
	       bfd_boolean build)
d1082 1
a1082 1
	  if (!maybe_needs_stubs (isec, output_bfd))
d1181 1
a1181 2
spu_elf_size_stubs (bfd *output_bfd,
		    struct bfd_link_info *info,
d1194 1
a1194 1
  if (!process_stubs (output_bfd, info, FALSE))
d1392 2
a1393 3
  /* Write out all the stubs.  */
  obfd = htab->ovtab->output_section->owner;
  process_stubs (obfd, info, TRUE);
d1425 1
d1476 22
d1630 1
a1630 1
  int is_tail;
d1932 6
a1937 2
	if (p->is_tail > callee->is_tail)
	  p->is_tail = callee->is_tail;
d2163 1
a2163 1
discover_functions (bfd *output_bfd, struct bfd_link_info *info)
d2229 1
a2229 1
	    if (s != NULL && interesting_section (s, output_bfd))
d2271 1
a2271 1
	if (interesting_section (sec, output_bfd))
d2289 1
a2289 1
	    if (interesting_section (sec, output_bfd)
d2316 1
a2316 1
	    if (interesting_section (sec, output_bfd))
d2342 1
a2342 1
	    if (interesting_section (sec, output_bfd))
d2435 1
a2435 1
build_call_tree (bfd *output_bfd, struct bfd_link_info *info)
d2449 1
a2449 1
	  if (!interesting_section (sec, output_bfd)
d2640 1
a2640 3
spu_elf_stack_analysis (bfd *output_bfd,
			struct bfd_link_info *info,
			int emit_stack_syms)
d2645 1
a2645 1
  if (!discover_functions (output_bfd, info))
d2648 1
a2648 1
  if (!build_call_tree (output_bfd, info))
d2703 1
a2703 1
      && !spu_elf_stack_analysis (output_bfd, info, htab->emit_stack_syms))
a3076 21
/* Check that all loadable section VMAs lie in the range
   LO .. HI inclusive.  */

asection *
spu_elf_check_vma (bfd *abfd, bfd_vma lo, bfd_vma hi)
{
  struct elf_segment_map *m;
  unsigned int i;

  for (m = elf_tdata (abfd)->segment_map; m != NULL; m = m->next)
    if (m->p_type == PT_LOAD)
      for (i = 0; i < m->count; i++)
	if (m->sections[i]->size != 0
	    && (m->sections[i]->vma < lo
		|| m->sections[i]->vma > hi
		|| m->sections[i]->vma + m->sections[i]->size - 1 > hi))
	  return m->sections[i];

  return NULL;
}

@


1.33
log
@	* elf-bfd.h (_bfd_elf_section_from_bfd_section): Update prototype.
	* elf.c (_bfd_elf_section_from_bfd_section): Return unsigned int,
	SHN_BAD on error.
	(_bfd_elf_print_private_bfd_data): Test for SHN_BAD result from
	_bfd_elf_section_from_bfd_section, not -1.
	(swap_out_syms): Likewise.
	* elflink.c (elf_link_add_object_symbols): Likewise.
	(bfd_elf_get_bfd_needed_list): Likewise.
	(bfd_elf_match_symbols_in_sections): Likewise.
	(elf_link_add_object_symbols): Don't bother testing for symbols
	using normal sections before calling bfd_section_from_elf_index.
	(elf_link_input_bfd, bfd_elf_final_link): Likewise.
	(bfd_elf_reloc_symbol_deleted_p): Likewise.
	* elfcode.h (elf_slurp_symbol_table): Likewise.
	* elf32-spu.c (get_sym_h): Likewise.
	* elf32-xtensa.c (get_elf_r_symndx_section): Likewise.
	* elf64-ppc.c (opd_entry_value, get_sym_h, ppc64_elf_edit_toc): Ditto.
	* elf64-sh64.c (sh_elf64_get_relocated_section_contents): Likewise.
@
text
@d562 4
d624 1
a624 1
/* Return TRUE if this reloc symbol should possibly go via an overlay stub.  */
d627 32
a658 1
needs_ovl_stub (const char *sym_name,
d661 3
a663 2
		struct spu_link_hash_table *htab,
		bfd_boolean is_branch)
d665 5
a669 2
  if (htab->num_overlays == 0)
    return FALSE;
d673 1
d675 1
a675 1
    return FALSE;
d677 13
a689 6
  /* setjmp always goes via an overlay stub, because then the return
     and hence the longjmp goes via __ovly_return.  That magically
     makes setjmp/longjmp between overlays work.  */
  if (strncmp (sym_name, "setjmp", 6) == 0
      && (sym_name[6] == '\0' || sym_name[6] == '@@'))
    return TRUE;
d694 63
a756 1
    return FALSE;
d762 1
a762 1
    return TRUE;
d766 1
a766 1
  return !is_branch;
a768 2
enum _insn_type { non_branch, branch, call };

d773 1
a773 1
	    enum _insn_type insn_type,
d786 1
a786 1
  if (insn_type != non_branch)
d873 1
a873 1
	    enum _insn_type insn_type,
d885 1
a885 1
  if (insn_type != non_branch)
d1018 1
a1018 1
      count_stub (htab, NULL, NULL, non_branch, h, NULL);
d1036 1
a1036 1
      build_stub (htab, NULL, NULL, non_branch, h, NULL,
a1080 2
	      || (isec->flags & SEC_ALLOC) == 0
	      || (isec->flags & SEC_LOAD) == 0
d1084 1
a1084 4
	  /* If this section is a link-once section that will be
	     discarded, then don't create any stubs.  */
	  if (isec->output_section == NULL
	      || isec->output_section->owner != output_bfd)
d1103 1
a1103 3
	      const char *sym_name;
	      unsigned int sym_type;
	      enum _insn_type insn_type;
d1126 3
a1128 62
	      if (sym_sec == NULL
		  || sym_sec->output_section == NULL
		  || sym_sec->output_section->owner != output_bfd)
		continue;

	      /* Ensure no stubs for user supplied overlay manager syms.  */
	      if (h != NULL
		  && (strcmp (h->root.root.string, "__ovly_load") == 0
		      || strcmp (h->root.root.string, "__ovly_return") == 0))
		continue;

	      insn_type = non_branch;
	      if (r_type == R_SPU_REL16
		  || r_type == R_SPU_ADDR16)
		{
		  unsigned char insn[4];

		  if (!bfd_get_section_contents (ibfd, isec, insn,
						 irela->r_offset, 4))
		    goto error_ret_free_internal;

		  if (is_branch (insn) || is_hint (insn))
		    {
		      insn_type = branch;
		      if ((insn[0] & 0xfd) == 0x31)
			insn_type = call;
		    }
		}

	      /* We are only interested in function symbols.  */
	      if (h != NULL)
		{
		  sym_type = h->type;
		  sym_name = h->root.root.string;
		}
	      else
		{
		  sym_type = ELF_ST_TYPE (sym->st_info);
		  sym_name = bfd_elf_sym_name (sym_sec->owner,
					       symtab_hdr,
					       sym,
					       sym_sec);
		}

	      if (sym_type != STT_FUNC)
		{
		  /* It's common for people to write assembly and forget
		     to give function symbols the right type.  Handle
		     calls to such symbols, but warn so that (hopefully)
		     people will fix their code.  We need the symbol
		     type to be correct to distinguish function pointer
		     initialisation from other pointer initialisation.  */
		  if (insn_type == call)
		    (*_bfd_error_handler) (_("warning: call to non-function"
					     " symbol %s defined in %B"),
					   sym_sec->owner, sym_name);
		  else if (insn_type == non_branch)
		    continue;
		}

	      if (!needs_ovl_stub (sym_name, sym_sec, isec, htab,
				   insn_type != non_branch))
d1130 2
d1144 1
a1144 1
		  if (!count_stub (htab, ibfd, isec, insn_type, h, irela))
d1156 1
a1156 1
		  if (!build_stub (htab, ibfd, isec, insn_type, h, irela,
d2726 1
d2729 2
d2810 3
a2812 20
      if (htab->stub_sec != NULL
	  && sec != NULL
	  && sec->output_section != NULL
	  && sec->output_section->owner == output_bfd
	  && (h == NULL
	      || (h != htab->ovly_load && h != htab->ovly_return)))
	{
	  bfd_boolean branch;
	  unsigned int sym_type;

	  branch = FALSE;
	  if (r_type == R_SPU_REL16
	      || r_type == R_SPU_ADDR16)
	    branch = (is_branch (contents + rel->r_offset)
		      || is_hint (contents + rel->r_offset));

	  if (h != NULL)
	    sym_type = h->type;
	  else
	    sym_type = ELF_ST_TYPE (sym->st_info);
d2814 3
a2816 2
	  if ((sym_type == STT_FUNC || branch)
	      && needs_ovl_stub (sym_name, sec, input_section, htab, branch))
d2821 1
a2821 1
	      if (branch)
@


1.32
log
@	* elf32-spu.c (spu_elf_relocate_section): Test identical conditions
	to those in process_stubs for overlay symbols.
@
text
@d412 1
a412 8
	{
	  asection *symsec = NULL;
	  if ((sym->st_shndx != SHN_UNDEF
	       && sym->st_shndx < SHN_LORESERVE)
	      || sym->st_shndx > SHN_HIRESERVE)
	    symsec = bfd_section_from_elf_index (ibfd, sym->st_shndx);
	  *symsecp = symsec;
	}
@


1.31
log
@	* elf32-spu.c (struct got_entry): Add "addend" field.
	(count_stub, build_stub): Use a new stub if relocation addend
	differs from existing stubs for this symbol.
	(process_stubs): Deal with addends.
	(spu_elf_relocate_section, spu_elf_output_symbol_hook): Likewise.
@
text
@a2710 1
      bfd_boolean branch;
a2770 2
      branch = (is_branch (contents + rel->r_offset)
		|| is_hint (contents + rel->r_offset));
d2772 3
a2774 1
	  && needs_ovl_stub (sym_name, sec, input_section, htab, branch)
d2778 2
a2779 2
	  unsigned int ovl = 0;
	  struct got_entry *g, **head;
d2781 5
a2785 3
	  if (branch)
	    ovl = (spu_elf_section_data (input_section->output_section)
		   ->u.o.ovl_index);
d2788 1
a2788 1
	    head = &h->got.glist;
d2790 1
a2790 1
	    head = elf_local_got_ents (input_bfd) + r_symndx;
d2792 20
a2811 5
	  for (g = *head; g != NULL; g = g->next)
	    if (g->addend == addend && (g->ovl == ovl || g->ovl == 0))
	      break;
	  if (g == NULL)
	    abort ();
d2813 3
a2815 2
	  relocation = g->stub_addr;
	  addend = 0;
@


1.30
log
@	* elf32-spu.c (mark_functions_via_relocs): Don't assume that
	the "->start" pointer reaches to function origin, so that we
	can handle functions split over more than two sections.
	(build_call_tree): Likewise.
	(pasted_function): Don't attempt to set fun->start back to the
	function origin, just go back one section.
@
text
@d304 1
d679 1
d704 3
a706 5
  /* If we have a stub in the non-overlay area then there's no need
     for one in overlays.  */
  g = *head;
  if (g != NULL && g->ovl == 0)
    return TRUE;
d712 5
a716 2
      /* Need a new non-overlay area stub.  Zap other stubs.  */
      for (; g != NULL; g = gnext)
d718 10
a727 3
	  htab->stub_count[g->ovl] -= 1;
	  gnext = g->next;
	  free (g);
d732 2
a733 2
      for (; g != NULL; g = g->next)
	if (g->ovl == ovl)
d743 1
d782 1
a782 1
  bfd_vma val, from, to;
d793 3
a795 3
  g = *head;
  if (g != NULL && g->ovl == 0 && ovl != 0)
    return TRUE;
d797 2
a798 2
  for (; g != NULL; g = g->next)
    if (g->ovl == ovl)
d803 3
d1119 1
d2792 1
a2792 1
	    if (g->ovl == ovl || g->ovl == 0)
d2901 1
a2901 1
      struct got_entry *g = h->got.glist;
d2903 9
a2911 7
      if (g != NULL && g->ovl == 0)
	{
	  sym->st_shndx = (_bfd_elf_section_from_bfd_section
			   (htab->stub_sec[0]->output_section->owner,
			    htab->stub_sec[0]->output_section));
	  sym->st_value = g->stub_addr;
	}
@


1.29
log
@bfd/
	* elf32-spu.c (spu_elf_size_stubs): Revert 2008-01-28 doubling
	of _ovly_buf_table size.
	(spu_elf_build_stubs): Use low bit of .size as "present" bit.
	Adjust initialisations relating to _ovly_buf_table.
ld/
	* emultempl/spu_ovl.S: Use low bit of _ovly_table.size as
	a "present" bit rather than low bit of .buf.  Correct indexing
	into _ovly_buf_table.  Use relative loads and stores to access
	overlay manager local vars.
	* emultempl/spu_ovl.o: Regenerate.
@
text
@d2000 1
a2000 2
	  if (callee->fun->start != NULL
	      || sec->owner != sym_sec->owner)
d2005 2
d2008 15
a2022 1
	    callee->fun->start = caller;
d2059 1
a2059 5
	    {
	      if (fun_start->start)
		fun_start = fun_start->start;
	      fun->start = fun_start;
	    }
d2396 3
a2398 1
		  if (sinfo->fun[i].start != NULL)
d2400 1
a2400 1
		      struct call_info *call = sinfo->fun[i].call_list;
d2402 3
d2408 1
a2408 1
			  if (!insert_callee (sinfo->fun[i].start, call))
@


1.28
log
@	* elf32-spu.c (spu_elf_relocate_section): Correct return type.
	Return error status on unexpected relocation errors.
@
text
@d1205 1
a1205 1
  htab->ovtab->size = htab->num_overlays * 16 + 16 + htab->num_buf * 2 * 4;
d1376 2
a1377 2
  /* set low bit of .buf to mark non-overlay area as present.  */
  p[15] = 1;
d1390 1
a1390 1
	  bfd_put_32 (htab->ovtab->owner, ovl_buf * 2, p + off + 12);
d1410 1
a1410 1
  h->size = htab->num_buf * 2 * 4;
d1415 1
a1415 1
  h->root.u.def.value = htab->num_overlays * 16 + 16 + htab->num_buf * 2 * 4;
@


1.27
log
@	Rewrite SPU overlay handling code.  Put overlay calls stubs in the
	overlays where possible.  Use a faster call stub, or optionally at
	compile time, a more compact stub.  Double size of _ovly_buf_table
	so that low bit of _ovly_table.buf can be used as a "present" bit.
	Reserve an extra _ovly_table entry for index zero.
@
text
@d3 1
a3 1
   Copyright 2006, 2007 Free Software Foundation, Inc.
d2643 1
a2643 1
static bfd_boolean
d2657 1
a2657 1
  bfd_boolean ret = TRUE;
d2813 1
@


1.26
log
@	* elf32-spu.c (spu_elf_size_stubs): Do consider branches to
	non-function symbols for overlay stubs.
@
text
@d260 4
a263 2
  /* The stub hash table.  */
  struct bfd_hash_table stub_hash_table;
d265 2
a266 6
  /* Sorted array of stubs.  */
  struct {
    struct spu_stub_hash_entry **sh;
    unsigned int count;
    int err;
  } stubs;
d268 2
a269 3
  /* Shortcuts to overlay sections.  */
  asection *stub;
  asection *ovtab;
d272 1
a274 8
  /* An array of two output sections per overlay region, chosen such that
     the first section vma is the overlay buffer vma (ie. the section has
     the lowest vma in the group that occupy the region), and the second
     section vma+size specifies the end of the region.  We keep pointers
     to sections like this because section vmas may change when laying
     them out.  */
  asection **ovl_region;

d289 1
a289 1
  unsigned int stub_overflow : 1;
d298 1
a298 2
#define spu_hash_table(p) \
  ((struct spu_link_hash_table *) ((p)->hash))
d300 1
a300 1
struct spu_stub_hash_entry
d302 3
a304 11
  struct bfd_hash_entry root;

  /* Destination of this stub.  */
  asection *target_section;
  bfd_vma target_off;

  /* Offset of entry in stub section.  */
  bfd_vma off;

  /* Offset from this stub to stub that loads the overlay index.  */
  bfd_vma delta;
d307 2
a308 30
/* Create an entry in a spu stub hash table.  */

static struct bfd_hash_entry *
stub_hash_newfunc (struct bfd_hash_entry *entry,
		   struct bfd_hash_table *table,
		   const char *string)
{
  /* Allocate the structure if it has not already been allocated by a
     subclass.  */
  if (entry == NULL)
    {
      entry = bfd_hash_allocate (table, sizeof (struct spu_stub_hash_entry));
      if (entry == NULL)
	return entry;
    }

  /* Call the allocation method of the superclass.  */
  entry = bfd_hash_newfunc (entry, table, string);
  if (entry != NULL)
    {
      struct spu_stub_hash_entry *sh = (struct spu_stub_hash_entry *) entry;

      sh->target_section = NULL;
      sh->target_off = 0;
      sh->off = 0;
      sh->delta = 0;
    }

  return entry;
}
d329 2
a330 7
  /* Init the stub hash table too.  */
  if (!bfd_hash_table_init (&htab->stub_hash_table, stub_hash_newfunc,
			    sizeof (struct spu_stub_hash_entry)))
    return NULL;

  memset (&htab->stubs, 0,
	  sizeof (*htab) - offsetof (struct spu_link_hash_table, stubs));
d332 4
a338 11
/* Free the derived linker hash table.  */

static void
spu_elf_link_hash_table_free (struct bfd_link_hash_table *hash)
{
  struct spu_link_hash_table *ret = (struct spu_link_hash_table *) hash;

  bfd_hash_table_free (&ret->stub_hash_table);
  _bfd_generic_link_hash_table_free (hash);
}

a423 45
/* Build a name for an entry in the stub hash table.  We can't use a
   local symbol name because ld -r might generate duplicate local symbols.  */

static char *
spu_stub_name (const asection *sym_sec,
	       const struct elf_link_hash_entry *h,
	       const Elf_Internal_Rela *rel)
{
  char *stub_name;
  bfd_size_type len;

  if (h)
    {
      len = strlen (h->root.root.string) + 1 + 8 + 1;
      stub_name = bfd_malloc (len);
      if (stub_name == NULL)
	return stub_name;

      sprintf (stub_name, "%s+%x",
	       h->root.root.string,
	       (int) rel->r_addend & 0xffffffff);
      len -= 8;
    }
  else
    {
      len = 8 + 1 + 8 + 1 + 8 + 1;
      stub_name = bfd_malloc (len);
      if (stub_name == NULL)
	return stub_name;

      sprintf (stub_name, "%x:%x+%x",
	       sym_sec->id & 0xffffffff,
	       (int) ELF32_R_SYM (rel->r_info) & 0xffffffff,
	       (int) rel->r_addend & 0xffffffff);
      len = strlen (stub_name);
    }

  if (stub_name[len - 2] == '+'
      && stub_name[len - 1] == '0'
      && stub_name[len] == 0)
    stub_name[len - 2] = 0;

  return stub_name;
}

d533 1
a533 3
     Count them.  Also count the number of overlay regions and for
     each region save a section from that region with the lowest vma
     and another section with the highest end vma.  */
d542 1
a542 1
	  if (spu_elf_section_data (s0)->ovl_index == 0)
d544 3
a546 4
	      spu_elf_section_data (s0)->ovl_index = ++ovl_index;
	      alloc_sec[num_buf * 2] = s0;
	      alloc_sec[num_buf * 2 + 1] = s0;
	      num_buf++;
d548 4
a551 2
	  spu_elf_section_data (s)->ovl_index = ++ovl_index;
	  if (ovl_end < s->vma + s->size)
d553 4
a556 2
	      ovl_end = s->vma + s->size;
	      alloc_sec[num_buf * 2 - 1] = s;
d558 2
d567 2
a568 12
  if (ovl_index == 0)
    {
      free (alloc_sec);
      return FALSE;
    }

  alloc_sec = bfd_realloc (alloc_sec, num_buf * 2 * sizeof (*alloc_sec));
  if (alloc_sec == NULL)
    return FALSE;

  htab->ovl_region = alloc_sec;
  return TRUE;
d571 9
a579 9
/* One of these per stub.  */
#define SIZEOF_STUB1 8
#define ILA_79	0x4200004f		/* ila $79,function_address */
#define BR	0x32000000		/* br stub2 */

/* One of these per overlay.  */
#define SIZEOF_STUB2 8
#define ILA_78	0x4200004e		/* ila $78,overlay_number */
					/* br __ovly_load */
d581 2
d651 1
a651 1
  if (spu_elf_section_data (sym_sec->output_section)->ovl_index == 0
d657 2
a658 2
  if (spu_elf_section_data (sym_sec->output_section)->ovl_index
       != spu_elf_section_data (input_section->output_section)->ovl_index)
d666 223
a902 9
      static Elf_Internal_Rela zero_rel;
      char *stub_name = spu_stub_name (h->root.u.def.section, h, &zero_rel);
      struct spu_stub_hash_entry *sh;

      if (stub_name == NULL)
	{
	  htab->stubs.err = 1;
	  return FALSE;
	}
d904 1
a904 18
      sh = (struct spu_stub_hash_entry *)
	bfd_hash_lookup (&htab->stub_hash_table, stub_name, TRUE, FALSE);
      if (sh == NULL)
	{
	  free (stub_name);
	  return FALSE;
	}

      /* If this entry isn't new, we already have a stub.  */
      if (sh->target_section != NULL)
	{
	  free (stub_name);
	  return TRUE;
	}

      sh->target_section = h->root.u.def.section;
      sh->target_off = h->root.u.def.value;
      htab->stubs.count += 1;
a909 3
/* Called via bfd_hash_traverse to set up pointers to all symbols
   in the stub hash table.  */

d911 1
a911 1
populate_stubs (struct bfd_hash_entry *bh, void *inf)
d913 8
a920 1
  struct spu_link_hash_table *htab = inf;
d922 4
a925 1
  htab->stubs.sh[--htab->stubs.count] = (struct spu_stub_hash_entry *) bh;
d929 1
a929 1
/* qsort predicate to sort stubs by overlay number.  */
d931 4
a934 38
static int
sort_stubs (const void *a, const void *b)
{
  const struct spu_stub_hash_entry *const *sa = a;
  const struct spu_stub_hash_entry *const *sb = b;
  int i;
  bfd_signed_vma d;

  i = spu_elf_section_data ((*sa)->target_section->output_section)->ovl_index;
  i -= spu_elf_section_data ((*sb)->target_section->output_section)->ovl_index;
  if (i != 0)
    return i;

  d = ((*sa)->target_section->output_section->vma
       + (*sa)->target_section->output_offset
       + (*sa)->target_off
       - (*sb)->target_section->output_section->vma
       - (*sb)->target_section->output_offset
       - (*sb)->target_off);
  if (d != 0)
    return d < 0 ? -1 : 1;

  /* Two functions at the same address.  Aliases perhaps.  */
  i = strcmp ((*sb)->root.string, (*sa)->root.string);
  BFD_ASSERT (i != 0);
  return i;
}

/* Allocate space for overlay call and return stubs.  */

bfd_boolean
spu_elf_size_stubs (bfd *output_bfd,
		    struct bfd_link_info *info,
		    int non_overlay_stubs,
		    int stack_analysis,
		    asection **stub,
		    asection **ovtab,
		    asection **toe)
a937 2
  unsigned i, group;
  flagword flags;
a938 1
  htab->non_overlay_stubs = non_overlay_stubs;
d943 1
a943 1
      asection *section;
d957 1
a957 1
      if (stack_analysis)
d961 1
a961 1
      for (section = ibfd->sections; section != NULL; section = section->next)
d966 4
a969 4
	  if ((section->flags & SEC_RELOC) == 0
	      || (section->flags & SEC_ALLOC) == 0
	      || (section->flags & SEC_LOAD) == 0
	      || section->reloc_count == 0)
d974 2
a975 2
	  if (section->output_section == NULL
	      || section->output_section->owner != output_bfd)
d979 2
a980 3
	  internal_relocs
	    = _bfd_elf_link_read_relocs (ibfd, section, NULL, NULL,
					 info->keep_memory);
d986 1
a986 1
	  irelaend = irela + section->reloc_count;
a994 2
	      char *stub_name;
	      struct spu_stub_hash_entry *sh;
d996 1
a996 1
	      enum _insn_type { non_branch, branch, call } insn_type;
d1004 9
a1012 1
		  goto error_ret_free_internal;
d1036 1
a1036 1
		  if (!bfd_get_section_contents (ibfd, section, insn,
d1079 1
a1079 1
	      if (!needs_ovl_stub (sym_name, sym_sec, section, htab,
d1083 1
a1083 8
	      stub_name = spu_stub_name (sym_sec, h, irela);
	      if (stub_name == NULL)
		goto error_ret_free_internal;

	      sh = (struct spu_stub_hash_entry *)
		bfd_hash_lookup (&htab->stub_hash_table, stub_name,
				 TRUE, FALSE);
	      if (sh == NULL)
d1085 5
a1089 10
		  free (stub_name);
		error_ret_free_internal:
		  if (elf_section_data (section)->relocs != internal_relocs)
		    free (internal_relocs);
		error_ret_free_local:
		  if (local_syms != NULL
		      && (symtab_hdr->contents
			  != (unsigned char *) local_syms))
		    free (local_syms);
		  return FALSE;
d1092 1
a1092 2
	      /* If this entry isn't new, we already have a stub.  */
	      if (sh->target_section != NULL)
d1094 2
a1095 2
		  free (stub_name);
		  continue;
a1096 4

	      sh->target_section = sym_sec;
	      if (h != NULL)
		sh->target_off = h->root.u.def.value;
d1098 2
a1099 2
		sh->target_off = sym->st_value;
	      sh->target_off += irela->r_addend;
d1101 8
a1108 1
	      htab->stubs.count += 1;
d1112 1
a1112 1
	  if (elf_section_data (section)->relocs != internal_relocs)
d1126 23
d1150 2
a1151 2
  if (htab->stubs.err)
    return FALSE;
d1153 2
a1154 3
  *stub = NULL;
  if (htab->stubs.count == 0)
    return TRUE;
d1157 5
d1164 7
a1170 5
  htab->stub = bfd_make_section_anyway_with_flags (ibfd, ".stub", flags);
  *stub = htab->stub;
  if (htab->stub == NULL
      || !bfd_set_section_alignment (ibfd, htab->stub, 4))
    return FALSE;
d1172 11
a1182 68
  flags = (SEC_ALLOC | SEC_LOAD
	   | SEC_HAS_CONTENTS | SEC_IN_MEMORY);
  htab->ovtab = bfd_make_section_anyway_with_flags (ibfd, ".ovtab", flags);
  *ovtab = htab->ovtab;
  if (htab->ovtab == NULL
      || !bfd_set_section_alignment (ibfd, htab->ovtab, 4))
    return FALSE;

  *toe = bfd_make_section_anyway_with_flags (ibfd, ".toe", SEC_ALLOC);
  if (*toe == NULL
      || !bfd_set_section_alignment (ibfd, *toe, 4))
    return FALSE;
  (*toe)->size = 16;

  /* Retrieve all the stubs and sort.  */
  htab->stubs.sh = bfd_malloc (htab->stubs.count * sizeof (*htab->stubs.sh));
  if (htab->stubs.sh == NULL)
    return FALSE;
  i = htab->stubs.count;
  bfd_hash_traverse (&htab->stub_hash_table, populate_stubs, htab);
  BFD_ASSERT (htab->stubs.count == 0);

  htab->stubs.count = i;
  qsort (htab->stubs.sh, htab->stubs.count, sizeof (*htab->stubs.sh),
	 sort_stubs);

  /* Now that the stubs are sorted, place them in the stub section.
     Stubs are grouped per overlay
     .	    ila $79,func1
     .	    br 1f
     .	    ila $79,func2
     .	    br 1f
     .
     .
     .	    ila $79,funcn
     .	    nop
     .	1:
     .	    ila $78,ovl_index
     .	    br __ovly_load  */

  group = 0;
  for (i = 0; i < htab->stubs.count; i++)
    {
      if (spu_elf_section_data (htab->stubs.sh[group]->target_section
				->output_section)->ovl_index
	  != spu_elf_section_data (htab->stubs.sh[i]->target_section
				   ->output_section)->ovl_index)
	{
	  htab->stub->size += SIZEOF_STUB2;
	  for (; group != i; group++)
	    htab->stubs.sh[group]->delta
	      = htab->stubs.sh[i - 1]->off - htab->stubs.sh[group]->off;
	}
      if (group == i
	  || ((htab->stubs.sh[i - 1]->target_section->output_section->vma
	       + htab->stubs.sh[i - 1]->target_section->output_offset
	       + htab->stubs.sh[i - 1]->target_off)
	      != (htab->stubs.sh[i]->target_section->output_section->vma
		  + htab->stubs.sh[i]->target_section->output_offset
		  + htab->stubs.sh[i]->target_off)))
	{
	  htab->stubs.sh[i]->off = htab->stub->size;
	  htab->stub->size += SIZEOF_STUB1;
	  if (info->emitrelocations)
	    htab->stub->reloc_count += 1;
	}
      else
	htab->stubs.sh[i]->off = htab->stubs.sh[i - 1]->off;
a1183 7
  if (group != i)
    htab->stub->size += SIZEOF_STUB2;
  if (info->emitrelocations)
    htab->stub->flags |= SEC_RELOC;
  for (; group != i; group++)
    htab->stubs.sh[group]->delta
      = htab->stubs.sh[i - 1]->off - htab->stubs.sh[group]->off;
d1195 2
a1196 1
    .	} _ovly_buf_table[];  */
d1198 6
a1203 2
  htab->ovtab->alignment_power = 4;
  htab->ovtab->size = htab->num_overlays * 16 + htab->num_buf * 4;
d1205 11
a1215 1
  return TRUE;
a1263 143
/* Fill in the ila and br for a stub.  On the last stub for a group,
   write the stub that sets the overlay number too.  */

static bfd_boolean
write_one_stub (struct spu_stub_hash_entry *ent, struct bfd_link_info *info)
{
  struct spu_link_hash_table *htab = spu_hash_table (info);
  asection *sec = htab->stub;
  asection *s = ent->target_section;
  unsigned int ovl;
  bfd_vma val;

  val = ent->target_off + s->output_offset + s->output_section->vma;
  bfd_put_32 (sec->owner, ILA_79 + ((val << 7) & 0x01ffff80),
	      sec->contents + ent->off);
  val = ent->delta + 4;
  bfd_put_32 (sec->owner, BR + ((val << 5) & 0x007fff80),
	      sec->contents + ent->off + 4);

  if (info->emitrelocations)
    {
      Elf_Internal_Rela *relocs, *r;
      struct bfd_elf_section_data *elfsec_data;

      elfsec_data = elf_section_data (sec);
      relocs = elfsec_data->relocs;
      if (relocs == NULL)
	{
	  bfd_size_type relsize;
	  Elf_Internal_Shdr *symtab_hdr;
	  struct elf_link_hash_entry **sym_hash;
	  unsigned long symcount;
	  bfd_vma amt;

	  relsize = sec->reloc_count * sizeof (*relocs);
	  relocs = bfd_alloc (sec->owner, relsize);
	  if (relocs == NULL)
	    return FALSE;
	  elfsec_data->relocs = relocs;
	  elfsec_data->rel_hdr.sh_size
	    = sec->reloc_count * sizeof (Elf32_External_Rela);
	  elfsec_data->rel_hdr.sh_entsize = sizeof (Elf32_External_Rela);
	  sec->reloc_count = 0;

	  /* Increase the size of symbol hash array on the bfd to
	     which we attached our .stub section.  This hack allows
	     us to create relocs against global symbols.  */
	  symtab_hdr = &elf_tdata (sec->owner)->symtab_hdr;
	  symcount = symtab_hdr->sh_size / symtab_hdr->sh_entsize;
	  symcount -= symtab_hdr->sh_info;
	  amt = symcount * sizeof (*sym_hash);
	  sym_hash = bfd_alloc (sec->owner, amt + sizeof (*sym_hash));
	  if (sym_hash == NULL)
	    return FALSE;
	  memcpy (sym_hash, elf_sym_hashes (sec->owner), amt);
	  sym_hash[symcount] = htab->ovly_load;
	  htab->ovly_load_r_symndx = symcount + symtab_hdr->sh_info;
	  elf_sym_hashes (sec->owner) = sym_hash;
	}
      r = relocs + sec->reloc_count;
      sec->reloc_count += 1;
      r->r_offset = ent->off + 4;
      r->r_info = ELF32_R_INFO (0, R_SPU_REL16);
      r->r_addend = (sec->output_section->vma
		     + sec->output_offset
		     + ent->off + 4
		     + val);
    }

  /* If this is the last stub of this group, write stub2.  */
  if (ent->delta == 0)
    {
      bfd_put_32 (sec->owner, NOP,
		  sec->contents + ent->off + 4);

      ovl = spu_elf_section_data (s->output_section)->ovl_index;
      bfd_put_32 (sec->owner, ILA_78 + ((ovl << 7) & 0x01ffff80),
		  sec->contents + ent->off + 8);

      val = (htab->ovly_load->root.u.def.section->output_section->vma
	     + htab->ovly_load->root.u.def.section->output_offset
	     + htab->ovly_load->root.u.def.value
	     - (sec->output_section->vma
		+ sec->output_offset
		+ ent->off + 12));

      if (val + 0x20000 >= 0x40000)
	htab->stub_overflow = TRUE;

      bfd_put_32 (sec->owner, BR + ((val << 5) & 0x007fff80),
		  sec->contents + ent->off + 12);

      if (info->emitrelocations)
	{
	  Elf_Internal_Rela *relocs, *r;
	  struct bfd_elf_section_data *elfsec_data;

	  elfsec_data = elf_section_data (sec);
	  relocs = elfsec_data->relocs;
	  /* The last branch is overwritten, so overwrite its reloc too.  */
	  r = relocs + sec->reloc_count - 1;
	  r->r_offset = ent->off + 12;
	  r->r_info = ELF32_R_INFO (htab->ovly_load_r_symndx, R_SPU_REL16);
	  r->r_addend = 0;
	}
    }

  if (htab->emit_stub_syms)
    {
      struct elf_link_hash_entry *h;
      size_t len1, len2;
      char *name;

      len1 = sizeof ("00000000.ovl_call.") - 1;
      len2 = strlen (ent->root.string);
      name = bfd_malloc (len1 + len2 + 1);
      if (name == NULL)
	return FALSE;
      memcpy (name, "00000000.ovl_call.", len1);
      memcpy (name + len1, ent->root.string, len2 + 1);
      h = elf_link_hash_lookup (&htab->elf, name, TRUE, TRUE, FALSE);
      free (name);
      if (h == NULL)
	return FALSE;
      if (h->root.type == bfd_link_hash_new)
	{
	  h->root.type = bfd_link_hash_defined;
	  h->root.u.def.section = sec;
	  h->root.u.def.value = ent->off;
	  h->size = (ent->delta == 0
		     ? SIZEOF_STUB1 + SIZEOF_STUB2 : SIZEOF_STUB1);
	  h->type = STT_FUNC;
	  h->ref_regular = 1;
	  h->def_regular = 1;
	  h->ref_regular_nonweak = 1;
	  h->forced_local = 1;
	  h->non_elf = 0;
	}
    }

  return TRUE;
}

d1301 1
a1301 1
spu_elf_build_stubs (struct bfd_link_info *info, int emit_syms, asection *toe)
d1311 13
a1323 3
  htab->stub->contents = bfd_zalloc (htab->stub->owner, htab->stub->size);
  if (htab->stub->contents == NULL)
    return FALSE;
d1333 1
a1333 1
  if (spu_elf_section_data (s)->ovl_index)
d1341 3
d1345 6
a1350 2
  for (i = 0; i < htab->stubs.count; i++)
    write_one_stub (htab->stubs.sh[i], info);
d1352 12
a1363 1
  if (htab->stub_overflow)
d1376 2
a1377 1
  obfd = htab->ovtab->output_section->owner;
d1380 1
a1380 1
      unsigned int ovl_index = spu_elf_section_data (s)->ovl_index;
d1384 3
a1386 2
	  unsigned int lo, hi, mid;
	  unsigned long off = (ovl_index - 1) * 16;
d1390 1
a1390 18

	  lo = 0;
	  hi = htab->num_buf;
	  while (lo < hi)
	    {
	      mid = (lo + hi) >> 1;
	      if (htab->ovl_region[2 * mid + 1]->vma
		  + htab->ovl_region[2 * mid + 1]->size <= s->vma)
		lo = mid + 1;
	      else if (htab->ovl_region[2 * mid]->vma > s->vma)
		hi = mid;
	      else
		{
		  bfd_put_32 (htab->ovtab->owner, mid + 1, p + off + 12);
		  break;
		}
	    }
	  BFD_ASSERT (lo < hi);
a1393 8
  /* Write out _ovly_buf_table.  */
  p = htab->ovtab->contents + htab->num_overlays * 16;
  for (i = 0; i < htab->num_buf; i++)
    {
      bfd_put_32 (htab->ovtab->owner, 0, p);
      p += 4;
    }

d1397 1
a1397 1
  h->root.u.def.value = 0;
d1403 1
a1403 1
  h->root.u.def.value = htab->num_overlays * 16;
d1409 2
a1410 2
  h->root.u.def.value = htab->num_overlays * 16;
  h->size = htab->num_buf * 4;
d1415 1
a1415 1
  h->root.u.def.value = htab->num_overlays * 16 + htab->num_buf * 4;
d1421 1
a1421 1
  h->root.u.def.section = toe;
d1614 4
a1617 4
  sec_data->stack_info = bfd_zmalloc (amt);
  if (sec_data->stack_info != NULL)
    sec_data->stack_info->max_fun = max_fun;
  return sec_data->stack_info;
d1630 1
a1630 1
  struct spu_elf_stack_info *sinfo = sec_data->stack_info;
d1694 1
a1694 1
      sec_data->stack_info = sinfo;
d1785 1
a1785 1
  struct spu_elf_stack_info *sinfo = sec_data->stack_info;
d1831 1
a1831 1
  struct spu_elf_stack_info *sinfo = sec_data->stack_info;
d2053 1
a2053 1
	  && (sinfo = sec_data->stack_info) != NULL
d2062 2
a2063 1
/* We're only interested in code sections.  */
d2066 1
a2066 1
interesting_section (asection *s, bfd *obfd, struct spu_link_hash_table *htab)
d2068 1
a2068 2
  return (s != htab->stub
	  && s->output_section != NULL
d2070 1
a2070 1
	  && ((s->flags & (SEC_ALLOC | SEC_LOAD | SEC_CODE))
a2079 1
  struct spu_link_hash_table *htab = spu_hash_table (info);
d2144 1
a2144 1
	    if (s != NULL && interesting_section (s, output_bfd, htab))
d2186 1
a2186 1
	if (interesting_section (sec, output_bfd, htab))
d2204 1
a2204 1
	    if (interesting_section (sec, output_bfd, htab)
d2231 1
a2231 1
	    if (interesting_section (sec, output_bfd, htab))
d2257 1
a2257 1
	    if (interesting_section (sec, output_bfd, htab))
d2263 1
a2263 1
		sinfo = sec_data->stack_info;
a2351 1
  struct spu_link_hash_table *htab = spu_hash_table (info);
d2364 1
a2364 1
	  if (!interesting_section (sec, output_bfd, htab)
d2380 1
a2380 1
	      && (sinfo = sec_data->stack_info) != NULL)
d2419 1
a2419 1
	      && (sinfo = sec_data->stack_info) != NULL)
d2445 1
a2445 1
	      && (sinfo = sec_data->stack_info) != NULL)
d2580 1
a2580 1
	      && (sinfo = sec_data->stack_info) != NULL)
d2743 16
a2758 4
      if (needs_ovl_stub (sym_name, sec, input_section, htab, branch))
	{
	  char *stub_name;
	  struct spu_stub_hash_entry *sh;
d2760 5
a2764 3
	  stub_name = spu_stub_name (sec, h, rel);
	  if (stub_name == NULL)
	    return FALSE;
d2766 2
a2767 10
	  sh = (struct spu_stub_hash_entry *)
	    bfd_hash_lookup (&htab->stub_hash_table, stub_name, FALSE, FALSE);
	  if (sh != NULL)
	    {
	      relocation = (htab->stub->output_section->vma
			    + htab->stub->output_offset
			    + sh->off);
	      addend = 0;
	    }
	  free (stub_name);
d2862 1
a2862 1
      && htab->num_overlays != 0
d2869 1
a2869 3
      static Elf_Internal_Rela zero_rel;
      char *stub_name = spu_stub_name (h->root.u.def.section, h, &zero_rel);
      struct spu_stub_hash_entry *sh;
d2871 7
a2877 13
      if (stub_name == NULL)
	return FALSE;
      sh = (struct spu_stub_hash_entry *)
	bfd_hash_lookup (&htab->stub_hash_table, stub_name, FALSE, FALSE);
      free (stub_name);
      if (sh == NULL)
	return TRUE;
      sym->st_shndx
	= _bfd_elf_section_from_bfd_section (htab->stub->output_section->owner,
					     htab->stub->output_section);
      sym->st_value = (htab->stub->output_section->vma
		       + htab->stub->output_offset
		       + sh->off);
d2943 1
a2943 1
	    || spu_elf_section_data (s)->ovl_index != 0)
d3042 1
a3042 1
	    && (o = spu_elf_section_data (m->sections[0])->ovl_index) != 0)
d3050 1
a3050 1
		unsigned int off = (o - 1) * 16 + 8;
a3119 1
#define bfd_elf32_bfd_link_hash_table_free	spu_elf_link_hash_table_free
@


1.25
log
@	* elf32-spu.c (spu_elf_size_stubs): Correct section alignment.
@
text
@d999 1
d1012 1
a1012 1
		  else
@


1.24
log
@bfd/
	* elf32-spu.c (struct spu_link_hash_table): Add ovly_load_r_symndx.
	(spu_elf_size_stubs): Count stub relocs.
	(write_one_stub): Emit relocs on overlay call stubs.
ld/testsuite/
	* ld-spu/ovl.d: Adjust for stub relocs.
	* ld-spu/ovl2.d: Likewise.
@
text
@d1086 1
a1086 1
      || !bfd_set_section_alignment (ibfd, htab->stub, 2))
d1094 1
a1094 1
      || !bfd_set_section_alignment (ibfd, htab->stub, 4))
@


1.23
log
@	* elf32-spu.c (struct spu_link_hash_table): Add "stubs".
	(spu_elf_link_hash_table_create): Init new field.
	(spu_elf_size_stubs): Store sorted stub syms in new htab field
	rather than local var.
	(spu_elf_build_stubs): Iterate over htab stubs rather than
	hash traversal.
	(struct stubarr): Delete.
	(allocate_spuear_stubs, populate_stubs, write_one_stub): Adjust.
@
text
@d275 1
d1152 2
d1160 2
d1249 50
d1321 14
@


1.22
log
@	* elf32-spu.c (is_indirect_branch): New function.
	(find_function_stack_adjust): End scan on hitting indirect branch.
	(sum_stack): Cast %v arg to correct type.
@
text
@d263 7
d380 2
a381 2
  memset (&htab->stub, 0,
	  sizeof (*htab) - offsetof (struct spu_link_hash_table, stub));
a773 7
struct stubarr {
  struct bfd_hash_table *stub_hash_table;
  struct spu_stub_hash_entry **sh;
  unsigned int count;
  int err;
};

d787 1
a787 1
      struct stubarr *stubs = inf;
d794 1
a794 1
	  stubs->err = 1;
d799 1
a799 1
	bfd_hash_lookup (stubs->stub_hash_table, stub_name, TRUE, FALSE);
d815 1
a815 1
      stubs->count += 1;
d827 1
a827 1
  struct stubarr *stubs = inf;
d829 1
a829 1
  stubs->sh[--stubs->count] = (struct spu_stub_hash_entry *) bh;
a875 1
  struct stubarr stubs;
a879 3
  stubs.stub_hash_table = &htab->stub_hash_table;
  stubs.count = 0;
  stubs.err = 0;
d1053 1
a1053 1
	      stubs.count += 1;
d1071 2
a1072 2
  elf_link_hash_traverse (&htab->elf, allocate_spuear_stubs, &stubs);
  if (stubs.err)
d1076 1
a1076 1
  if (stubs.count == 0)
d1103 2
a1104 2
  stubs.sh = bfd_malloc (stubs.count * sizeof (*stubs.sh));
  if (stubs.sh == NULL)
d1106 7
a1112 6
  i = stubs.count;
  bfd_hash_traverse (&htab->stub_hash_table, populate_stubs, &stubs);
  BFD_ASSERT (stubs.count == 0);

  stubs.count = i;
  qsort (stubs.sh, stubs.count, sizeof (*stubs.sh), sort_stubs);
d1129 1
a1129 1
  for (i = 0; i < stubs.count; i++)
d1131 1
a1131 1
      if (spu_elf_section_data (stubs.sh[group]->target_section
d1133 1
a1133 1
	  != spu_elf_section_data (stubs.sh[i]->target_section
d1138 2
a1139 2
	    stubs.sh[group]->delta
	      = stubs.sh[i - 1]->off - stubs.sh[group]->off;
d1142 6
a1147 6
	  || ((stubs.sh[i - 1]->target_section->output_section->vma
	       + stubs.sh[i - 1]->target_section->output_offset
	       + stubs.sh[i - 1]->target_off)
	      != (stubs.sh[i]->target_section->output_section->vma
		  + stubs.sh[i]->target_section->output_offset
		  + stubs.sh[i]->target_off)))
d1149 1
a1149 1
	  stubs.sh[i]->off = htab->stub->size;
d1153 1
a1153 1
	stubs.sh[i]->off = stubs.sh[i - 1]->off;
d1158 2
a1159 1
    stubs.sh[group]->delta = stubs.sh[i - 1]->off - stubs.sh[group]->off;
d1229 1
a1229 1
write_one_stub (struct bfd_hash_entry *bh, void *inf)
d1231 1
a1231 2
  struct spu_stub_hash_entry *ent = (struct spu_stub_hash_entry *) bh;
  struct spu_link_hash_table *htab = inf;
d1372 2
a1373 1
  bfd_hash_traverse (&htab->stub_hash_table, write_one_stub, htab);
@


1.21
log
@	* elf32-spu.c (elf_howto_table): Formatting.
@
text
@d701 16
d1553 1
a1553 1
      else if (is_branch (buf))
d2529 2
a2530 1
  info->callbacks->minfo (_("%s: 0x%v 0x%v\n"), f1, fun->stack, max_stack);
@


1.20
log
@Switch sources over to use the GPL version 3
@
text
@d57 1
a57 1
  HOWTO (R_SPU_ADDR32,   0, 2, 32, FALSE,  0, complain_overflow_dont,
d78 1
a78 1
  HOWTO (R_SPU_REL32,   0, 2, 32, TRUE,  0, complain_overflow_dont,
d84 1
a84 1
  HOWTO (R_SPU_PPU32,   0, 2, 32, FALSE,  0, complain_overflow_dont,
d87 1
a87 1
  HOWTO (R_SPU_PPU64,   0, 4, 64, FALSE,  0, complain_overflow_dont,
@


1.19
log
@	* elf32-spu.c (spu_elf_fake_sections): New function.
	(elf_backend_fake_sections): Define.
@
text
@d9 1
a9 1
   the Free Software Foundation; either version 2 of the License, or
@


1.18
log
@	* elf32-spu.c (spu_elf_create_sections): Properly iterate over
	input bfds.
@
text
@d3027 12
d3150 1
@


1.17
log
@include/elf/
	* spu.h (R_SPU_ADDR16X): Define.
	(R_SPU_PPU32, R_SPU_PPU64): Renumber.
bfd/
	* elf32-spu.c (elf_howto_table): Add howto for R_SPU_ADDR16X.
@
text
@d536 1
a536 1
  for (ibfd = info->input_bfds; ibfd != NULL; ibfd = ibfd->next)
@


1.16
log
@include/elf/
	* spu.h (R_SPU_PPU32, R_SPU_PPU64): Define.
bfd/
	* reloc.c (BFD_RELOC_SPU_PPU32, BFD_RELOC_SPU_PPU64): Define.
	* elf-bfd.h (struct elf_backend_data): Change return type of
	elf_backend_relocate_section to int.
	* elf32-spu.c (elf_howto_table): Add howtos for R_SPU_PPU32 and
	R_SPU_PPU64.
	(spu_elf_bfd_to_reloc_type): Convert new relocs.
	(spu_elf_count_relocs): New function.
	(elf_backend_count_relocs): Define.
	(spu_elf_relocate_section): Arrange to emit R_SPU_PPU32 and
	R_SPU_PPU64 relocs.
	* elflink.c (elf_link_input_bfd): Emit relocs if relocate_section
	returns 2.
	* bfd-in2.h: Regenerate.
	* libbfd.h: Regenerate.
gas/
	* config/tc-spu.c (md_pseudo_table): Add int, long, quad.  Call
	spu_cons for word.
	(md_assemble): Tidy use of insn.flag.
	(get_imm): Likewise.  Handle uppercase input too.
	(spu_cons): New function.
	* config/tc-spu.h (tc_fix_adjustable): Don't adjust SPU_PPU relocs.
	(TC_FORCE_RELOCATION): Don't resolve them either.
binutils/
	* embedspu.sh (find_prog): Prefer prog in same dir as embedspu
	over one found on the users path.
	(main): Generate .reloc for each R_SPU_PPU* reloc.
@
text
@d81 3
@


1.15
log
@	* elf32-spu.c (spu_elf_size_stubs): Use "void *" for psyms.
	(mark_functions_via_relocs): Likewise.
@
text
@d81 6
d129 4
d2640 20
d2677 1
d2703 6
a2711 1

d2835 25
d3123 1
@


1.14
log
@	* elf32-spu.c (spu_elf_reloc_type_lookup): Return NULL on
	invalid reloc code.
	(spu_elf_gc_mark_hook, spu_elf_section_processing): Delete functions.
	(elf_backend_gc_mark_hook, elf_backend_section_processing): Don't
	define.
@
text
@d861 1
a861 1
      Elf_Internal_Sym **psyms;
d874 1
a874 1
	psyms = (Elf_Internal_Sym **) &symtab_hdr->contents;
d1892 2
a1893 1
  Elf_Internal_Sym *syms, **psyms;
d1902 2
a1903 2
  psyms = (Elf_Internal_Sym **) &symtab_hdr->contents;
  syms = *psyms;
@


1.13
log
@bfd/
	* elf32-spu.c (struct spu_link_hash_table): Add stack_analysis
	and emit_stack_syms bitfields.
	(get_sym_h): Read all symbols if stack analysis will be done.
	(spu_elf_create_sections): Add stack_analysis and emit_stack_syms
	params, and stash in hash table.
	(is_hint): Split off from..
	(is_branch): ..here.  Adjust callers.
	(spu_elf_size_stubs): Add stack_analysis param.  Arrange to read
	and keep all syms.
	(write_one_stub): Fix mem leak.
	(find_function_stack_adjust): New function.
	(sort_syms_syms, sort_syms_psecs): New vars.
	(sort_syms): New function.
	(struct call_info, struct function_info): New.
	(struct spu_elf_stack_info): New.
	(alloc_stack_info, maybe_insert_function, func_name): New functions.
	(is_nop, insns_at_end, check_function_ranges): Likewise.
	(find_function, insert_callee, mark_functions_via_relocs): Likewise.
	(pasted_function, interesting_section, discover_functions): Likewise.
	(mark_non_root, call_graph_traverse, build_call_tree): Likewise.
	(sum_stack, spu_elf_stack_analysis, spu_elf_final_link): Likewise.
	(bfd_elf32_bfd_final_link): Define.
	* elf32-spu.h (struct _spu_elf_section_data): Add stack_info field.
	(spu_elf_create_sections, spu_elf_size_stubs): Update prototypes.
include/
	* bfdlink.h (struct bfd_link_info): Add "info" and "minfo".
ld/
	* ldmain.c (link_callbacks): Init info and minfo fields.
	* ldmisc.c (minfo): Do nothing if no map file.
	* emultempl/spuelf.em (stack_analysis, emit_stack_syms): New vars.
	(spu_after_open): Adjust spu_elf_create_sections call.
	(spu_before_allocation): Likewise for spu_elf_size_stubs.
	(OPTION_SPU_STACK_ANALYSIS, OPTION_SPU_STACK_SYMS): Define.
	(PARSE_AND_LIST_LONGOPTS): Add new entries.
	(PARSE_AND_LIST_OPTIONS, PARSE_AND_LIST_ARGS_CASES): Likewise.
	* gen-doc.texi: Add @@set for SPU and other missing targets.
	* ld.texinfo: Update man page selection to match gen-doc.texi.
	Document SPU features.
@
text
@d142 6
a147 1
  return elf_howto_table + spu_elf_bfd_to_reloc_type (code);
a565 31
/* Return the section that should be marked against GC for a given
   relocation.  */

static asection *
spu_elf_gc_mark_hook (asection *sec,
		      struct bfd_link_info *info ATTRIBUTE_UNUSED,
		      Elf_Internal_Rela *rel ATTRIBUTE_UNUSED,
		      struct elf_link_hash_entry *h,
		      Elf_Internal_Sym *sym)
{
  if (h != NULL)
    {
      switch (h->root.type)
	{
	case bfd_link_hash_defined:
	case bfd_link_hash_defweak:
	  return h->root.u.def.section;

	case bfd_link_hash_common:
	  return h->root.u.c.p->section;

	default:
	  break;
	}
    }
  else
    return bfd_section_from_elf_index (sec->owner, sym->st_shndx);

  return NULL;
}

a3048 18
/* Arrange for our linker created section to be output.  */

static bfd_boolean
spu_elf_section_processing (bfd *abfd ATTRIBUTE_UNUSED,
			    Elf_Internal_Shdr *i_shdrp)
{
  asection *sec;

  sec = i_shdrp->bfd_section;
  if (sec != NULL
      && (sec->flags & SEC_LINKER_CREATED) != 0
      && sec->name != NULL
      && strcmp (sec->name, SPU_PTNOTE_SPUNAME) == 0)
    i_shdrp->contents = sec->contents;

  return TRUE;
}

a3060 1
#define elf_backend_gc_mark_hook		spu_elf_gc_mark_hook
a3071 1
#define elf_backend_section_processing		spu_elf_section_processing
@


1.12
log
@
bfd/
	Many files: Include sysdep.h before bfd.h.
	* Makefile.am: Run "make dep-am".
	* Makefile.in: Regenerate.
binutils/
	* bucumm.h: Split off host dependencies to..
	* sysdep.h: ..here.
	Many files: Include sysdep.h.  Remove duplicate headers and reorder.
	* Makefile.am: Run "make dep-am".
	* Makefile.in: Regenerate.
ld/
	Many files: Include sysdep.h first.  Remove duplicate headers.
	* Makefile.am: Run "make dep-am".
	* Makefile.in: Regenerate.
opcodes/
	* Makefile.am: Run "make dep-am".
	* Makefile.in: Regenerate.
	* ns32k-dis.c: Include sysdep.h first.
@
text
@d274 6
d420 11
a430 3
	    locsyms = bfd_elf_get_elf_syms (ibfd, symtab_hdr,
					    symtab_hdr->sh_info,
					    0, NULL, NULL, NULL);
d453 1
d506 4
a509 1
spu_elf_create_sections (bfd *output_bfd, struct bfd_link_info *info)
d512 5
d698 1
a698 1
/* Return true for all relative and absolute branch and hint instructions.
d706 9
a714 1
   brhnz 00100011 0..
d719 1
a719 1
is_branch (const unsigned char *insn)
d721 1
a721 2
  return (((insn[0] & 0xec) == 0x20 && (insn[1] & 0x80) == 0)
	  || (insn[0] & 0xfc) == 0x10);
d866 1
d887 1
d897 5
d953 1
a953 1
	      if (!get_sym_h (&h, &sym, &sym_sec, &local_syms, r_indx, ibfd))
d977 1
a977 1
		  if (is_branch (insn))
d1281 2
a1282 1
      h = elf_link_hash_lookup (&htab->elf, name, TRUE, FALSE, FALSE);
d1462 1193
d2693 1
d2749 3
a2751 2
      if (needs_ovl_stub (sym_name, sec, input_section, htab,
			  is_branch (contents + rel->r_offset)))
d3119 1
@


1.11
log
@	* elf32-spu.c (needs_ovl_stub): Test that spu_elf_section_data
	is non-NULL before dereferencing.
@
text
@d21 1
a22 1
#include "sysdep.h"
@


1.10
log
@bfd/
	* elf32-spu.c (spu_elf_output_symbol_hook): New function.
	(elf_backend_link_output_symbol_hook): Define.
ld/testsuite/
	* ld-spu/ovl2.d: Update.
@
text
@d707 2
a708 1
      || sym_sec->output_section == NULL)
@


1.9
log
@	* elf32-spu.c (struct stubarr): Add stub_hash_table and err fields.
	(allocate_spuear_stubs): New function.
	(spu_elf_size_stubs): Call allocate_spuear_stubs.
@
text
@d1593 41
d1874 1
@


1.8
log
@	* aout-adobe.c (aout_32_bfd_reloc_name_lookup): Define.
	* aout-arm.c (MY_bfd_reloc_name_lookup): Define.
	(MY (bfd_reloc_name_lookup)): New function.
	* aout-ns32k.c (MY (bfd_reloc_name_lookup)): New function.
	* aout-target.h (NAME (aout, reloc_name_lookup)): Declare.
	(MY_bfd_reloc_name_lookup): Define.
	* aout-tic30.c (tic30_aout_reloc_name_lookup): New function.
	(MY_bfd_reloc_name_lookup): Define.
	* aoutx.h (NAME (aout, reloc_type_lookup)): Don't declare.
	(NAME (aout, reloc_name_lookup)): New function.
	* bout.c (b_out_bfd_reloc_name_lookup): New function.
	* coff-alpha.c (alpha_bfd_reloc_name_lookup): New function.
	(_bfd_ecoff_bfd_reloc_name_lookup): Define.
	* coff-arm.c (coff_arm_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-i386.c (coff_bfd_reloc_name_lookup): Define.
	(coff_i386_reloc_name_lookup): New function.
	* coff-i860.c (coff_i860_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-i960.c (coff_i960_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-m68k.c (m68k_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-maxq.c (maxq_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-mcore.c (mcore_coff_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-mips.c (mips_bfd_reloc_name_lookup): New function.
	(_bfd_ecoff_bfd_reloc_name_lookup): Define.
	* coff-ppc.c (ppc_coff_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-rs6000.c (coff_bfd_reloc_name_lookup): Define.
	(_bfd_xcoff_reloc_name_lookup): New function.
	(rs6000coff_vec, pmac_xcoff_vec): Init new field.
	* coff-sh.c (coff_bfd_reloc_name_lookup): Define.
	(sh_coff_reloc_name_lookup): New function.
	* coff-sparc.c (coff_sparc_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-tic30.c (coff_bfd_reloc_name_lookup): Define.
	(tic30_coff_reloc_name_lookup): New function.
	* coff-tic4x.c (coff_bfd_reloc_name_lookup): Define.
	(tic4x_coff_reloc_name_lookup): New function.
	* coff-tic54x.c (coff_bfd_reloc_name_lookup): Define.
	(tic54x_coff_reloc_name_lookup): New function.
	* coff-x86_64.c (coff_bfd_reloc_name_lookup): Define.
	(coff_amd64_reloc_name_lookup): New function.
	* coff-z80.c (coff_z80_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff-z8k.c (coff_z8k_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* coff64-rs6000.c (coff_bfd_reloc_name_lookup): Define.
	(xcoff64_reloc_name_lookup): New function.
	(rs6000coff64_vec, aix5coff64_vec): Init new field.
	* coffcode.h (coff_bfd_reloc_name_lookup): Define.
	* elf-hppa.h (elf_hppa_reloc_name_lookup): New function.
	* elf-m10200.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf-m10300.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-arc.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-arm.c (elf32_arm_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-avr.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-bfin.c (bfin_bfd_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-cr16c.c (elf_cr16c_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-cris.c (cris_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-crx.c (elf_crx_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-d10v.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-d30v.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-dlx.c (elf32_dlx_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-fr30.c (fr30_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-frv.c (frv_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-gen.c (bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-h8300.c (elf32_h8_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-hppa.c (bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-i370.c (i370_elf_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-i386.c (elf_i386_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-i860.c (elf32_i860_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-i960.c (elf32_i960_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-ip2k.c (ip2k_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-iq2000.c (iq2000_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-m32c.c (m32c_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-m32r.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-m68hc11.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-m68hc12.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-m68k.c (reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-m88k.c (bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-mcore.c (mcore_elf_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-mep.c (mep_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-mips.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	(mips_vxworks_bfd_reloc_name_lookup): Likewise.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-msp430.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-mt.c (mt_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-openrisc.c (openrisc_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-or32.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elf32-pj.c (pj_elf_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-ppc.c (ppc_elf_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-s390.c (elf_s390_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-score.c (elf32_score_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-sh.c (sh_elf_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-sparc.c (bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-spu.c (spu_elf_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-v850.c (v850_elf_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-vax.c (reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-xc16x.c (xc16x_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-xstormy16.c (xstormy16_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf32-xtensa.c (elf_xtensa_reloc_name_lookup): New function.
	(bfd_elf32_bfd_reloc_name_lookup): Define.
	* elf64-alpha.c (elf64_alpha_bfd_reloc_name_lookup): New function.
	(bfd_elf64_bfd_reloc_name_lookup): Define.
	* elf64-gen.c (bfd_elf64_bfd_reloc_name_lookup): Define.
	* elf64-hppa.c (bfd_elf64_bfd_reloc_name_lookup): Define.
	* elf64-mips.c (bfd_elf64_bfd_reloc_name_lookup): New function.
	* elf64-mmix.c (bfd_elf64_bfd_reloc_name_lookup): New function.
	* elf64-ppc.c (ppc64_elf_reloc_name_lookup): New function.
	(bfd_elf64_bfd_reloc_name_lookup): Define.
	* elf64-s390.c (elf_s390_reloc_name_lookup): New function.
	(bfd_elf64_bfd_reloc_name_lookup): Define.
	* elf64-sh64.c (sh_elf64_reloc_name_lookup): New function.
	(bfd_elf64_bfd_reloc_name_lookup): Define.
	* elf64-sparc.c (bfd_elf64_bfd_reloc_name_lookup): Define.
	* elf64-x86-64.c (elf64_x86_64_reloc_name_lookup): New function.
	(bfd_elf64_bfd_reloc_name_lookup): Define.
	* elfn32-mips.c (bfd_elf32_bfd_reloc_name_lookup): New function.
	* elfxx-ia64.c (elfNN_ia64_reloc_name_lookup): New function.
	(bfd_elfNN_bfd_reloc_name_lookup): Define.
	* elfxx-sparc.c (_bfd_sparc_elf_reloc_name_lookup): New function.
	* elfxx-sparc.h (_bfd_sparc_elf_reloc_name_lookup): Declare.
	* i386msdos.c (msdos_bfd_reloc_name_lookup): Define.
	* i386os9k.c (aout_32_bfd_reloc_name_lookup): Define.
	* ieee.c (ieee_bfd_reloc_name_lookup): Define.
	* libaout.h (NAME (aout, reloc_name_lookup)): Declare.
	* libbfd-in.h (_bfd_norelocs_bfd_reloc_name_lookup): Declare.
	* mipsbsd.c (MY_bfd_reloc_name_lookup): Define.
	(MY(reloc_type_lookup)): Rename from MY(reloc_howto_type_lookup).
	(MY(reloc_name_lookup)): New function.
	* nlm-target.h (nlm_bfd_reloc_name_lookup): Define.
	* oasys.c (oasys_bfd_reloc_name_lookup): Define.
	* pdp11.c (NAME (aout, reloc_name_lookup)): New function.
	* pe-mips.c (coff_mips_reloc_name_lookup): New function.
	(coff_bfd_reloc_name_lookup): Define.
	* reloc.c (bfd_reloc_name_lookup): New function.
	* riscix.c (riscix_reloc_name_lookup): New function.
	(MY_bfd_reloc_name_lookup): Define.
	* som.c (som_bfd_reloc_name_lookup): New function.
	* targets.c (struct bfd_target): Add reloc_name_lookup.
	(BFD_JUMP_TABLE_RELOCS): Add NAME##_bfd_reloc_name_lookup.
	* versados.c (versados_bfd_reloc_name_lookup): Define.
	* vms.c (vms_bfd_reloc_name_lookup): New function.
	* bfd-in2.h: Regenerate.
	* libbfd.h: Regenerate.
@
text
@d734 1
d737 1
d740 47
d846 1
d848 1
d1034 4
@


1.7
log
@	* elf32-spu.c (spu_stub_name): Don't put input section in stub name.
	Remove input_sec param.  Adjust all calls.
	(write_one_stub): Adjust stub symbol.
	(needs_ovl_stub): New function, extracted from..
	(spu_elf_size_stubs): ..here.
	(spu_elf_relocate_section): Use needs_ovl_stub.
@
text
@d145 14
d1773 1
@


1.6
log
@	* elf32-spu.c (spu_elf_size_stubs): Always use an overlay stub
	on setjmp calls.
@
text
@d428 2
a429 4
/* Build a name for an entry in the stub hash table.  The input section
   id isn't really necessary but we add that in for consistency with
   ppc32 and ppc64 stub names.  We can't use a local symbol name
   because ld -r might generate duplicate local symbols.  */
d432 1
a432 2
spu_stub_name (const asection *input_sec,
	       const asection *sym_sec,
d441 1
a441 1
      len = 8 + 1 + strlen (h->root.root.string) + 1 + 8 + 1;
d446 1
a446 2
      sprintf (stub_name, "%08x.%s+%x",
	       input_sec->id & 0xffffffff,
d453 1
a453 1
      len = 8 + 1 + 8 + 1 + 8 + 1 + 8 + 1;
d458 1
a458 2
      sprintf (stub_name, "%08x.%x:%x+%x",
	       input_sec->id & 0xffffffff,
d680 39
d834 1
a838 1
	      bfd_boolean is_setjmp;
d884 4
a887 1
		sym_type = h->type;
d889 7
a895 1
		sym_type = ELF_ST_TYPE (sym->st_info);
d905 3
a907 15
		    {
		      const char *sym_name;

		      if (h != NULL)
			sym_name = h->root.root.string;
		      else
			sym_name = bfd_elf_sym_name (sym_sec->owner,
						     symtab_hdr,
						     sym,
						     sym_sec);

		      (*_bfd_error_handler) (_("warning: call to non-function"
					       " symbol %s defined in %B"),
					     sym_sec->owner, sym_name);
		    }
d912 2
a913 13
	      /* setjmp always goes via an overlay stub, because
		 then the return and hence the longjmp goes via
		 __ovly_return.  That magically makes setjmp/longjmp
		 between overlays work.  */
	      is_setjmp = (h != NULL
			   && strncmp (h->root.root.string, "setjmp", 6) == 0
			   && (h->root.root.string[6] == '\0'
			       || h->root.root.string[6] == '@@'));

	      /* Usually, non-overlay sections don't need stubs.  */
	      if (!spu_elf_section_data (sym_sec->output_section)->ovl_index
		  && !non_overlay_stubs
		  && !is_setjmp)
d916 1
a916 14
	      /* We need a reference from some other section before
		 we consider that a symbol might need an overlay stub.  */
	      if (spu_elf_section_data (sym_sec->output_section)->ovl_index
		  == spu_elf_section_data (section->output_section)->ovl_index
		  && !is_setjmp)
		{
		  /* Or we need this to *not* be a branch.  ie. We are
		     possibly taking the address of a function and
		     passing it out somehow.  */
		  if (insn_type != non_branch)
		    continue;
		}

	      stub_name = spu_stub_name (section, sym_sec, h, irela);
d1167 1
a1167 1
      len1 = sizeof ("ovl_call.") - 1;
d1172 2
a1173 3
      memcpy (name, ent->root.string, 9);
      memcpy (name + 9, "ovl_call.", len1);
      memcpy (name + 9 + len1, ent->root.string + 9, len2 - 9 + 1);
d1447 2
a1448 7
      if (sec != NULL
	  && sec->output_section != NULL
	  && sec->output_section->owner == output_bfd
	  && (spu_elf_section_data (sec->output_section)->ovl_index != 0
	      || htab->non_overlay_stubs)
	  && !(sec == input_section
	       && is_branch (contents + rel->r_offset)))
d1453 1
a1453 1
	  stub_name = spu_stub_name (input_section, sec, h, rel);
@


1.5
log
@	PR 3958
bfd/
	* elf-bfd.h (RELOC_FOR_GLOBAL_SYMBOL): No error on relocatable link.
	(elf_discarded_section): Move..
	* bfd-in.h: ..to here.
	* bfd-in2.h: Regenerate.
	* elflink.c (elf_link_input_bfd): Don't zap relocs against symbols
	from discarded sections before relocate_section has done its job.
	* reloc.c (bfd_generic_get_relocated_section_contents): Handle
	relocs against symbols from discarded sections.
	* elf-hppa.h (elf_hppa_howto_table): Set size.  Set dst_mask on
	SECREL32.
	(elf_hppa_relocate_section): Handle relocatable link after setting
	sec, sym, h etc. for final link.  Squash error messages for
	relocatable link.  Clear section contents for relocs against
	symbols in discarded sections, and zero reloc.  Remove existing
	zero r_symndx code.
	* elf-m10200.c (mn10200_elf_relocate_section): Likewise.
	* elf-m10300.c (mn10300_elf_relocate_section): Likewise.
	* elf32-arm.c (elf32_arm_relocate_section): Likewise.
	* elf32-avr.c (elf32_avr_relocate_section): Likewise.
	* elf32-bfin.c (bfinfdpic_relocate_section): Likewise.
	(bfin_relocate_section): Likewise.
	* elf32-cr16c.c (elf32_cr16c_relocate_section): Likewise.
	* elf32-cris.c (cris_elf_relocate_section): Likewise.
	* elf32-crx.c (elf32_crx_relocate_section): Likewise.
	* elf32-d10v.c (elf32_d10v_relocate_section): Likewise.
	* elf32-fr30.c (fr30_elf_relocate_section): Likewise.
	* elf32-frv.c (elf32_frv_relocate_section): Likewise.
	* elf32-h8300.c (elf32_h8_relocate_section): Likewise.
	* elf32-hppa.c (elf32_hppa_relocate_section): Likewise.
	* elf32-i370.c (i370_elf_relocate_section): Likewise.
	* elf32-i386.c (elf_i386_relocate_section): Likewise.
	* elf32-i860.c (elf32_i860_relocate_section): Likewise.
	* elf32-ip2k.c (ip2k_elf_relocate_section): Likewise.
	* elf32-iq2000.c (iq2000_elf_relocate_section): Likewise.
	* elf32-m32c.c (m32c_elf_relocate_section): Likewise.
	* elf32-m32r.c (m32r_elf_relocate_section): Likewise.
	* elf32-m68hc1x.c (elf32_m68hc11_check_relocs): Likewise.
	* elf32-m68k.c (elf_m68k_relocate_section): Likewise.
	* elf32-mcore.c (mcore_elf_relocate_section): Likewise.
	* elf32-mep.c (mep_elf_relocate_section): Likewise.
	* elf32-msp430.c (elf32_msp430_relocate_section): Likewise.
	* elf32-mt.c (mt_elf_relocate_section): Likewise.
	* elf32-openrisc.c (openrisc_elf_relocate_section): Likewise.
	* elf32-ppc.c (ppc_elf_relocate_section): Likewise.
	* elf32-s390.c (elf_s390_relocate_section): Likewise.
	* elf32-score.c (_bfd_score_elf_relocate_section): Likewise.
	* elf32-sh.c (sh_elf_relocate_section): Likewise.
	* elf32-spu.c (spu_elf_relocate_section): Likewise.
	* elf32-v850.c (v850_elf_relocate_section): Likewise.
	* elf32-vax.c (elf_vax_relocate_section): Likewise.
	* elf32-xc16x.c (elf32_xc16x_relocate_section): Likewise.
	* elf32-xstormy16.c (xstormy16_elf_relocate_section): Likewise.
	* elf32-xtensa.c (elf_xtensa_relocate_section): Likewise.
	* elf64-alpha.c (elf64_alpha_relocate_section_r): Likewise.
	(elf64_alpha_relocate_section): Likewise.
	* elf64-mmix.c (mmix_elf_relocate_section): Likewise.
	* elf64-ppc.c (ppc64_elf_relocate_section): Likewise.
	* elf64-s390.c (elf_s390_relocate_section): Likewise.
	* elf64-sh64.c (sh_elf64_relocate_section): Likewise.
	* elf64-x86-64.c (elf64_x86_64_relocate_section): Likewise.
	* elfxx-ia64.c (elfNN_ia64_relocate_section): Likewise.
	* elfxx-mips.c (_bfd_mips_elf_relocate_section): Likewise.
	* elfxx-sparc.c (_bfd_sparc_elf_relocate_section): Likewise.

	* elf32-arm.c (elf32_arm_relocate_section): Always adjust section
	symbols for relocatable link.  Don't use always-zero st_value.
	(elf_backend_rela_normal): Don't define.
	* elf32-bfin.c (bfinfdpic_relocate_section): Use
	RELOC_FOR_GLOBAL_SYMBOL.
	* elf32-frv.c (elf32_frv_relocate_section): Likewise.
	* elf32-d10v.c (elf32_d10v_relocate_section): Combine SEC_MERGE
	section symbol adjustments with same for relocatable link.
	* elf32-i386.c (elf_i386_relocate_section): Likewise.
	* elf32-m68hc1x.c (m68hc11_get_relocation_value): Move..
	(elf32_m68hc11_check_relocs): ..to here.
	* elf32-score.c (score_elf_final_link_relocate): Remove zero
	r_symndx code.
	* elfxx-mips.c (mips_elf_calculate_relocation): Likewise.

ld/testsuite/
	* ld-elf/linkonce1.d: New.
	* ld-elf/linkonce1a.s: New.
	* ld-elf/linkonce1b.s: New.
	* ld-elf/linkonce2.d: New.
	* ld-i386/pcrel16abs.d: New.
	* ld-i386/pcrel16abs.s: New.
	* ld-i386/i386.exp: Run it.
@
text
@d804 1
d881 9
d892 2
a893 1
		  && !non_overlay_stubs)
d899 2
a900 1
		  == spu_elf_section_data (section->output_section)->ovl_index)
@


1.4
log
@	* elf32-spu.h (struct _ovl_stream): Make "start" and "end" const.
	* elf32-spu.c (ovl_mgr_pread): Add const to casts.
@
text
@a1353 3
  if (info->relocatable)
    return TRUE;

d1400 14
@


1.3
log
@	* elf32-spu.c (spu_elf_size_stubs): Correct order of warning args.
@
text
@d1072 1
a1072 1
  max = (char *) os->end - (char *) os->start;
d1081 1
a1081 1
  memcpy (buf, (char *) os->start + offset, count);
@


1.2
log
@bfd/
	* opncls.c (bfd_openr_iovec): Add "stat" parameter.
	(struct opncls): Add "stat" field.
	(opncls_bstat): Call vec->stat.
	* bfd-in2.h: Regenerate.
	* elf32-spu.c (spu_elf_open_builtin_lib): Adjust.
gdb/
	* spu-linux-nat.c (spu_bfd_iovec_stat): New function.
	(spu_bfd_open): Adjust bfd_openr_iovec call.
@
text
@d3 1
a3 1
   Copyright 2006 Free Software Foundation, Inc.
d874 1
a874 1
					     sym_name, sym_sec->owner);
@


1.1
log
@New Cell SPU port.
@
text
@d1093 1
@

