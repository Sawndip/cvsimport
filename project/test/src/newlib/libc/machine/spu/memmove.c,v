head	1.2;
access;
symbols
	cygwin-1_7_35-release:1.2
	cygwin-1_7_34-release:1.2
	newlib-2_2_0:1.2.0.10
	cygwin-1_7_33-release:1.2
	cygwin-1_7_32-release:1.2
	cygwin-1_7_31-release:1.2
	cygwin-1_7_30-release:1.2
	cygwin-1_7_29-release:1.2
	cygwin-1_7_28-release:1.2
	newlib-2_1_0:1.2
	cygwin-1_7_27-release:1.2
	cygwin-1_7_26-release:1.2
	cygwin-1_7_25-release:1.2
	cygwin-1_7_24-release:1.2
	cygwin-1_7_23-release:1.2
	cygwin-1_7_22-release:1.2
	cygwin-1_7_21-release:1.2
	cygwin-1_7_20-release:1.2
	cygwin-1_7_19-release:1.2
	cygwin-64bit-postmerge:1.2
	cygwin-64bit-premerge-branch:1.2.0.8
	cygwin-64bit-premerge:1.2
	cygwin-1_7_18-release:1.2
	newlib-2_0_0:1.2
	cygwin-1_7_17-release:1.2
	cygwin-64bit-branch:1.2.0.6
	cygwin-1_7_16-release:1.2
	cygwin-1_7_15-release:1.2
	cygwin-1_7_14_2-release:1.2
	cygwin-1_7_14-release:1.2
	cygwin-1_7_12-release:1.2
	cygwin-1_7_11-release:1.2
	cygwin-1_7_10-release:1.2
	newlib-1_20_0:1.2
	cygwin-1_7_9-release:1.2
	cygwin-1_7_8-release:1.2
	newlib-1_19_0:1.2
	cygwin-1_7_7-release:1.2
	cygwin-1_7_5-release:1.2
	cygwin-1_7_4-release:1.2
	cygwin-1_7_3-release:1.2
	cygwin-1_7_2-release:1.2
	newlib-1_18_0:1.2
	cygwin-1_7_1-release:1.2
	newlib-1_17_0-arc:1.2.0.4
	binutils-arc-20080908-branch:1.2.0.2
	binutils-arc-20080908-branchpoint:1.2
	newlib-1_17_0:1.2
	newlib-1_16_0:1.2
	newlib-1_15_0:1.2;
locks; strict;
comment	@ * @;


1.2
date	2006.11.22.21.19.56;	author jjohnstn;	state Exp;
branches;
next	1.1;

1.1
date	2006.10.27.23.02.00;	author jjohnstn;	state Exp;
branches;
next	;


desc
@@


1.2
log
@
2006-11-22  Luca Barbato  <lu_zero@@gentoo.org>

        * libc/machine/spu/memcpy.c: Use spu_splats, explicit cast.
        * libc/machine/spu/memmove.c: Use spu_splats, explicit cast.
        * libc/machine/spu/memset.c: Use spu_splats, remove apple-cast.
        * libc/machine/spu/strchr.c: Use spu_splats, remove apple-cast.
        * libc/machine/spu/strncat.c: Explicit cast.
        * libc/machine/spu/strncmp.c: Use spu_splats.
        * libc/machine/spu/strncpy.c: Explicit cast.
        * libc/machine/spu/strrchr.c: Use spu_splats.
        * libc/machine/spu/strspn.c: Use spu_splats.
@
text
@/*
  (C) Copyright 2001,2006,
  International Business Machines Corporation,
  Sony Computer Entertainment, Incorporated,
  Toshiba Corporation,

  All rights reserved.

  Redistribution and use in source and binary forms, with or without
  modification, are permitted provided that the following conditions are met:

    * Redistributions of source code must retain the above copyright notice,
  this list of conditions and the following disclaimer.
    * Redistributions in binary form must reproduce the above copyright
  notice, this list of conditions and the following disclaimer in the
  documentation and/or other materials provided with the distribution.
    * Neither the names of the copyright holders nor the names of their
  contributors may be used to endorse or promote products derived from this
  software without specific prior written permission.

  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
  POSSIBILITY OF SUCH DAMAGE.
*/
#include <spu_intrinsics.h>
#include <stddef.h>
#include "vec_literal.h"

/* Copy n bytes from memory area src to memory area dest.
 * Copying is performed as if the n characters pointed to
 * by src are first copied into a temporary array that does
 * not overlap the src and dest arrays. Then the n characters
 * of the temporary array are copied into the destination
 * array. The memmove subroutine returns a pointer to dest.
 */

void * memmove(void * __restrict__ dest, const void * __restrict__ src, size_t n)
{
  int adjust, delta;
  unsigned int soffset1, soffset2, doffset1, doffset2;
  vec_uchar16 *vSrc, *vDst;
  vec_uchar16 sdata1, sdata2, sdata, ddata, shuffle;
  vec_uchar16 mask, mask1, mask2, mask3, one = spu_splats((unsigned char)-1);

  soffset1  = (unsigned int)(src) & 15;
  doffset1 = (unsigned int)(dest) & 15;
  doffset2 = ((unsigned int)(dest) + n) & 15;

  /* Construct a series of masks used to data insert. The masks
   * contains 0 bit when the destination word is unchanged, 1 when it
   * must be replaced by source bits.
   *
   * mask1 = mask for leading unchanged bytes
   * mask2 = mask for trailing unchange bytes
   * mask3 = mask indicating the more than one qword is being changed.
   */
  mask  = one;
  mask1 = spu_rlmaskqwbyte(mask, -doffset1);
  mask2 = spu_slqwbyte(mask, 16-doffset2);
  mask3 = (vec_uchar16)spu_cmpgt(spu_splats((unsigned int)(doffset1 + n)), 15);

  vDst = (vec_uchar16 *)(dest);

  delta  = (int)soffset1 - (int)doffset1;

  /* The follow check only works if the SPU addresses are not
   * wrapped. No provisions have been made to correct for this
   * limitation.
   */
  if (((unsigned int)dest - (unsigned int)src) >= (unsigned int)n) {
    /* Forward copy. Perform a memcpy.
     *
     * Handle any leading destination partial quadwords as
     * well a very short copy (ie, such that the n characters
     * all reside in a single (destination) quadword.
     */
    vSrc = (vec_uchar16 *)(src);
    vDst = (vec_uchar16 *)(dest);

    /* Handle any leading destination partial quadwords as
     * well a very short copy (ie, such that the n characters
     * all reside in a single (destination) quadword.
     */
    soffset1 = (unsigned int)(src) & 15;
    doffset1 = (unsigned int)(dest) & 15;
    doffset2 = ((unsigned int)(dest) + n) & 15;

    /* Compute a shuffle pattern used to align the source string
     * with the alignment of the destination string.
     */

    adjust = (int)spu_extract(spu_cmpgt(spu_promote(doffset1, 0), spu_promote(soffset1, 0)), 0);
    delta  = (int)soffset1 - (int)doffset1;
    delta += adjust & 16;

    shuffle = (vec_uchar16)spu_add((vec_uint4)spu_splats((unsigned char)delta),
				   VEC_LITERAL(vec_uint4, 0x00010203, 0x04050607, 0x08090A0B, 0x0C0D0E0F));

    vSrc += adjust;

    sdata1 = *vSrc++;
    sdata2 = *vSrc++;

    ddata = *vDst;
    sdata = spu_shuffle(sdata1, sdata2, shuffle);

    /* Construct a series of masks used to data insert. The masks
     * contain 0 when the destination word is unchanged, 1 when it
     * must be replaced by source bytes.
     *
     * mask1 = mask for leading unchanged bytes
     * mask2 = mask for trailing unchange bytes
     * mask3 = mask indicating the more than one qword is being changed.
     */
    mask  = one;
    mask1 = spu_rlmaskqwbyte(mask, -doffset1);
    mask2 = spu_slqwbyte(mask, 16-doffset2);
    mask3 = (vec_uchar16)spu_cmpgt(spu_splats((unsigned int)(doffset1 + n)), 15);

    *vDst++ = spu_sel(ddata, sdata, spu_and(mask1, spu_or(mask2, mask3)));

    n += doffset1;

    /* Handle complete destination quadwords
     */
    while (n > 31) {
      sdata1 = sdata2;
      sdata2 = *vSrc++;
      *vDst++ = spu_shuffle(sdata1, sdata2, shuffle);
      n -= 16;
    }

    /* Handle any trailing partial (destination) quadwords
     */
    mask = spu_and((vec_uchar16)spu_cmpgt(spu_splats((unsigned int)n), 16), mask2);
    *vDst = spu_sel(*vDst, spu_shuffle(sdata2, *vSrc, shuffle), mask);

  } else {
    /* Backward copy.
     *
     * Handle any leading destination partial quadwords as
     * well a very short copy (ie, such that the n characters
     * all reside in a single (destination) quadword.
     */
    vSrc = (vec_uchar16 *)((unsigned int)src  + n-1);
    vDst = (vec_uchar16 *)((unsigned int)dest + n-1);

    /* Handle any leading destination partial quadwords as
     * well a very short copy (ie, such that the n characters
     * all reside in a single (destination) quadword.
     */
    soffset1 = (unsigned int)(src)  & 15;
    soffset2 = (unsigned int)(vSrc) & 15;
    doffset1 = (unsigned int)(dest) & 15;
    doffset2 = (unsigned int)(vDst) & 15;

    /* Compute a shuffle pattern used to align the source string
     * with the alignment of the destination string.
     */
    adjust = (int)spu_extract(spu_cmpgt(spu_promote(soffset2, 0), spu_promote(doffset2, 0)), 0);
    delta  = (int)doffset2 - (int)soffset2;
    delta += adjust & 16;

    shuffle = (vec_uchar16)spu_sub(VEC_LITERAL(vec_uint4, 0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F),
				   (vec_uint4)spu_splats((unsigned char)delta));

    vSrc -= adjust;

    sdata2 = *vSrc--;
    sdata1 = *vSrc--;

    ddata = *vDst;
    sdata = spu_shuffle(sdata1, sdata2, shuffle);

    /* Construct a series of masks used to data insert. The masks
     * contain 0 when the destination word is unchanged, 1 when it
     * must be replaced by source bytes.
     *
     * mask1 = mask for leading unchanged bytes
     * mask2 = mask for trailing unchange bytes
     * mask3 = mask indicating the more than one qword is being changed.
     */
    mask  = one;
    mask1 = spu_rlmaskqwbyte(mask, -doffset1);
    mask2 = spu_slqwbyte(mask, 15-doffset2);
    mask3 = (vec_uchar16)spu_cmpgt(spu_splats((int)(doffset2 - n)), -2);

    *vDst-- = spu_sel(ddata, sdata, spu_and(mask2, spu_orc(mask1, mask3)));

    n -= doffset2 + 1;

    /* Handle complete destination quadwords
     */
    while ((int)n > 15) {
      sdata2 = sdata1;
      sdata1 = *vSrc--;
      *vDst-- = spu_shuffle(sdata1, sdata2, shuffle);
      n -= 16;
    }

    /* Handle any trailing partial (destination) quadwords
     */
    mask = spu_and((vec_uchar16)spu_cmpgt(spu_splats((int)n), 0), mask1);
    *vDst = spu_sel(*vDst, spu_shuffle(*vSrc, sdata1, shuffle), mask);
  }
  return (dest);
}

@


1.1
log
@
2006-10-27  Joel Schopp  <jschopp@@austin.ibm.com>

        * libc/machine/spu/memcpy.c: Override generic function with vectorized
        version optimized for the cell spu.
        * libc/machine/spu/memmove.c: Ditto.
        * libc/machine/spu/memset.c: Ditto.
        * libc/machine/spu/strcat.c: Ditto.
        * libc/machine/spu/strchr.c: Ditto.
        * libc/machine/spu/strcmp.c: Ditto.
        * libc/machine/spu/strcpy.c: Ditto.
        * libc/machine/spu/strcspn.c: Ditto.
        * libc/machine/spu/strlen.c: Ditto.
        * libc/machine/spu/strncat.c: Ditto.
        * libc/machine/spu/strncmp.c: Ditto.
        * libc/machine/spu/strncpy.c: Ditto.
        * libc/machine/spu/strpbrk.c: Ditto.
        * libc/machine/spu/strrchr.c: Ditto.
        * libc/machine/spu/strspn.c: Ditto.
        * libc/machine/spu/strxfrm.c: Ditto.
        * libc/machine/spu/vec_literal.h: Add abstraction of vector literals,
        removing altivec style initializers.
        * libc/machine/spu/Makefile.am: Add new files to list so they build
        * libc/machine/spu/Makefile.in: Regenerate from new Makefile.am
@
text
@d51 1
a51 1
  vec_uchar16 mask, mask1, mask2, mask3;
d65 1
a65 1
  mask  = VEC_SPLAT_U8(-1);
d68 1
a68 1
  mask3 = (vec_uchar16)spu_cmpgt(spu_splats(doffset1 + n), 15);
d123 1
a123 1
    mask  = VEC_SPLAT_U8(-1);
d126 1
a126 1
    mask3 = (vec_uchar16)spu_cmpgt(spu_splats(doffset1 + n), 15);
d143 1
a143 1
    mask = spu_and((vec_uchar16)spu_cmpgt(spu_splats(n), 16), mask2);
d191 1
a191 1
    mask  = VEC_SPLAT_U8(-1);
@

