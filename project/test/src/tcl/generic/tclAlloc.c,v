head	1.9;
access;
symbols
	sid-snapshot-20180601:1.9
	sid-snapshot-20180501:1.9
	sid-snapshot-20180401:1.9
	sid-snapshot-20180301:1.9
	sid-snapshot-20180201:1.9
	sid-snapshot-20180101:1.9
	sid-snapshot-20171201:1.9
	sid-snapshot-20171101:1.9
	sid-snapshot-20171001:1.9
	sid-snapshot-20170901:1.9
	sid-snapshot-20170801:1.9
	sid-snapshot-20170701:1.9
	sid-snapshot-20170601:1.9
	sid-snapshot-20170501:1.9
	sid-snapshot-20170401:1.9
	sid-snapshot-20170301:1.9
	sid-snapshot-20170201:1.9
	sid-snapshot-20170101:1.9
	sid-snapshot-20161201:1.9
	sid-snapshot-20161101:1.9
	sid-snapshot-20160901:1.9
	sid-snapshot-20160801:1.9
	sid-snapshot-20160701:1.9
	sid-snapshot-20160601:1.9
	sid-snapshot-20160501:1.9
	sid-snapshot-20160401:1.9
	sid-snapshot-20160301:1.9
	sid-snapshot-20160201:1.9
	sid-snapshot-20160101:1.9
	sid-snapshot-20151201:1.9
	sid-snapshot-20151101:1.9
	sid-snapshot-20151001:1.9
	sid-snapshot-20150901:1.9
	sid-snapshot-20150801:1.9
	sid-snapshot-20150701:1.9
	sid-snapshot-20150601:1.9
	sid-snapshot-20150501:1.9
	sid-snapshot-20150401:1.9
	sid-snapshot-20150301:1.9
	sid-snapshot-20150201:1.9
	sid-snapshot-20150101:1.9
	sid-snapshot-20141201:1.9
	sid-snapshot-20141101:1.9
	sid-snapshot-20141001:1.9
	sid-snapshot-20140901:1.9
	sid-snapshot-20140801:1.9
	sid-snapshot-20140701:1.9
	sid-snapshot-20140601:1.9
	sid-snapshot-20140501:1.9
	sid-snapshot-20140401:1.9
	sid-snapshot-20140301:1.9
	sid-snapshot-20140201:1.9
	sid-snapshot-20140101:1.9
	sid-snapshot-20131201:1.9
	sid-snapshot-20131101:1.9
	sid-snapshot-20131001:1.9
	sid-snapshot-20130901:1.9
	sid-snapshot-20130801:1.9
	sid-snapshot-20130701:1.9
	sid-snapshot-20130601:1.9
	insight_7_6-2013-04-10-branchpoint:1.9
	gdb_7_6-branch:1.9.0.58
	sid-snapshot-20130501:1.9
	sid-snapshot-20130401:1.9
	sid-snapshot-20130301:1.9
	sid-snapshot-20130201:1.9
	sid-snapshot-20130101:1.9
	sid-snapshot-20121201:1.9
	sid-snapshot-20121101:1.9
	sid-snapshot-20121001:1.9
	sid-snapshot-20120901:1.9
	gdb_7_5-branch:1.9.0.56
	sid-snapshot-20120801:1.9
	sid-snapshot-20120701:1.9
	sid-snapshot-20120601:1.9
	sid-snapshot-20120501:1.9
	sid-snapshot-20120401:1.9
	gdb_7_4-branch:1.9.0.54
	sid-snapshot-20120301:1.9
	sid-snapshot-20120201:1.9
	sid-snapshot-20120101:1.9
	sid-snapshot-20111201:1.9
	sid-snapshot-20111101:1.9
	sid-snapshot-20111001:1.9
	sid-snapshot-20110901:1.9
	gdb_7_3-branch:1.9.0.52
	sid-snapshot-20110801:1.9
	sid-snapshot-20110701:1.9
	sid-snapshot-20110601:1.9
	sid-snapshot-20110501:1.9
	sid-snapshot-20110401:1.9
	sid-snapshot-20110301:1.9
	sid-snapshot-20110201:1.9
	sid-snapshot-20110101:1.9
	sid-snapshot-20101201:1.9
	sid-snapshot-20101101:1.9
	sid-snapshot-20101001:1.9
	sid-snapshot-20100901:1.9
	sid-snapshot-20100801:1.9
	sid-snapshot-20100701:1.9
	sid-snapshot-20100601:1.9
	sid-snapshot-20100501:1.9
	sid-snapshot-20100401:1.9
	sid-snapshot-20100301:1.9
	gdb_7_1-branch:1.9.0.50
	gdb_7_0-branch:1.9.0.48
	sid-snapshot-20100201:1.9
	sid-snapshot-20100101:1.9
	sid-snapshot-20091201:1.9
	sid-snapshot-20091101:1.9
	sid-snapshot-20091001:1.9
	arc-sim-20090309:1.9
	sid-snapshot-20090901:1.9
	sid-snapshot-20090801:1.9
	sid-snapshot-20090701:1.9
	sid-snapshot-20090601:1.9
	sid-snapshot-20090501:1.9
	kevinb-pre-tcl8_5_7_merge:1.9
	sid-snapshot-20090401:1.9
	arc-insight_6_8-branch:1.9.0.46
	arc-insight_6_8-branchpoint:1.9
	insight_6_8-branch:1.9.0.44
	insight_6_8-branchpoint:1.9
	sid-snapshot-20090301:1.9
	sid-snapshot-20090201:1.9
	sid-snapshot-20090101:1.9
	sid-snapshot-20081201:1.9
	sid-snapshot-20081101:1.9
	sid-snapshot-20081001:1.9
	sid-snapshot-20080901:1.9
	sid-snapshot-20080801:1.9
	sid-snapshot-20080701:1.9
	sid-snapshot-20080601:1.9
	sid-snapshot-20080501:1.9
	sid-snapshot-20080403:1.9
	sid-snapshot-20080401:1.9
	gdb_6_8-branch:1.9.0.42
	sid-snapshot-20080301:1.9
	sid-snapshot-20080201:1.9
	sid-snapshot-20080101:1.9
	sid-snapshot-20071201:1.9
	sid-snapshot-20071101:1.9
	sid-snapshot-20071001:1.9
	insight_6_6-20070208-release:1.9
	gdb_6_6-branch:1.9.0.40
	gdb_6_6-2006-11-15-branchpoint:1.9
	insight_6_5-20061003-release:1.9
	gdb_6_5-branch:1.9.0.38
	gdb_6_5-2006-05-14-branchpoint:1.9
	readline_5_1-import-branch:1.9.0.36
	readline_5_1-import-branchpoint:1.9
	gdb_6_4-branch:1.9.0.34
	gdb_6_4-2005-11-01-branchpoint:1.9
	msnyder-tracepoint-checkpoint-branch:1.9.0.32
	msnyder-tracepoint-checkpoint-branchpoint:1.9
	gdb_6_1-2004-04-05-release:1.9
	ezannoni_pie-20040323-branch:1.9.0.30
	ezannoni_pie-20040323-branchpoint:1.9
	cagney_tramp-20040321-mergepoint:1.9
	cagney_tramp-20040309-branch:1.9.0.28
	cagney_tramp-20040309-branchpoint:1.9
	gdb_6_1-branch:1.9.0.26
	gdb_6_1-2004-03-01-gmt-branchpoint:1.9
	drow-cplus-merge-20040208:1.9
	carlton_dictionary-20040126-merge:1.9
	drow-cplus-merge-20040113:1.9
	drow-cplus-merge-20031224:1.9
	drow-cplus-merge-20031220:1.9
	carlton_dictionary-20031215-merge:1.9
	drow-cplus-merge-20031214:1.9
	carlton-dictionary-20031111-merge:1.9
	gdb_6_0-2003-10-04-release:1.9
	carlton_dictionary-20030917-merge:1.9
	ezannoni_pie-20030916-branchpoint:1.9
	ezannoni_pie-20030916-branch:1.9.0.24
	cagney_x86i386-20030821-branch:1.9.0.22
	cagney_x86i386-20030821-branchpoint:1.9
	carlton_dictionary-20030805-merge:1.9
	carlton_dictionary-20030627-merge:1.9
	gdb_6_0-branch:1.9.0.20
	gdb_6_0-2003-06-23-branchpoint:1.9
	cagney_convert-20030606-branch:1.9.0.18
	cagney_convert-20030606-branchpoint:1.9
	cagney_writestrings-20030508-branch:1.9.0.16
	cagney_writestrings-20030508-branchpoint:1.9
	carlton_dictionary-20030523-merge:1.9
	cagney_fileio-20030521-branch:1.9.0.14
	cagney_fileio-20030521-branchpoint:1.9
	carlton_dictionary-20030430-merge:1.9
	carlton_dictionary-20030416-merge:1.9
	cagney_frameaddr-20030409-mergepoint:1.9
	cagney_frameaddr-20030403-branchpoint:1.9
	cagney_frameaddr-20030403-branch:1.9.0.12
	cagney_framebase-20030330-mergepoint:1.9
	cagney_framebase-20030326-branch:1.9.0.10
	cagney_framebase-20030326-branchpoint:1.9
	cagney_lazyid-20030317-branch:1.9.0.8
	cagney_lazyid-20030317-branchpoint:1.9
	offbyone-20030313-branch:1.9.0.6
	offbyone-20030313-branchpoint:1.9
	carlton_dictionary-20030305-merge:1.9
	cagney_offbyone-20030303-branch:1.9.0.4
	cagney_offbyone-20030303-branchpoint:1.9
	carlton_dictionary-20030207-merge:1.9
	interps-20030202-branch:1.9.0.2
	interps-20030202-branchpoint:1.9
	TCL8_4_1:1.1.1.3
	cagney-unwind-20030108-branch:1.8.0.2
	cagney-unwind-20030108-branchpoint:1.8
	carlton_dictionary-20021223-merge:1.8
	gdb_5_3-2002-12-12-release:1.6
	TCL_8_4_1:1.1.1.3
	carlton_dictionary-20021115-merge:1.7
	kseitz_interps-20021105-merge:1.7
	kseitz_interps-20021103-merge:1.7
	drow-cplus-merge-20021020:1.7
	drow-cplus-merge-20021025:1.7
	carlton_dictionary-20021025-merge:1.7
	carlton_dictionary-20021011-merge:1.7
	drow-cplus-branch:1.7.0.4
	drow-cplus-branchpoint:1.7
	kseitz_interps-20020930-merge:1.7
	carlton_dictionary-20020927-merge:1.7
	tcltk840-20020924-branch:1.7.0.2
	tcltk840-20020924-branchpoint:1.7
	TCL_8_4_0:1.1.1.3
	carlton_dictionary-branch:1.6.0.16
	carlton_dictionary-20020920-branchpoint:1.6
	sid-20020905-branchpoint:1.6
	sid-20020905-branch:1.6.0.14
	gdb_5_3-branch:1.6.0.12
	gdb_5_3-2002-09-04-branchpoint:1.6
	kseitz_interps-20020829-merge:1.6
	cagney_sysregs-20020825-branch:1.6.0.10
	cagney_sysregs-20020825-branchpoint:1.6
	readline_4_3-import-branch:1.6.0.8
	readline_4_3-import-branchpoint:1.6
	gdb_5_2_1-2002-07-23-release:1.6
	kseitz_interps-20020528-branch:1.6.0.6
	kseitz_interps-20020528-branchpoint:1.6
	cagney_regbuf-20020515-branch:1.6.0.4
	cagney_regbuf-20020515-branchpoint:1.6
	gdb_5_2-2002-04-29-release:1.6
	gdb_5_2-branch:1.6.0.2
	gdb_5_2-2002-03-03-branchpoint:1.6
	gdb_5_1_1-2002-01-24-release:1.2
	cygnus_cvs_20020108_pre:1.6
	gdb_5_1_0_1-2002-01-03-branch:1.2.0.6
	gdb_5_1_0_1-2002-01-03-branchpoint:1.2
	gdb_5_1-2001-11-21-release:1.2
	gdb_s390-2001-09-26-branch:1.2.0.4
	gdb_s390-2001-09-26-branchpoint:1.2
	TCL_8_3:1.1.1.2
	NET:1.1.1
	gdb_5_1-2001-07-29-branch:1.2.0.2
	gdb_5_1-2001-07-29-branchpoint:1.2
	insight-precleanup-2001-01-01:1.1.1.1
	gdb_5_0-2000-05-19-release:1.1.1.1
	gdb_4_18_2-2000-05-18-release:1.1.1.1
	gdb_4_95_1-2000-05-11-snapshot:1.1.1.1
	gdb_4_95_0-2000-04-27-snapshot:1.1.1.1
	gdb_5_0-2000-04-10-branch:1.1.1.1.0.2
	gdb_5_0-2000-04-10-branchpoint:1.1.1.1
	repo-unification-2000-02-06:1.1.1.1
	dejagnu-2000-02-04:1.1.1.1
	dejagnu-2000-01-31:1.1.1.1
	dejagnu-2000-01-24:1.1.1.1
	dejagnu-2000-01-17:1.1.1.1
	dejagnu-2000-01-10:1.1.1.1
	dejagnu-2000-01-04:1.1.1.1
	dejagnu-1999-12-21:1.1.1.1
	dejagnu-1999-12-13:1.1.1.1
	dejagnu-1999-12-07:1.1.1.1
	dejagnu-1999-12-06:1.1.1.1
	dejagnu-1999-11-15:1.1.1.1
	dejagnu-1999-11-08:1.1.1.1
	SNAPSHOT:1.1.1;
locks; strict;
comment	@ * @;
expand	@o@;


1.9
date	2003.01.21.19.40.01;	author hunt;	state Exp;
branches;
next	1.8;

1.8
date	2002.11.26.19.47.51;	author hunt;	state Exp;
branches;
next	1.7;

1.7
date	2002.09.24.18.37.02;	author kseitz;	state Exp;
branches
	1.7.2.1
	1.7.4.1;
next	1.6;

1.6
date	2001.09.13.18.27.53;	author irox;	state Exp;
branches
	1.6.16.1;
next	1.5;

1.5
date	2001.09.13.00.38.49;	author irox;	state Exp;
branches;
next	1.4;

1.4
date	2001.09.09.23.56.04;	author irox;	state Exp;
branches;
next	1.3;

1.3
date	2001.09.09.23.26.06;	author irox;	state Exp;
branches;
next	1.2;

1.2
date	2001.04.10.20.08.27;	author cgf;	state Exp;
branches;
next	1.1;

1.1
date	99.11.09.01.28.43;	author jsm;	state Exp;
branches
	1.1.1.1;
next	;

1.7.2.1
date	2002.09.27.21.49.02;	author kseitz;	state Exp;
branches;
next	;

1.7.4.1
date	2003.12.14.20.28.42;	author drow;	state Exp;
branches;
next	;

1.6.16.1
date	2002.12.23.19.40.16;	author carlton;	state Exp;
branches;
next	1.6.16.2;

1.6.16.2
date	2003.02.07.19.18.09;	author carlton;	state Exp;
branches;
next	;

1.1.1.1
date	99.11.09.01.28.43;	author jsm;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2001.09.09.22.40.54;	author irox;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2002.09.24.19.55.53;	author kseitz;	state Exp;
branches;
next	;


desc
@@


1.9
log
@Updated to tcl 8.4.1
@
text
@/* 
 * tclAlloc.c --
 *
 *	This is a very fast storage allocator.  It allocates blocks of a
 *	small number of different sizes, and keeps free lists of each size.
 *	Blocks that don't exactly fit are passed up to the next larger size.
 *	Blocks over a certain size are directly allocated from the system.
 *
 * Copyright (c) 1983 Regents of the University of California.
 * Copyright (c) 1996-1997 Sun Microsystems, Inc.
 * Copyright (c) 1998-1999 by Scriptics Corporation.
 *
 * Portions contributed by Chris Kingsley, Jack Jansen and Ray Johnson.
 *
 * See the file "license.terms" for information on usage and redistribution
 * of this file, and for a DISCLAIMER OF ALL WARRANTIES.
 *
 * RCS: @@(#) $Id: tclAlloc.c,v 1.16 2002/04/23 17:03:34 hobbs Exp $
 */

/*
 * Windows and Unix use an alternative allocator when building with threads
 * that has significantly reduced lock contention.
 */

#if !defined(TCL_THREADS) || !defined(USE_THREAD_ALLOC)

#include "tclInt.h"
#include "tclPort.h"

#if USE_TCLALLOC

#ifdef TCL_DEBUG
#   define DEBUG
/* #define MSTATS */
#   define RCHECK
#endif

/*
 * We should really make use of AC_CHECK_TYPE(caddr_t)
 * here, but it can wait until Tcl uses config.h properly.
 */
#if defined(MAC_TCL) || defined(_MSC_VER) || defined(__MINGW32__) || defined(__BORLANDC__)
typedef unsigned long caddr_t;
#endif

/*
 * The overhead on a block is at least 8 bytes.  When free, this space
 * contains a pointer to the next free block, and the bottom two bits must
 * be zero.  When in use, the first byte is set to MAGIC, and the second
 * byte is the size index.  The remaining bytes are for alignment.
 * If range checking is enabled then a second word holds the size of the
 * requested block, less 1, rounded up to a multiple of sizeof(RMAGIC).
 * The order of elements is critical: ov_magic must overlay the low order
 * bits of ov_next, and ov_magic can not be a valid ov_next bit pattern.
 */

union overhead {
    union overhead *ov_next;	/* when free */
    unsigned char ov_padding[8]; /* Ensure the structure is 8-byte aligned. */
    struct {
	unsigned char	ovu_magic0;	/* magic number */
	unsigned char	ovu_index;	/* bucket # */
	unsigned char	ovu_unused;	/* unused */
	unsigned char	ovu_magic1;	/* other magic number */
#ifdef RCHECK
	unsigned short	ovu_rmagic;	/* range magic number */
	unsigned long	ovu_size;	/* actual block size */
	unsigned short  ovu_unused2;    /* padding to 8-byte align */
#endif
    } ovu;
#define ov_magic0	ovu.ovu_magic0
#define ov_magic1	ovu.ovu_magic1
#define ov_index	ovu.ovu_index
#define ov_rmagic	ovu.ovu_rmagic
#define ov_size		ovu.ovu_size
};


#define MAGIC		0xef		/* magic # on accounting info */
#define RMAGIC		0x5555		/* magic # on range info */

#ifdef RCHECK
#define	RSLOP		sizeof (unsigned short)
#else
#define	RSLOP		0
#endif

#define OVERHEAD (sizeof(union overhead) + RSLOP)

/*
 * nextf[i] is the pointer to the next free block of size 2^(i+3).  The
 * smallest allocatable block is 8 bytes.  The overhead information
 * precedes the data area returned to the user.
 */

#define NBUCKETS	13
#define MAXMALLOC	(1<<(NBUCKETS+2))
static	union overhead *nextf[NBUCKETS];

/* 
 * The following structure is used to keep track of all system memory 
 * currently owned by Tcl.  When finalizing, all this memory will
 * be returned to the system.
 */

struct block {
    struct block *nextPtr;	/* Linked list. */
    struct block *prevPtr;	/* Linked list for big blocks, ensures 8-byte 
				 * alignment for suballocated blocks. */
};

static struct block *blockList;		/* Tracks the suballocated blocks. */
static struct block bigBlocks = {	/* Big blocks aren't suballocated. */
    &bigBlocks, &bigBlocks
};

/*
 * The allocator is protected by a special mutex that must be
 * explicitly initialized.  Futhermore, because Tcl_Alloc may be
 * used before anything else in Tcl, we make this module self-initializing
 * after all with the allocInit variable.
 */

#ifdef TCL_THREADS
static Tcl_Mutex *allocMutexPtr;
#endif
static int allocInit = 0;


#ifdef MSTATS

/*
 * nmalloc[i] is the difference between the number of mallocs and frees
 * for a given block size.
 */

static	unsigned int nmalloc[NBUCKETS+1];
#include <stdio.h>
#endif

#if defined(DEBUG) || defined(RCHECK)
#define	ASSERT(p)   if (!(p)) panic(# p)
#define RANGE_ASSERT(p) if (!(p)) panic(# p)
#else
#define	ASSERT(p)
#define RANGE_ASSERT(p)
#endif

/*
 * Prototypes for functions used only in this file.
 */

static void 		MoreCore _ANSI_ARGS_((int bucket));


/*
 *-------------------------------------------------------------------------
 *
 * TclInitAlloc --
 *
 *	Initialize the memory system.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	Initialize the mutex used to serialize allocations.
 *
 *-------------------------------------------------------------------------
 */

void
TclInitAlloc()
{
    if (!allocInit) {
	allocInit = 1;
#ifdef TCL_THREADS
	allocMutexPtr = Tcl_GetAllocMutex();
#endif
    }
}

/*
 *-------------------------------------------------------------------------
 *
 * TclFinalizeAllocSubsystem --
 *
 *	Release all resources being used by this subsystem, including 
 *	aggressively freeing all memory allocated by TclpAlloc() that 
 *	has not yet been released with TclpFree().
 *	
 *	After this function is called, all memory allocated with 
 *	TclpAlloc() should be considered unusable.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	This subsystem is self-initializing, since memory can be 
 *	allocated before Tcl is formally initialized.  After this call,
 *	this subsystem has been reset to its initial state and is 
 *	usable again.
 *
 *-------------------------------------------------------------------------
 */

void
TclFinalizeAllocSubsystem()
{
    int i;
    struct block *blockPtr, *nextPtr;

    Tcl_MutexLock(allocMutexPtr);
    for (blockPtr = blockList; blockPtr != NULL; blockPtr = nextPtr) {
	nextPtr = blockPtr->nextPtr;
	TclpSysFree(blockPtr);
    }
    blockList = NULL;

    for (blockPtr = bigBlocks.nextPtr; blockPtr != &bigBlocks; ) {
	nextPtr = blockPtr->nextPtr;
	TclpSysFree(blockPtr);
	blockPtr = nextPtr;
    }
    bigBlocks.nextPtr = &bigBlocks;
    bigBlocks.prevPtr = &bigBlocks;

    for (i = 0; i < NBUCKETS; i++) {
	nextf[i] = NULL;
#ifdef MSTATS
	nmalloc[i] = 0;
#endif
    }
#ifdef MSTATS
    nmalloc[i] = 0;
#endif
    Tcl_MutexUnlock(allocMutexPtr);
}

/*
 *----------------------------------------------------------------------
 *
 * TclpAlloc --
 *
 *	Allocate more memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

char *
TclpAlloc(nbytes)
    unsigned int nbytes;	/* Number of bytes to allocate. */
{
    register union overhead *op;
    register long bucket;
    register unsigned amt;
    struct block *bigBlockPtr;

    if (!allocInit) {
	/*
	 * We have to make the "self initializing" because Tcl_Alloc
	 * may be used before any other part of Tcl.  E.g., see
	 * main() for tclsh!
	 */
	TclInitAlloc();
    }
    Tcl_MutexLock(allocMutexPtr);
    /*
     * First the simple case: we simple allocate big blocks directly
     */
    if (nbytes + OVERHEAD >= MAXMALLOC) {
	bigBlockPtr = (struct block *) TclpSysAlloc((unsigned) 
		(sizeof(struct block) + OVERHEAD + nbytes), 0);
	if (bigBlockPtr == NULL) {
	    Tcl_MutexUnlock(allocMutexPtr);
	    return NULL;
	}
	bigBlockPtr->nextPtr = bigBlocks.nextPtr;
	bigBlocks.nextPtr = bigBlockPtr;
	bigBlockPtr->prevPtr = &bigBlocks;
	bigBlockPtr->nextPtr->prevPtr = bigBlockPtr;

	op = (union overhead *) (bigBlockPtr + 1);
	op->ov_magic0 = op->ov_magic1 = MAGIC;
	op->ov_index = 0xff;
#ifdef MSTATS
	nmalloc[NBUCKETS]++;
#endif
#ifdef RCHECK
	/*
	 * Record allocated size of block and
	 * bound space with magic numbers.
	 */
	op->ov_size = (nbytes + RSLOP - 1) & ~(RSLOP - 1);
	op->ov_rmagic = RMAGIC;
	*(unsigned short *)((caddr_t)(op + 1) + op->ov_size) = RMAGIC;
#endif
	Tcl_MutexUnlock(allocMutexPtr);
	return (void *)(op+1);
    }
    /*
     * Convert amount of memory requested into closest block size
     * stored in hash buckets which satisfies request.
     * Account for space used per block for accounting.
     */
#ifndef RCHECK
    amt = 8;	/* size of first bucket */
    bucket = 0;
#else
    amt = 16;	/* size of first bucket */
    bucket = 1;
#endif
    while (nbytes + OVERHEAD > amt) {
	amt <<= 1;
	if (amt == 0) {
	    Tcl_MutexUnlock(allocMutexPtr);
	    return (NULL);
	}
	bucket++;
    }
    ASSERT( bucket < NBUCKETS );

    /*
     * If nothing in hash bucket right now,
     * request more memory from the system.
     */
    if ((op = nextf[bucket]) == NULL) {
	MoreCore(bucket);
	if ((op = nextf[bucket]) == NULL) {
	    Tcl_MutexUnlock(allocMutexPtr);
	    return (NULL);
	}
    }
    /*
     * Remove from linked list
     */
    nextf[bucket] = op->ov_next;
    op->ov_magic0 = op->ov_magic1 = MAGIC;
    op->ov_index = (unsigned char) bucket;
#ifdef MSTATS
    nmalloc[bucket]++;
#endif
#ifdef RCHECK
    /*
     * Record allocated size of block and
     * bound space with magic numbers.
     */
    op->ov_size = (nbytes + RSLOP - 1) & ~(RSLOP - 1);
    op->ov_rmagic = RMAGIC;
    *(unsigned short *)((caddr_t)(op + 1) + op->ov_size) = RMAGIC;
#endif
    Tcl_MutexUnlock(allocMutexPtr);
    return ((char *)(op + 1));
}

/*
 *----------------------------------------------------------------------
 *
 * MoreCore --
 *
 *	Allocate more memory to the indicated bucket.
 *
 *	Assumes Mutex is already held.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	Attempts to get more memory from the system.
 *
 *----------------------------------------------------------------------
 */

static void
MoreCore(bucket)
    int bucket;		/* What bucket to allocat to. */
{
    register union overhead *op;
    register long sz;		/* size of desired block */
    long amt;			/* amount to allocate */
    int nblks;			/* how many blocks we get */
    struct block *blockPtr;

    /*
     * sbrk_size <= 0 only for big, FLUFFY, requests (about
     * 2^30 bytes on a VAX, I think) or for a negative arg.
     */
    sz = 1 << (bucket + 3);
    ASSERT(sz > 0);

    amt = MAXMALLOC;
    nblks = amt / sz;
    ASSERT(nblks*sz == amt);

    blockPtr = (struct block *) TclpSysAlloc((unsigned) 
	    (sizeof(struct block) + amt), 1);
    /* no more room! */
    if (blockPtr == NULL) {
	return;
    }
    blockPtr->nextPtr = blockList;
    blockList = blockPtr;

    op = (union overhead *) (blockPtr + 1);
    
    /*
     * Add new memory allocated to that on
     * free list for this hash bucket.
     */
    nextf[bucket] = op;
    while (--nblks > 0) {
	op->ov_next = (union overhead *)((caddr_t)op + sz);
	op = (union overhead *)((caddr_t)op + sz);
    }
    op->ov_next = (union overhead *)NULL;
}

/*
 *----------------------------------------------------------------------
 *
 * TclpFree --
 *
 *	Free memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

void
TclpFree(cp)
    char *cp;		/* Pointer to memory to free. */
{   
    register long size;
    register union overhead *op;
    struct block *bigBlockPtr;

    if (cp == NULL) {
	return;
    }

    Tcl_MutexLock(allocMutexPtr);
    op = (union overhead *)((caddr_t)cp - sizeof (union overhead));

    ASSERT(op->ov_magic0 == MAGIC);		/* make sure it was in use */
    ASSERT(op->ov_magic1 == MAGIC);
    if (op->ov_magic0 != MAGIC || op->ov_magic1 != MAGIC) {
	Tcl_MutexUnlock(allocMutexPtr);
	return;
    }

    RANGE_ASSERT(op->ov_rmagic == RMAGIC);
    RANGE_ASSERT(*(unsigned short *)((caddr_t)(op + 1) + op->ov_size) == RMAGIC);
    size = op->ov_index;
    if ( size == 0xff ) {
#ifdef MSTATS
	nmalloc[NBUCKETS]--;
#endif
	bigBlockPtr = (struct block *) op - 1;
	bigBlockPtr->prevPtr->nextPtr = bigBlockPtr->nextPtr;
	bigBlockPtr->nextPtr->prevPtr = bigBlockPtr->prevPtr;
	TclpSysFree(bigBlockPtr);
	Tcl_MutexUnlock(allocMutexPtr);
	return;
    }
    ASSERT(size < NBUCKETS);
    op->ov_next = nextf[size];	/* also clobbers ov_magic */
    nextf[size] = op;
#ifdef MSTATS
    nmalloc[size]--;
#endif
    Tcl_MutexUnlock(allocMutexPtr);
}

/*
 *----------------------------------------------------------------------
 *
 * TclpRealloc --
 *
 *	Reallocate memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

char *
TclpRealloc(cp, nbytes)
    char *cp;			/* Pointer to alloced block. */
    unsigned int nbytes;	/* New size of memory. */
{   
    int i;
    union overhead *op;
    struct block *bigBlockPtr;
    int expensive;
    unsigned long maxsize;

    if (cp == NULL) {
	return (TclpAlloc(nbytes));
    }

    Tcl_MutexLock(allocMutexPtr);

    op = (union overhead *)((caddr_t)cp - sizeof (union overhead));

    ASSERT(op->ov_magic0 == MAGIC);		/* make sure it was in use */
    ASSERT(op->ov_magic1 == MAGIC);
    if (op->ov_magic0 != MAGIC || op->ov_magic1 != MAGIC) {
	Tcl_MutexUnlock(allocMutexPtr);
	return NULL;
    }

    RANGE_ASSERT(op->ov_rmagic == RMAGIC);
    RANGE_ASSERT(*(unsigned short *)((caddr_t)(op + 1) + op->ov_size) == RMAGIC);
    i = op->ov_index;

    /*
     * If the block isn't in a bin, just realloc it.
     */

    if (i == 0xff) {
	struct block *prevPtr, *nextPtr;
	bigBlockPtr = (struct block *) op - 1;
	prevPtr = bigBlockPtr->prevPtr;
	nextPtr = bigBlockPtr->nextPtr;
	bigBlockPtr = (struct block *) TclpSysRealloc(bigBlockPtr, 
		sizeof(struct block) + OVERHEAD + nbytes);
	if (bigBlockPtr == NULL) {
	    Tcl_MutexUnlock(allocMutexPtr);
	    return NULL;
	}

	if (prevPtr->nextPtr != bigBlockPtr) {
	    /*
	     * If the block has moved, splice the new block into the list where
	     * the old block used to be. 
	     */

	    prevPtr->nextPtr = bigBlockPtr;
	    nextPtr->prevPtr = bigBlockPtr;
	}

	op = (union overhead *) (bigBlockPtr + 1);
#ifdef MSTATS
	nmalloc[NBUCKETS]++;
#endif
#ifdef RCHECK
	/*
	 * Record allocated size of block and update magic number bounds.
	 */

	op->ov_size = (nbytes + RSLOP - 1) & ~(RSLOP - 1);
	*(unsigned short *)((caddr_t)(op + 1) + op->ov_size) = RMAGIC;
#endif
	Tcl_MutexUnlock(allocMutexPtr);
	return (char *)(op+1);
    }
    maxsize = 1 << (i+3);
    expensive = 0;
    if ( nbytes + OVERHEAD > maxsize ) {
	expensive = 1;
    } else if ( i > 0 && nbytes + OVERHEAD < (maxsize/2) ) {
	expensive = 1;
    }

    if (expensive) {
	void *newp;

	Tcl_MutexUnlock(allocMutexPtr);

	newp = TclpAlloc(nbytes);
	if ( newp == NULL ) {
	    return NULL;
	}
	maxsize -= OVERHEAD;
	if ( maxsize < nbytes )
	    nbytes = maxsize;
	memcpy((VOID *) newp, (VOID *) cp, (size_t) nbytes);
	TclpFree(cp);
	return newp;
    }
    
    /*
     * Ok, we don't have to copy, it fits as-is
     */
#ifdef RCHECK
    op->ov_size = (nbytes + RSLOP - 1) & ~(RSLOP - 1);
    *(unsigned short *)((caddr_t)(op + 1) + op->ov_size) = RMAGIC;
#endif
    Tcl_MutexUnlock(allocMutexPtr);
    return(cp);
}

/*
 *----------------------------------------------------------------------
 *
 * mstats --
 *
 *	Prints two lines of numbers, one showing the length of the 
 *	free list for each size category, the second showing the 
 *	number of mallocs - frees for each size category.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

#ifdef MSTATS
void
mstats(s)
    char *s;	/* Where to write info. */
{
    register int i, j;
    register union overhead *p;
    int totfree = 0,
	totused = 0;

    Tcl_MutexLock(allocMutexPtr);
    fprintf(stderr, "Memory allocation statistics %s\nTclpFree:\t", s);
    for (i = 0; i < NBUCKETS; i++) {
	for (j = 0, p = nextf[i]; p; p = p->ov_next, j++)
	    fprintf(stderr, " %d", j);
	totfree += j * (1 << (i + 3));
    }
    fprintf(stderr, "\nused:\t");
    for (i = 0; i < NBUCKETS; i++) {
	fprintf(stderr, " %d", nmalloc[i]);
	totused += nmalloc[i] * (1 << (i + 3));
    }
    fprintf(stderr, "\n\tTotal small in use: %d, total free: %d\n",
	    totused, totfree);
    fprintf(stderr, "\n\tNumber of big (>%d) blocks in use: %d\n", 
	    MAXMALLOC, nmalloc[NBUCKETS]);
    Tcl_MutexUnlock(allocMutexPtr);
}
#endif

#else  /* !USE_TCLALLOC */

/*
 *----------------------------------------------------------------------
 *
 * TclpAlloc --
 *
 *	Allocate more memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

char *
TclpAlloc(nbytes)
    unsigned int nbytes;	/* Number of bytes to allocate. */
{
    return (char*) malloc(nbytes);
}

/*
 *----------------------------------------------------------------------
 *
 * TclpFree --
 *
 *	Free memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

void
TclpFree(cp)
    char *cp;		/* Pointer to memory to free. */
{   
    free(cp);
    return;
}

/*
 *----------------------------------------------------------------------
 *
 * TclpRealloc --
 *
 *	Reallocate memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

char *
TclpRealloc(cp, nbytes)
    char *cp;			/* Pointer to alloced block. */
    unsigned int nbytes;	/* New size of memory. */
{   
    return (char*) realloc(cp, nbytes);
}

#endif /* !USE_TCLALLOC */
#endif /* !TCL_THREADS */
@


1.8
log
@touched all sources to ease next import
@
text
@d18 1
a18 1
 * RCS: @@(#) $Id: tclAlloc.c,v 1.8.8.6 2001/07/17 01:33:49 mdejong Exp $
d21 7
d40 2
a41 3
 * With gcc this will already be defined. This should really
 * make use of AC_CHECK_TYPE(caddr_t) but that can wait
 * until we use config.h properly.
d43 1
a43 2

#if defined(MAC_TCL) || defined(_MSC_VER) || defined(__MINGW32__)
d731 1
a731 1

@


1.7
log
@touched all sources to ease next import
@
text
@@


1.7.4.1
log
@Merge drow-cplus-branch to:
  cvs rtag -D 2003-12-14 00:00:00 UTC drow-cplus-merge-20031214 gdb+dejagnu
@
text
@d18 1
a18 1
 * RCS: @@(#) $Id: tclAlloc.c,v 1.16 2002/04/23 17:03:34 hobbs Exp $
a20 7
/*
 * Windows and Unix use an alternative allocator when building with threads
 * that has significantly reduced lock contention.
 */

#if !defined(TCL_THREADS) || !defined(USE_THREAD_ALLOC)

d33 3
a35 2
 * We should really make use of AC_CHECK_TYPE(caddr_t)
 * here, but it can wait until Tcl uses config.h properly.
d37 2
a38 1
#if defined(MAC_TCL) || defined(_MSC_VER) || defined(__MINGW32__) || defined(__BORLANDC__)
d726 1
a726 1
#endif /* !TCL_THREADS */
@


1.7.2.1
log
@Import Tcl 8.4.0 into mainline-like sources. Simplest Tcl build possible for
cygwin.
@
text
@d18 1
a18 1
 * RCS: @@(#) $Id: tclAlloc.c,v 1.16 2002/04/23 17:03:34 hobbs Exp $
a20 7
/*
 * Windows and Unix use an alternative allocator when building with threads
 * that has significantly reduced lock contention.
 */

#if !defined(TCL_THREADS) || !defined(USE_THREAD_ALLOC)

d33 3
a35 2
 * We should really make use of AC_CHECK_TYPE(caddr_t)
 * here, but it can wait until Tcl uses config.h properly.
d37 2
a38 1
#if defined(MAC_TCL) || defined(_MSC_VER) || defined(__MINGW32__) || defined(__BORLANDC__)
d726 1
a726 1
#endif /* !TCL_THREADS */
@


1.6
log
@	* generic/tclStubInit.tcl: Export tclAlloc functions
	if __MINGW32__ is defined.
	* generic/tclAlloc.c: Revert changes from 2001-09-12.
	* generic/tcl.h: Use tclAlloc function if __WIN32__
	is defined.
	* win/tclWinPort.h: Fixed typer __MWIN32 should read
	__WIN32__.
@
text
@@


1.6.16.1
log
@2002-12-23  David Carlton  <carlton@@math.stanford.edu>

	* Merge from mainline; tag is carlton_dictionary-20021223-merge.
@
text
@@


1.6.16.2
log
@2003-02-07  David Carlton  <carlton@@math.stanford.edu>

	* Merge with mainline; tag is carlton_dictionary-20030207-merge.
@
text
@a20 7
/*
 * Windows and Unix use an alternative allocator when building with threads
 * that has significantly reduced lock contention.
 */

#if !defined(TCL_THREADS) || !defined(USE_THREAD_ALLOC)

d33 3
a35 2
 * We should really make use of AC_CHECK_TYPE(caddr_t)
 * here, but it can wait until Tcl uses config.h properly.
d37 2
a38 1
#if defined(MAC_TCL) || defined(_MSC_VER) || defined(__MINGW32__) || defined(__BORLANDC__)
d726 1
a726 1
#endif /* !TCL_THREADS */
@


1.5
log
@
	* Makefile.in: Add 'cygwin' subdirectory to 'make all'
	target.
	* configure.in: Configure 'cygwin' and 'win' directory
	for a cygwin host.
	* configure: Regenerated.
	* cygwin/configure.in: Change version number to 8.3.
	* cygwin/configure: Regenerated.
	* cygwin/Makefile.am: Added/removed files to be build
	for Tcl8.3.
	* cygwin/Makefile.in: Regenerated.
	* generic/tcl.h: Don't define __WIN32__ for cygwin or
	mwing32 builds.  Don't define USE_TCLALLOC when building
	for cygwin.  Don't use __declspec unless building Tcl or
	tk or build with USE_TCL_STUBS.
	* generic/tclAlloc.c: For cygwin hosts, don't using
	anything in this file unless build with __TCL_UNIX_VARIANT.
	* generic/tclClock.c: Declare 'timezone' as an int, if it
	hasn't been #defined.
	* generic/tclStubInit.c: Don't export any tclAlloc function
	when build for a cygwin host.
	* win/configure.in: Set DL_LIBS and MATH_LIBS.  Create
	unix/tclConfig.sh.
	* win/configure: Regenerated.
	* win/tclWinPort.h: Added missing #endif.
	* win/tclWinFile.c (TclpChdir): Don't invert change
	directory results on cygwin.
@
text
@a23 2
#if !defined(__CYGWIN__) || defined(__TCL_UNIX_VARIANT)

a725 2

#endif /* !__CYGWIN__ OR __TCL_UNIX_VARIANT */
@


1.4
log
@touched all Tcl files to ease next import.
@
text
@d24 2
d728 2
@


1.3
log
@Tcl8.3 upgrade merge.
@
text
@@


1.2
log
@Fixes for newer cygwin gccs.
Use modern Cygwin conditional.
@
text
@d11 1
d18 1
a18 1
 * RCS: @@(#) $Id: tclAlloc.c,v 1.7 1999/01/26 03:53:08 jingham Exp $
d24 2
d32 7
a38 1
#ifndef __CYGWIN__
d43 1
a43 1
 * The overhead on a block is at least 4 bytes.  When free, this space
d55 1
d64 1
d71 1
a71 1
#define ov_size	ovu.ovu_size
d96 30
d150 85
d253 2
a254 2
TclpAlloc(
    unsigned int nbytes)	/* Number of bytes to allocate. */
d259 1
d261 9
d274 4
a277 2
	op = (union overhead *)TclpSysAlloc(nbytes+OVERHEAD, 0);
	if (op == NULL) {
d280 6
d300 1
d318 1
d332 1
d354 1
d365 2
d377 2
a378 2
MoreCore(
    int bucket)		/* What bucket to allocat to. */
d384 1
d397 2
a398 1
    op = (union overhead *)TclpSysAlloc(amt, 1);
d400 1
a400 1
    if (op == NULL) {
d403 4
d437 2
a438 2
TclpFree(
    char *cp)		/* Pointer to memory to free. */
d442 1
d448 1
d454 1
d465 5
a469 1
	TclpSysFree(op);
d478 1
d498 3
a500 3
TclpRealloc(
    char *cp,			/* Pointer to alloced block. */
    unsigned int nbytes)	/* New size of memory. */
d504 1
d512 2
d519 1
d532 8
a539 2
	op = (union overhead *) TclpSysRealloc(op, nbytes+OVERHEAD);
	if (op == NULL) {
d542 12
d565 1
d578 3
a580 1
		
d600 1
d624 2
a625 2
mstats(
    char *s)	/* Where to write info. */
d632 1
d648 1
d651 76
@


1.1
log
@Initial revision
@
text
@d29 1
a29 1
#ifndef __CYGWIN32__
@


1.1.1.1
log
@import dejagnu-1999-11-08 snapshot
@
text
@@


1.1.1.2
log
@Tcl 8.3 upgrade
@
text
@a10 1
 * Copyright (c) 1998-1999 by Scriptics Corporation.
d17 1
a17 1
 * RCS: @@(#) $Id: tclAlloc.c,v 1.8.8.6 2001/07/17 01:33:49 mdejong Exp $
a22 2
#if USE_TCLALLOC

d29 1
a29 7
/*
 * With gcc this will already be defined. This should really
 * make use of AC_CHECK_TYPE(caddr_t) but that can wait
 * until we use config.h properly.
 */

#if defined(MAC_TCL) || defined(_MSC_VER) || defined(__MINGW32__)
d34 1
a34 1
 * The overhead on a block is at least 8 bytes.  When free, this space
a45 1
    unsigned char ov_padding[8]; /* Ensure the structure is 8-byte aligned. */
a53 1
	unsigned short  ovu_unused2;    /* padding to 8-byte align */
d60 1
a60 1
#define ov_size		ovu.ovu_size
a84 30
/* 
 * The following structure is used to keep track of all system memory 
 * currently owned by Tcl.  When finalizing, all this memory will
 * be returned to the system.
 */

struct block {
    struct block *nextPtr;	/* Linked list. */
    struct block *prevPtr;	/* Linked list for big blocks, ensures 8-byte 
				 * alignment for suballocated blocks. */
};

static struct block *blockList;		/* Tracks the suballocated blocks. */
static struct block bigBlocks = {	/* Big blocks aren't suballocated. */
    &bigBlocks, &bigBlocks
};

/*
 * The allocator is protected by a special mutex that must be
 * explicitly initialized.  Futhermore, because Tcl_Alloc may be
 * used before anything else in Tcl, we make this module self-initializing
 * after all with the allocInit variable.
 */

#ifdef TCL_THREADS
static Tcl_Mutex *allocMutexPtr;
#endif
static int allocInit = 0;


a108 85


/*
 *-------------------------------------------------------------------------
 *
 * TclInitAlloc --
 *
 *	Initialize the memory system.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	Initialize the mutex used to serialize allocations.
 *
 *-------------------------------------------------------------------------
 */

void
TclInitAlloc()
{
    if (!allocInit) {
	allocInit = 1;
#ifdef TCL_THREADS
	allocMutexPtr = Tcl_GetAllocMutex();
#endif
    }
}

/*
 *-------------------------------------------------------------------------
 *
 * TclFinalizeAllocSubsystem --
 *
 *	Release all resources being used by this subsystem, including 
 *	aggressively freeing all memory allocated by TclpAlloc() that 
 *	has not yet been released with TclpFree().
 *	
 *	After this function is called, all memory allocated with 
 *	TclpAlloc() should be considered unusable.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	This subsystem is self-initializing, since memory can be 
 *	allocated before Tcl is formally initialized.  After this call,
 *	this subsystem has been reset to its initial state and is 
 *	usable again.
 *
 *-------------------------------------------------------------------------
 */

void
TclFinalizeAllocSubsystem()
{
    int i;
    struct block *blockPtr, *nextPtr;

    Tcl_MutexLock(allocMutexPtr);
    for (blockPtr = blockList; blockPtr != NULL; blockPtr = nextPtr) {
	nextPtr = blockPtr->nextPtr;
	TclpSysFree(blockPtr);
    }
    blockList = NULL;

    for (blockPtr = bigBlocks.nextPtr; blockPtr != &bigBlocks; ) {
	nextPtr = blockPtr->nextPtr;
	TclpSysFree(blockPtr);
	blockPtr = nextPtr;
    }
    bigBlocks.nextPtr = &bigBlocks;
    bigBlocks.prevPtr = &bigBlocks;

    for (i = 0; i < NBUCKETS; i++) {
	nextf[i] = NULL;
#ifdef MSTATS
	nmalloc[i] = 0;
#endif
    }
#ifdef MSTATS
    nmalloc[i] = 0;
#endif
    Tcl_MutexUnlock(allocMutexPtr);
}
d127 2
a128 2
TclpAlloc(nbytes)
    unsigned int nbytes;	/* Number of bytes to allocate. */
a132 1
    struct block *bigBlockPtr;
a133 9
    if (!allocInit) {
	/*
	 * We have to make the "self initializing" because Tcl_Alloc
	 * may be used before any other part of Tcl.  E.g., see
	 * main() for tclsh!
	 */
	TclInitAlloc();
    }
    Tcl_MutexLock(allocMutexPtr);
d138 2
a139 4
	bigBlockPtr = (struct block *) TclpSysAlloc((unsigned) 
		(sizeof(struct block) + OVERHEAD + nbytes), 0);
	if (bigBlockPtr == NULL) {
	    Tcl_MutexUnlock(allocMutexPtr);
a141 6
	bigBlockPtr->nextPtr = bigBlocks.nextPtr;
	bigBlocks.nextPtr = bigBlockPtr;
	bigBlockPtr->prevPtr = &bigBlocks;
	bigBlockPtr->nextPtr->prevPtr = bigBlockPtr;

	op = (union overhead *) (bigBlockPtr + 1);
a155 1
	Tcl_MutexUnlock(allocMutexPtr);
a172 1
	    Tcl_MutexUnlock(allocMutexPtr);
a185 1
	    Tcl_MutexUnlock(allocMutexPtr);
a206 1
    Tcl_MutexUnlock(allocMutexPtr);
a216 2
 *	Assumes Mutex is already held.
 *
d227 2
a228 2
MoreCore(bucket)
    int bucket;		/* What bucket to allocat to. */
a233 1
    struct block *blockPtr;
d246 1
a246 2
    blockPtr = (struct block *) TclpSysAlloc((unsigned) 
	    (sizeof(struct block) + amt), 1);
d248 1
a248 1
    if (blockPtr == NULL) {
a250 4
    blockPtr->nextPtr = blockList;
    blockList = blockPtr;

    op = (union overhead *) (blockPtr + 1);
d281 2
a282 2
TclpFree(cp)
    char *cp;		/* Pointer to memory to free. */
a285 1
    struct block *bigBlockPtr;
a290 1
    Tcl_MutexLock(allocMutexPtr);
a295 1
	Tcl_MutexUnlock(allocMutexPtr);
d306 1
a306 5
	bigBlockPtr = (struct block *) op - 1;
	bigBlockPtr->prevPtr->nextPtr = bigBlockPtr->nextPtr;
	bigBlockPtr->nextPtr->prevPtr = bigBlockPtr->prevPtr;
	TclpSysFree(bigBlockPtr);
	Tcl_MutexUnlock(allocMutexPtr);
a314 1
    Tcl_MutexUnlock(allocMutexPtr);
d334 3
a336 3
TclpRealloc(cp, nbytes)
    char *cp;			/* Pointer to alloced block. */
    unsigned int nbytes;	/* New size of memory. */
a339 1
    struct block *bigBlockPtr;
a346 2
    Tcl_MutexLock(allocMutexPtr);

a351 1
	Tcl_MutexUnlock(allocMutexPtr);
d364 2
a365 8
	struct block *prevPtr, *nextPtr;
	bigBlockPtr = (struct block *) op - 1;
	prevPtr = bigBlockPtr->prevPtr;
	nextPtr = bigBlockPtr->nextPtr;
	bigBlockPtr = (struct block *) TclpSysRealloc(bigBlockPtr, 
		sizeof(struct block) + OVERHEAD + nbytes);
	if (bigBlockPtr == NULL) {
	    Tcl_MutexUnlock(allocMutexPtr);
a367 12

	if (prevPtr->nextPtr != bigBlockPtr) {
	    /*
	     * If the block has moved, splice the new block into the list where
	     * the old block used to be. 
	     */

	    prevPtr->nextPtr = bigBlockPtr;
	    nextPtr->prevPtr = bigBlockPtr;
	}

	op = (union overhead *) (bigBlockPtr + 1);
a378 1
	Tcl_MutexUnlock(allocMutexPtr);
d391 1
a391 3

	Tcl_MutexUnlock(allocMutexPtr);

a410 1
    Tcl_MutexUnlock(allocMutexPtr);
d434 2
a435 2
mstats(s)
    char *s;	/* Where to write info. */
a441 1
    Tcl_MutexLock(allocMutexPtr);
a456 1
    Tcl_MutexUnlock(allocMutexPtr);
a458 76

#else  /* !USE_TCLALLOC */

/*
 *----------------------------------------------------------------------
 *
 * TclpAlloc --
 *
 *	Allocate more memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

char *
TclpAlloc(nbytes)
    unsigned int nbytes;	/* Number of bytes to allocate. */
{
    return (char*) malloc(nbytes);
}

/*
 *----------------------------------------------------------------------
 *
 * TclpFree --
 *
 *	Free memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

void
TclpFree(cp)
    char *cp;		/* Pointer to memory to free. */
{   
    free(cp);
    return;
}

/*
 *----------------------------------------------------------------------
 *
 * TclpRealloc --
 *
 *	Reallocate memory.
 *
 * Results:
 *	None.
 *
 * Side effects:
 *	None.
 *
 *----------------------------------------------------------------------
 */

char *
TclpRealloc(cp, nbytes)
    char *cp;			/* Pointer to alloced block. */
    unsigned int nbytes;	/* New size of memory. */
{   
    return (char*) realloc(cp, nbytes);
}

#endif /* !USE_TCLALLOC */

@


1.1.1.3
log
@import tcl 8.4.0
@
text
@d18 1
a18 1
 * RCS: @@(#) $Id: tclAlloc.c,v 1.16 2002/04/23 17:03:34 hobbs Exp $
a20 7
/*
 * Windows and Unix use an alternative allocator when building with threads
 * that has significantly reduced lock contention.
 */

#if !defined(TCL_THREADS) || !defined(USE_THREAD_ALLOC)

d33 3
a35 2
 * We should really make use of AC_CHECK_TYPE(caddr_t)
 * here, but it can wait until Tcl uses config.h properly.
d37 2
a38 1
#if defined(MAC_TCL) || defined(_MSC_VER) || defined(__MINGW32__) || defined(__BORLANDC__)
d726 1
a726 1
#endif /* !TCL_THREADS */
@


