head	1.3;
access;
symbols
	binutils-2_24-branch:1.3.0.2
	binutils-2_24-branchpoint:1.3
	binutils-2_23_2:1.1.2.1
	binutils-2_23_1:1.1.2.1
	binutils-2_23:1.1.2.1
	binutils-2_23-branch:1.1.0.2
	binutils_latest_snapshot:1.3;
locks; strict;
comment	@# @;


1.3
date	2013.05.13.22.28.27;	author yufeng;	state Exp;
branches;
next	1.2;

1.2
date	2013.01.17.16.09.43;	author yufeng;	state Exp;
branches;
next	1.1;

1.1
date	2012.08.13.14.52.46;	author nickc;	state Exp;
branches
	1.1.2.1;
next	;

1.1.2.1
date	2012.08.16.09.21.46;	author nickc;	state Exp;
branches;
next	1.1.2.2;

1.1.2.2
date	2013.05.13.23.09.52;	author yufeng;	state Exp;
branches;
next	;


desc
@@


1.3
log
@gas/

	* testsuite/gas/aarch64/diagnostic.s: Update.
	* testsuite/gas/aarch64/diagnostic.l: Ditto.
	* testsuite/gas/aarch64/movi.s: Add new tests.
	* testsuite/gas/aarch64/movi.d: Update.

opcodes/

	* aarch64-asm.c (aarch64_ins_advsimd_imm_modified): Remove assertion.
	* aarch64-opc.c (operand_general_constraint_met_p): Relax the range
	check from [0, 255] to [-128, 255].
@
text
@// movi.s Test file for AArch64 AdvSIMD modified immediate instruction MOVI

	.text

	.macro all_64bit_mask_movi	dst
	.irp	b7, 0, 0xff00000000000000
	.irp	b6, 0, 0xff000000000000
	.irp	b5, 0, 0xff0000000000
	.irp	b4, 0, 0xff00000000
	.irp	b3, 0, 0xff000000
	.irp	b2, 0, 0xff0000
	.irp	b1, 0, 0xff00
	.irp	b0, 0, 0xff
	movi	\dst, \b7 + \b6 + \b5 + \b4 + \b3 + \b2 + \b1 + \b0
	.endr
	.endr
	.endr
	.endr
	.endr
	.endr
	.endr
	.endr
	.endm

	// MOVI <Dd>, #<imm>
	// MOVI <Vd>.2D, #<imm>
	all_64bit_mask_movi d31
	all_64bit_mask_movi v15.2d


	.macro	all_8bit_imm_movi dst, from=0, to=255
	movi	\dst, \from
	.if	\to-\from
	all_8bit_imm_movi \dst, "(\from+1)", \to
	.endif
	.endm

	// Per byte
	// MOVI <Vd>.<T>, #<imm8>
	.irp	T, 8b, 16b
	all_8bit_imm_movi v15.\T, 0, 63
	all_8bit_imm_movi v15.\T, 64, 127
	all_8bit_imm_movi v15.\T, 128, 191
	all_8bit_imm_movi v15.\T, 192, 255
	.endr


	.macro	all_8bit_imm_movi_sft dst, from=0, to=255, shift_op, amount
	movi	\dst, \from, \shift_op \amount
	.if	\to-\from
	all_8bit_imm_movi_sft \dst, "(\from+1)", \to, \shift_op, \amount
	.endif
	.endm

	// Shift ones, per word
	// MOVI <Vd>.<T>, #<imm8>, MSL #<amount>
	.irp	T, 2s, 4s
	.irp	amount, 8, 16
	// Have to break into four chunks to avoid "Fatal error: macros nested
	// too deeply".
	all_8bit_imm_movi_sft v7.\T, 0, 63, MSL, \amount
	all_8bit_imm_movi_sft v7.\T, 64, 127, MSL, \amount
	all_8bit_imm_movi_sft v7.\T, 128, 191, MSL, \amount
	all_8bit_imm_movi_sft v7.\T, 192, 255, MSL, \amount
	.endr
	.endr


	// Shift zeros, per halfword
	// MOVI <Vd>.<T>, #<imm8> {, LSL #<amount>}
	.irp	T, 4h, 8h
	.irp	amount, 0, 8
	all_8bit_imm_movi_sft v7.\T, 0, 63, LSL, \amount
	all_8bit_imm_movi_sft v7.\T, 64, 127, LSL, \amount
	all_8bit_imm_movi_sft v7.\T, 128, 191, LSL, \amount
	all_8bit_imm_movi_sft v7.\T, 192, 255, LSL, \amount
	all_8bit_imm_movi v15.\T, 0, 63
	all_8bit_imm_movi v15.\T, 64, 127
	all_8bit_imm_movi v15.\T, 128, 191
	all_8bit_imm_movi v15.\T, 192, 255
	.endr
	.endr


	// Shift zeros, per word
	// MOVI <Vd>.<T>, #<imm8> {, LSL #<amount>}
	.irp	T, 2s, 4s
	.irp	amount, 0, 8, 16, 24
	all_8bit_imm_movi_sft v7.\T, 0, 63, LSL, \amount
	all_8bit_imm_movi_sft v7.\T, 64, 127, LSL, \amount
	all_8bit_imm_movi_sft v7.\T, 128, 191, LSL, \amount
	all_8bit_imm_movi_sft v7.\T, 192, 255, LSL, \amount
	all_8bit_imm_movi v15.\T, 0, 63
	all_8bit_imm_movi v15.\T, 64, 127
	all_8bit_imm_movi v15.\T, 128, 191
	all_8bit_imm_movi v15.\T, 192, 255
	.endr
	.endr

	// Shift zeros, per byte
	// MOVI <Vd>.<T>, #<imm8>, LSL #0
	// This used to be a programmer-friendly feature (allowing LSL #0),
	// but it is now part of the architecture specification.
	.irp	T, 8b, 16b
	all_8bit_imm_movi_sft v7.\T, 0, 63, LSL, 0
	all_8bit_imm_movi_sft v7.\T, 64, 127, LSL, 0
	all_8bit_imm_movi_sft v7.\T, 128, 191, LSL, 0
	all_8bit_imm_movi_sft v7.\T, 192, 255, LSL, 0
	.endr

	movi	v0.2d, 18446744073709551615
	movi	v0.2d, -1
	movi	v0.2d, bignum
	movi	d31, 18446744073709551615
.set    bignum, 0xffffffffffffffff

	// Allow -128 to 255 in #<imm8>
	movi	v3.8b, -128
	movi	v3.8b, -127
	movi	v3.8b, -1
@


1.2
log
@include/opcode/

2013-01-17  Yufeng Zhang  <yufeng.zhang@@arm.com>

	* aarch64.h (aarch64_op): Remove OP_V_MOVI_B.

opcodes/

2013-01-17  Yufeng Zhang  <yufeng.zhang@@arm.com>

	* aarch64-asm.c (aarch64_ins_advsimd_imm_modified): Handle 8-bit MOVI.
	* aarch64-dis.c (aarch64_ext_advsimd_imm_modified): Likewise.
	* aarch64-opc.c (operand_general_constraint_met_p): For
	AARCH64_MOD_LSL, move the range check on the shift amount before the
	alignment check; change to call set_sft_amount_out_of_range_error
	instead of set_imm_out_of_range_error.
	* aarch64-tbl.h (QL_SIMD_IMM_B): Replace NIL with LSL.
	(aarch64_opcode_table): Remove the OP enumerator from the asimdimm
	8-bit MOVI entry; change the 2nd operand from SIMD_IMM to
	SIMD_IMM_SFT.

gas/

2013-01-17  Yufeng Zhang  <yufeng.zhang@@arm.com>

	* config/tc-aarch64.c (output_operand_error_record): Change to output
	the out-of-range error message as value-expected message if there is
	only one single value in the expected range.
	(programmer_friendly_fixup): Remove the handling of 8-bit MOVI with
	LSL #0 as a programmer-friendly feature.

gas/testsuite/

2013-01-17  Yufeng Zhang  <yufeng.zhang@@arm.com>

	* gas/aarch64/diagnostic.l: Update.
	* gas/aarch64/movi.s: Add tests.
	* gas/aarch64/movi.d: Update.
	* gas/aarch64/programmer-friendly.s: Add comment.
@
text
@d116 5
@


1.1
log
@Add support for 64-bit ARM architecture: AArch64
@
text
@d100 11
@


1.1.2.1
log
@Add support for 64-bit ARM architecture: aarch64
@
text
@@


1.1.2.2
log
@gas/testsuite/

	Backport from mainline:

	2013-05-13  Yufeng Zhang  <yufeng.zhang@@arm.com>
	* gas/aarch64/diagnostic.s: Update.
	* gas/aarch64/diagnostic.l: Ditto.
	* gas/aarch64/movi.s: Add new tests.
	* gas/aarch64/movi.d: Update.

opcodes/

	Backport from mainline:

	2013-05-13  Yufeng Zhang  <yufeng.zhang@@arm.com>
	* aarch64-asm.c (aarch64_ins_advsimd_imm_modified): Remove assertion.
	* aarch64-opc.c (operand_general_constraint_met_p): Relax the range
	check from [0, 255] to [-128, 255].
@
text
@a104 5

	// Allow -128 to 255 in #<imm8>
	movi	v3.8b, -128
	movi	v3.8b, -127
	movi	v3.8b, -1
@


